%% For double-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\hifunrule}[3]{\highlight{#1} &\highlight{=}& \highlight{#2} & 
\highlight{#3}\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\comprulel}[4]{#1 & \fatsemi^l & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{Lazy\;UD}
\newcommand{\lazyD}{Lazy\;D}

\newcommand{\sOOinspect}[3]{\langle\langle#1,#2\rangle,#3\rangle}
\newcommand{\sOOreturn}[2]{\langle#1,#2\rangle}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}

%\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
%\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
%\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}

\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{#1 \; #2}
\newcommand{\eOOcons}[2]{\mathtt{cons} \; #1 \; #2}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{#1 \langle \cOOcast{#2}{#3}{#4} \rangle}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\cOOcast}[3]{#1 \Rightarrow^{#2} #3}
\newcommand{\oOOinj}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\vOOcast}[2]{#1\langle#2\rangle}
\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
%\newcommand{\rOOsucc}[1]{#1}
%\newcommand{\rOOfail}[1]{#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}

\newcommand{\kOOmt}[0]{\mathtt{stop}}
\newcommand{\kOOconsI}[3]{[\mathtt{cons} \; \square \; \langle#1,#2\rangle ]#3}
\newcommand{\kOOconsII}[2]{[\mathtt{cons} \; #1 \; \square]#2}
\newcommand{\kOOinl}[1]{[\mathtt{inl} \; \square]#1}
\newcommand{\kOOinr}[1]{[\mathtt{inr} \; \square]#1}
\newcommand{\kOOappI}[3]{
	[\mathtt{app} \; \square \; \langle#1,#2\rangle ]#3
}
\newcommand{\kOOappII}[2]{
	[\mathtt{app} \; #1 \; \square]#2}
\newcommand{\kOOcar}[1]{[\mathtt{fst} \; \square]#1}
\newcommand{\kOOcdr}[1]{[\mathtt{snd} \; \square]#1}
\newcommand{\kOOcaseI}[4]{
	[\mathtt{case} \; \square \; \langle#1,#3\rangle \; \langle#2,#3\rangle ]#4}
\newcommand{\kOOcaseII}[4]{
	[\mathtt{case} \; #1 \; \square \; \langle#2,#3\rangle ]#4}
\newcommand{\kOOcaseIII}[3]{
	[\mathtt{case} \; #1 \; #2 \; \square]#3}
\newcommand{\kOOcast}[2]{
	[\square \langle #1 \rangle]#2}

%\newcommand{\kOOmt}[0]{\mathtt{stop}}
%\newcommand{\kOOconsI}[3]{\mathtt{cons_1} \; #1 \; #2 \; #3}
%\newcommand{\kOOconsII}[2]{\mathtt{cons_2} \; #1 \; #2}
%\newcommand{\kOOinl}[1]{\mathtt{inl} \; #1}
%\newcommand{\kOOinr}[1]{\mathtt{inr} \; #1}
%\newcommand{\kOOappI}[3]{
%	\mathtt{app_1} \; #1 \; #2 \; #3
%}
%\newcommand{\kOOappII}[2]{
%	\mathtt{app_2} \; #1 \; #2}
%\newcommand{\kOOcar}[1]{
%	\mathtt{fst} \; #1}
%\newcommand{\kOOcdr}[1]{
%	\mathtt{snd} \; #1}
%\newcommand{\kOOcaseI}[4]{
%	\mathtt{case_1} \; #1 \; #2 \; #3 \; #4}
%\newcommand{\kOOcaseII}[4]{
%	\mathtt{case_2} \; #1 \; #2 \; #3 \; #4}
%\newcommand{\kOOcaseIII}[3]{
%	\mathtt{case_3} \; #1 \; #2 \; #3}
%\newcommand{\kOOcast}[2]{
%	\langle #1 \rangle #2}

\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{inj} \; #2}
%\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #2 \; #1 \; #3 \; #4 \; #5}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
%\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\langle#2\rangle\;#3\langle#4\rangle}
%\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
%\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\langle#2\rangle}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\langle#2\rangle}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D cast calculus on space-inefficient CEK
\newcommand{\judgeCreduce}[2]{#1 \longmapsto_{\mathcal{C}} #2}
\newcommand{\judgeCreduceTrans}[2]{#1 \longmapsto_{\mathcal{C}}^{*} #2}
\newcommand{\judgeCeval}[2]{eval_{\mathcal{C}}(#1) = #2}
\newcommand{\redrule}[3]{#1 & \longmapsto_\mathcal{C} & #2 & #3\\}
\newcommand{\hiredrule}[3]{\highlight{#1} & \highlight{\longmapsto_\mathcal{C}} & \highlight{#2} & \highlight{#3} \\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longmapsto_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longmapsto_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{eval_{\mathcal{S}(#1)}(#2) = #3}
\newcommand{\redruleS}[3]{#1 & \longmapsto_{\mathcal{S}(C)} & #2 & #3\\}
\newcommand{\hiredruleS}[3]{\highlight{#1} & 
\highlight{\longmapsto_{\mathcal{S}(C)}} & \highlight{#2} & \highlight{#3} \\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hypercoercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvSD}[3]{#2 \approx_{\mathcal{SD}} #3}
% to-dos
\newcommand{\todoKC}[1]{\todo[inline]{KC needs to #1}}
\newcommand{\todoKCFixed}[0]{\todo[inline]{Fixed. -KC}}
% abbrev
\newcommand{\castCalculus}[0]{$\lambda_{\rightarrow}^{\langle\cdot\rangle}$}
% names
\newcommand{\ineffCEK}{$\mathcal{C}$}
\newcommand{\ineffCEKD}{$\mathcal{D}$}
\newcommand{\ineffCEKUD}{$\mathcal{UD}$}
\newcommand{\judgeDreduce}[2]{#1 \longmapsto_{\mathcal{D}} #2}
\newcommand{\judgeDreduceTrans}[2]{#1 \longmapsto_{\mathcal{D}}^{*} #2}
\newcommand{\judgeDeval}[2]{eval_{\mathcal{D}}(#1) = #2}
\newcommand{\judgeUDreduce}[2]{#1 \longmapsto_{\mathcal{UD}} #2}
\newcommand{\judgeUDreduceTrans}[2]{#1 \longmapsto_{\mathcal{UD}}^{*} #2}
\newcommand{\judgeUDeval}[2]{eval_{\mathcal{UD}}(#1) = #2}
\newcommand{\effCEK}[1]{$\mathcal{S}(#1)$}
\newcommand{\evalEqv}[2]{$eval_{\text{#1}} = eval_{\text{#2}}$}
\newcommand{\continue}[2]{cont(#2,#1)}
\newcommand{\highlight}[1]{{\color{red} #1}}

\begin{document}

%% Title information
\title{Hypercoercions and a Framework for Equivalence of Cast Calculi}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  Designing a space-efficient cast representation that is good for
  both mechanized metatheory and implementation is
  challenging. Existing solutions are good for one or the other. This
  paper presents a new cast representation, named hypercoercions, that
  is good for both. On the way to proving the correctness of
  hypercoercions, this paper also makes progress on a general
  framework for proving the correctness of cast representations.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\listoftodos{}


\section{Introduction}

\todo[inline]{I see lots of mistakes regarding when to make words
  plural (whether they should have an ``s'' at the end). Please review
  the rules of English regarding plurals. The rules are tricky...
  some words don't have a plural form, like ``blame''. -JS
  \\---\\
  Will fix grammar after fixing all other problems -KC}

Around 2006, several groups of researchers proposed ways to integrate
dynamic typing and static typing, notably gradual typing
\citep{siek2006gradual}, hybrid typing \citep{flanagan2006hybrid},
migratory typing \citep{Tobin-Hochstadt:2006fk}, and multi-language
iteroperability \citep{Gray:2005ij,Matthews:2007zr}. Researchers
usually define the semantics of gradually typed languages by
translation to an intermediate language with casts, such as the blame
calculus \citep{wadler2009well} and other cast calculi
\citep{siek2009exploring}. Unfortunately, straightforward
implementations of casts on higher-order values (functions, objects,
etc.) impose significant runtime overheads that can change the
asymptotic space complexity of a program
\citep{herman2010space}. There are several known space-efficient cast
representations, with various strengths and weaknesses
\citep{siek2015blame,siek2010threesomes,garcia2013calculating,kuhlenschmidt2018efficient,siek2012interpretations,garcia2014deriving}.
The current state of the art includes

\begin{itemize}
\item threesomes \citep{siek2010threesomes,garcia2013calculating},
\item supercoercions \citep{garcia2013calculating}, and
\item coercions in normal form
  \citep{siek2012interpretations,siek2015blame}.
\end{itemize}
Recall that in these systems, casts are compressed using a composition
operator.  Threesomes and supercoercions are good for mechanized
metatheory because their compose operators are structurally recursive,
making them easy to define in a proof assistant such as Agda. In
contrast, the coercions in normal form have compose operators that are
not structurally recursive, which makes it more difficult to define in
Agda, requiring what amounts to an explicit proof of termination.
%
On the other hand, coercions in normal form are easier to understand
than threesomes (with a strange labelled bottom type), and
supercoercions (10 different kinds).

This paper presents a new cast representation, named
\emph{hypercoercions}, that is good for both mechanized metatheory and
good for implementation. The composition operator for hypercoercions
is defined by structural recursion and hypercoercions are suggestive
of a bit-level representation that minimizes the need for pointers and
fits all first-order casts into 64 bits. We present two flavors of
hypercoercions to support the two blame tracking strategies from the
literature: D and UD~\citep{siek2009exploring}. We are interested in
the D blame tracking strategy because it comes with a more
straightforward notion safe cast compared to
UD~\citep{siek2009exploring}, which is why D was chosen Grift
compiler. We are also intersted in UD because it plays a prominent
role in the gradual typing literature \citep{wadler2009well}. The
semantics of casts can also be lazy or
eager~\citep{siek2009exploring}. In this paper we focus on lazy cast
strategies because we suspect that they are more efficient than eager
strategies and because \citet{new2019gradual} show that eager
strategies are incompatible with $\eta$-equivalence of functions.

Of course, an alternative cast representation must be proved
correct. This paper presents steps toward a general framework for
proving equivalence of cast calculi and, in particular, proves that an
abstract machine using \lazyD{} hypercoercions is equivalent to an
abstract machine using standard \lazyD{}
casts~\citep{siek2009exploring}. We conjecture that the framework can
be generalized to \lazyUD{} and that it can be applied to coercions in
normal form and threesomes.

To summarize, the primary contributions of this paper are:
\begin{itemize}
\item hypercoercions, a new space-efficient cast representation, which
  has a structurally recursive composition and a more compact memory
  representation.
\item a framework in Agda for proving the correctness of cast
  represantations.
\item a formal proof that hypercoercion respects the semantics
  of the \lazyD{} cast calculus.
\end{itemize}

In Section~\ref{sec:background} we review cast calculi and coercions.
We present hypercoercions in
Section~\ref{sec:hypercoercion-definition}.  We present a framework
for proving correctness of cast reprensentations in
Section~\ref{sec:framework} and use it to prove the correctness of
\lazyD{} hypercoercions in
Section~\ref{sec:hypercoercion-correctness}.

\section{Background} \label{sec:background}

In this section, we review lazy cast calculi
(Section~\ref{sec:cast-calculi}) and coercion in normal form
(Section~\ref{sec:coercion-calculus}).

\subsection{Cast Calculi}
\label{sec:cast-calculi}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P}{pre-types}{
		\POOunit \mid
		\POOfun{T_1}{T_2} \mid
		\POOprod{T_1}{T_2} \mid
		\POOsum{T_1}{T_2}
	}
	\stxrule{e}{terms}{
		\eOOvar{x} \mid{}
		\eOOsole{} \mid{}
		\eOOlam{T_1}{T_2}{x}{e} \mid
		\eOOapp{e_1}{e_2} \mid
		\eOOcons{e_1}{e_2} \mid
		\eOOcar{e} \mid
		\eOOcdr{e}
	}
	\stxrulecont{
		\eOOinl{e} \mid
		\eOOinr{e} \mid
		\eOOcase{e_1}{e_2}{e_3} \mid
		\eOOcast{e}{T_1}{l}{T_2} \mid
		\eOOblame{l}
	}
	\end{array}
	\]
	
	Consistency
	\fbox{$T_1 \sim T_2$}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\[1ex]
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	Term typing
	\fbox{$\judgetype{\Gamma}{e}{T}$}
	\begin{gather*}
          \dots \qquad
		\inference{
			\Gamma \vdash e : T_1 & T_1 \sim T_2
		}{
			\judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\eOOblame{l}}{T}
		}
	\end{gather*}
	
	\caption{Syntax and static semantics of the cast calculi.}
	\label{fig:blame-static}
\end{figure}


\paragraph{Syntax and Static Semantics}

The syntax and static semantics is the same for the \lazyD{} and
\lazyUD{} cast calculi, and is reviewed in \figref{fig:blame-static}.
As usual, the important features are the cast expressions,
$\eOOcast{e}{T_1}{l}{T_2}$, which are responsible for runtime type
checking, and blame expressions, $\eOOblame{l}$, that raise errors.
The syntax and static semantics is the same that of
\citet{siek2009exploring} except for a few minor exceptions:
\begin{itemize}
\item We add sum, product, and unit types.
\item We separate types into those with a type constructor at the top,
  the \emph{pretypes} ($\POOunit$, functions, products, and sums),
  versus the dynamic type $\star$ (a.k.a. $\mathtt{Dyn}$ or
  $\mathbb{?}$).
\item We annotate the codomain of a lambda abstraction explicitly
  because we refer to it in the dynamic semantics. 
\end{itemize}
As usual, the source $T_1$ and target types $T_2$ of a cast
$\eOOcast{e}{T_1}{l}{T_2}$ are required to be consistent, written $T_1
\sim T_2$. The consistency relation is standard and defined in
\figref{fig:blame-static}.

%% defines the syntax of the cast calculus and
%% its static semantics. We extend the syntax of
%%  with sum and product types.  Let $T$ range
%% over types. A type is either the dynamic type$\star$(a.k.a. $
%% \mathtt{Dyn}$, $\mathbb{?}$, or$\mathtt{Unknown}$), or a type

%% As usual we write$T_1 \sim T_2$when$T_1$ and $T_2$ are
%% consistent. The intuition of $T_1 \sim T_2$ is that $T_1$and $
%% T_2$have no conflicting type information. Two types are consistent
%% if one of them is $\star$, or they have the same top-most type
%% constructor and the corresponding sub-parts are
%% consistent. Consistency is reflexive and symmetric, but not
%% transitive.

%% We write$T_1 \smile T_2$when$T_1$ and $T_2$ are
%% shallowly-consistent, that is, if one of them is $\star$, or they
%% have the same type constructor at the top. Shallow-inconsistency is
%% the root of all blame in lazy cast strategies -- casting a value to a
%% shallowly inconsistent type leads to a blame. Shallow-consistency is
%% reflexive, symmetric, but not transitive.

%% Let $e$ range over terms. Most terms are standard for a simply-typed
%% lambda calculus. We annotate the codomain of a lambda abstraction
%% explicitly because we refer to it in the dynamic semantics. Becuase
%% this is a cast calculus, we have two additional terms: cast
%% expressions and blame expressions. Cast expressions perform runtime
%% type checks and blame expressions raise an error.


\paragraph{Dynamic Semantics}

The dynamic semantics of a cast calculus is typically defined with a
reduction semantics. Here we use a CEK machine
\citep{felleisen1986control} instead because the first author is more
familiar with CEK machines and believes that a CEK machine is more
convenient to use for the space-efficient semantics in
Section~\ref{sec:framework:cek} (a major point of space-efficiency is about 
compressing continuations). So using an abstract machine for the cast calculi in
this section makes it easier prove correctness of the space-efficient
machines. Of course, one should prove that the abstract machine
presented here is equivalent to the standard reduction semantics for
cast calculi, but we have not yet done so.

Fig.~\ref{fig:machine-cekc} defines the transition relation of the CEK
machine and Fig.~\ref{fig:state} gives a grammar for machine states
$s$, including a definition of values and value typing. The
transitions involving casts are highlighted in red and described in
more detail below. The other transitions are standard for a CEK
machine for an extended simply typed lambda calculus.
%
Recall that CEK machine involves two kinds of transitions, (1) those
that dive further into an expression (looking for a redex) and push an
entry onto the continuation, and (2) those that return a value to the
current continuation and possibly perform a computation.
Corresponding to (1) and (2), the machine state is either in an
$\mathtt{Eval}$ or $\mathtt{Cont}$ configuration, respectively.
Additionally, there is the $\mathtt{Halt}$ configuration.

The transition relation $\judgeCreduce{s}{s}$ is parameterized over
$applyCast$ to allow for the differences between D and UD.
%
When evaluating a cast expression, the machine moves the cast to the
continuation and evaluates the inner expression.
%% Other
%% transition rules starting from$Eval$states are standard.
To apply a casted function, the machine first casts $v_1$, the
operand, then applies the casted operand to $v_2$, the underlying
function, and finally cast the result of the function application.
%
To take out the first (resp. second) part of a casted pair, the
machine firstly take out the first (resp. second) part of $v$, the
underlying pair, and cast the result.
%
%In case splitting, if the target value is a left injection, the
%machine moves to a state that will apply the first continuation
%function to the value inside the left injection. The case for right
%injection is similar.
%
When the target value is a casted sum, the machine moves the cast from
the target value to continuations functions.
%
To cast a value, the machine invokes $applyCast$ on the value.  If the
cast succeeds, the machine returns the result to the next
continuation.  If the cast fails, the machine halts with the blame
label.
%
%% When the continuation is $stop$, the machine enters a halting
%% state. The When the machine is in a halting state, it stays in the
%% same state.

The reflexive transitive closure of reduction ($\judgeCreduceTrans{s}{s}$) and 
evaluation ($eval_\mathcal{C}(e)$)
are standard~\citep{felleisen03:_pllc}.


\begin{figure}
  Machine state and other runtime data structures
  \[
  \begin{array}{rclr}
	\stxrule{v}{values}{
		\vOOtt{} \mid
		\vOOfun{\rho}{x}{e} \mid
		\vOOcons{v_1}{v_2} \mid
		\vOOinl{v} \mid
		\vOOinr{v} \mid		
		\vOOcast{v}{c}
	}
	\stxrule{c}{casts}{
		\cOOcast{T_1}{l}{T_2}
	}
	\stxrule{I}{injectable types (\lazyD)}{
		P
	}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\star}{\star} \mid
		\star \times \star \mid
		\star + \star
	}
	\stxrule{o}{observations}{
		\oOOinj \mid
		\oOOsole \mid
		\oOOfun \mid
		\oOOcons \mid
		\oOOinl \mid
		\oOOinr \mid
		\oOOblame{l}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuations}{
		\kOOmt \mid
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa}
	}
	\stxrulecont{
		\kOOinr{\kappa} \mid
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa}
	}
	\stxrulecont{	
		\kOOcdr{\kappa}\mid
		\kOOcaseI{e}{e}{\rho}{\kappa}\mid
		\kOOcaseII{v}{e}{\rho}{\kappa}
	}
	\stxrulecont{
		\kOOcaseIII{v}{v}{\kappa} \mid
		\kOOcast{c}{\kappa}
	}
  \end{array}
  \]

        Shallow-consistency
	\fbox{$T \smile T$}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
	} \quad
	\inference{}{
		T_{11} \times T_{12} \smile T_{21} \times T_{22}
	} \quad
	\inference{}{
	T_{11} \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	Value typing \fbox{$v : T$}
	\begin{gather*}
	\dots \qquad
	\inference{
		v : I
	}{
		\vOOcast{v}{\cOOcast{I}{l}{\TOOdyn}} : \TOOdyn
	}
	\quad
	\inference{
		v : P_1 &
		P_1 \smile P_2
	}{
		\vOOcast{v}{\cOOcast{P_1}{l}{P_2}} : P_2
	}
	\end{gather*}
        \caption{Definition of machine state and auxilliary data
          structures.}
        \label{fig:state}
\end{figure}

Let $v$ range over values. A value is either the unit, a function (a
closure), a pair, a left injection, a right injection, or a casted
value. As shown by the value typing rules, if the target type of a
casted value is the dynamic type, the underlying value must be of an
injectable type. The definition of injectable types depends on blame
strategies: for the \lazyD\ strategy, every pre-type is injectable;
for the \lazyUD\ strategy, a pre-types is injectable if and only if
all its sub-parts are the dynamic type. If the target type of a casted
value is a pre-type, the type of the underlying value must have the
same type constructor.

Let $c$ range over casts. A cast is a triple of a type, a label, and a type.

Let $o$ range over observations. They are what would be observed if
a program terminates. Observations include all value constructors and
blame.  The function converting values to observations ($observe(v) =
o$) is defined in the natural way.

\begin{figure}
	%	Continuation typing \fbox{$\kappa : T_1 \Longrightarrow T_2$}
	%	\begin{gather*}
	%	\dots \quad
	%	\inference{
	%		c : T_1 \Longrightarrow T_2 &
	%		\kappa : T_2 \Longrightarrow T_3
	%	}{
	%		\langle c \rangle \kappa : T_1 \Longrightarrow T_3
	%	}
	%	\end{gather*}
	
	\[
	\begin{array}{rclr}
	\end{array}
	\]
	
	Reduction \fbox{$\judgeCreduce{s}{s}$}
	\[
	\begin{array}{rclr}
		\hiredrule{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{
			\kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa}
%			\langle\cOOcast{T_1}{l}{T_2}\rangle\kappa
		}
	}{}
	\redrule{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho(x)}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\vOOtt}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\vOOfun{\rho}{x}{e})}{\kappa}
	}{}
	\redrule{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{(\kOOconsI{e_2}{\rho}{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{(\kOOinl{\kappa})}
	}{}
	\redrule{
	\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
	\sOOinspect{e}{\rho}{(\kOOinr{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
\sOOinspect{e_1}{\rho}{(\kOOappI{e_2}{\rho}{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
\sOOinspect{e}{\rho}{(\kOOcar{\kappa})}}{}

\redrule{
	\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
	\sOOinspect{e}{\rho}{(\kOOcdr{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
\sOOinspect{e_1}{\rho}{(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{}

\redrule{
\sOOreturn{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOconsII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
\sOOreturn{(\vOOcons{v_1}{v_2})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinl{\kappa})}}{
\sOOreturn{(\vOOinl{v})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinr{\kappa})}}{
\sOOreturn{(\vOOinr{v})}{\kappa}}{}

\redrule{
\sOOreturn{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOappII{(\vOOfun{\rho}{x}{e})}{\kappa})}}{
\sOOinspect{e}{\rho[x:=v_2]}{\kappa}}{}
	\hiredrule{
		\sOOreturn{v_1}{
			\kOOappII{\vOOcast{v_2}{
					\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
			}}{\kappa}
%			(\mathtt{app_2} \; \vOOcast{v_2}{
%				\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
%			} \; \kappa)
		}
	}{
		\sOOreturn{v_1}{
			\kOOcast{\cOOcast{T_3}{l}{T_1}}{
				\kOOappII{v_2}{
					\kOOcast{\cOOcast{T_2}{l}{T_4}}{\kappa}
				}
			}
%			\langle\rangle
%			(\mathtt{app_2} \; v_2 \; 
%			\langle\cOOcast{T_2}{l}{T_4}\rangle \kappa)}
		}
	}{}
	\redrule{
	\sOOreturn{
		(\vOOcons{v_1}{v_2})
	}{(\kOOcar{\kappa})}
	}{
	\sOOreturn{v_1}{\kappa}
	}{}
	\hiredrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{fst} \; \kappa)}
	}{
		\sOOreturn{v}{
			\kOOcar{
				\kOOcast{\cOOcast{T_1}{l}{T_3}}{\kappa}
			}}
	}{}
	\redrule{
	\sOOreturn{
		(\vOOcons{v_1}{v_2})
	}{(\kOOcdr{\kappa})}
	}{
	\sOOreturn{v_2}{\kappa}
	}{}
	
	\hiredrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{snd} \; \kappa)}
	}{
		\sOOreturn{v}{
			\kOOcdr{\kOOcast{\cOOcast{T_2}{l}{T_4}}{\kappa}}}
	}{}

\redrule{
\sOOreturn{v_1}{(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_3}{\rho}{
	(\kOOcaseIII{v_1}{v_2}{\kappa})
}}{}	

\redrule{
\sOOreturn{v_3}{
	(\kOOcaseIII{(\vOOinl{v})}{v_2}{\kappa})
%	(\mathtt{case_3}\;(\vOOinl{v})\;v_2\;\kappa)
}
}{
\sOOreturn{v}{(\kOOappII{v_2}{\kappa})}
}{}

\redrule{
	\sOOreturn{v_3}{
		(\kOOcaseIII{(\vOOinr{v})}{v_2}{\kappa})
%		(\mathtt{case_3}\;(\vOOinr{v})\;v_2\;\kappa)
	}
}{
\sOOreturn{v}{(\kOOappII{v_3}{\kappa})}
}{}

\redrule{
	\highlight{\sOOreturn{v_3}{
		(	\kOOcaseIII{
				\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
			}{v_2}{\kappa})
%		
%			(\mathtt{case_3}\;
%		(\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}})
%		\;v_2\;\kappa)
	}}
}{
	\highlight{\sOOreturn{v_3'}{
			(\kOOcaseIII{v}{v_2'}{\kappa})
	}}
}{\\&&
\highlight{\text{where}\;
v2' = \vOOcast{v_2}{\cOOcast{\POOfun{T_4}{T}}{l}{\POOfun{T_2}{T}}}}
\\&&
\highlight{\text{and}\;
v3' = \vOOcast{v_3}{\cOOcast{\POOfun{T_3}{T}}{l}{\POOfun{T_1}{T}}}}
}
	
	\redrule{
		\highlight{\sOOreturn{v}{(
				\kOOcast{c}{\kappa}
			)}}
	}{
\highlight{          
\begin{cases}
	\sOOreturn{v'}{\kappa} & \sidecond{applyCast(v,c) = \rOOsucc{v'}}
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
\end{cases}}
	}{}
\redrule{
\sOOreturn{v}{\kOOmt}}{
\sOOhalt{observe(v)}}{}
	\end{array}
	\]	
	
	Evaluation \fbox{$\judgeCeval{e}{o}$}
	\[
	\inference{
		\sOOinspect{e}{\emptyset}{wrap(\hckOOmt)} \longrightarrow_{B}^{*} 
		\sOOhalt{o}
	}{
		\judgeCeval{e}{o}
	}
	\]
	
	\caption{Dynamic semantics of the cast calculi as a CEK
          machine. The transitions that involve casts are highlighted
          in red.}
	\label{fig:machine-cekc}
\end{figure}

Let $r$ range over cast results. A cast result is either a success, which 
brings back a value, or a failure, which brings a blame label.

Let $s$ range over machine states. A state is either looking at an 
expression to decide what to do next, returning a value to a continuation, or 
halting with an observation.

Let $\kappa$ range over continuations. $\mathtt{stop}$ is the top 
continuation. The remaining continuations correspond to expressions. For 
example, $(\mathtt{cons_1} \; e \; \rho \; \kappa)$ is the continuation where 
we are waiting for the value of the first argument to a $\mathtt{cons}$. And 
the last continuation, $\langle c \rangle \kappa$ is to cast the value before 
returning to $\kappa$.

\begin{figure}
	
	\fbox{$applyCast(v,c) = r$}
	\[
	\begin{array}{rclr}
	\funrule{
		applyCast(v,\cOOcast{\star}{l}{\star})
	}{
		\rOOsucc{v}
	}{}
	\funrule{
		applyCast(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
	}{
		applyCast(v,\cOOcast{P_1}{l_2}{P_2})
	}{}
	\funrule{
		applyCast(v,\cOOcast{P}{l}{\star})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
	}{}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
	}{\sidecond{P_1 \smile P_2}}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOfail{l}
	}{\sidecond{\neg P_1 \smile P_2}}
	
	\end{array}
	\]
	\caption{Definition of $applyCast$for \lazyD}
	\label{fig:applyCast-D-C}
\end{figure}

\begin{definition}[\lazyD{} CEK Machine]
  The \lazyD{} CEK machine, written \ineffCEKD{}, is the CEK machine of
  \figref{fig:machine-cekc} using the $applyCast$ for \lazyD{} defined
  in \figref{fig:applyCast-D-C}.  We write the transition relations of
  this machine as $\judgeUDreduce{s}{s}$ and $\judgeUDreduceTrans{s}{s}$
  and write the evaluation function as $\judgeUDeval{e}{o}$.
\end{definition}

We conjecture that \ineffCEKD{} agrees with the \lazyD{} cast calculus
of \citet{siek2009exploring}.

Next we define the CEK Machine for \lazyUD{}. The only difference with
respect to \lazyD{} is in the definition of the $\mathit{applyCast}$
function, in which a cast whose source or target is the unknown type
$\star$ is always split into two casts that go through an injectiable
type, that is, a type in which all sub-components are the unknown
type, such as $\star \to \star$.


\begin{definition}[\lazyUD{} CEK Machine]
  The \lazyUD{} CEK machine, written \ineffCEKUD{}, is the CEK machine of
  \figref{fig:machine-cekc} using the $applyCast$ for \lazyUD{} defined
  in \figref{fig:apply-Cast-UD}.  We write the transition relations of
  this machine as $\judgeDreduce{s}{s}$ and $\judgeDreduceTrans{s}{s}$
  and write the evaluation function as $\judgeDeval{e}{o}$.
\end{definition}


\begin{figure}
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& v \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        v \langle \cOOcast{P}{l}{I} \rangle
          \langle \cOOcast{I}{l}{\star} \rangle
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        v \langle \cOOcast{\star}{l}{I} \rangle
          \langle \cOOcast{I}{l}{P} \rangle
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& v \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
     v \langle \cOOcast{P_1}{l}{P_2} \rangle & \text{if } P_1 \smile P_2
  \end{array}
  \]

  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}

We conjecture that \ineffCEKUD{} agrees with the \lazyUD{} cast
calculus of \citet{siek2009exploring}.

% the following are temporary -JS
\clearpage
\pagebreak

\subsection{Coercions in Normal Form} 
\label{sec:coercion-calculus}

In this section we review the coercions in normal form of
\citet{siek2012interpretations} to motivate the design of
hypercoercions.  We ignore sum types and product types in this
section, because \citet{siek2012interpretations} did not discuss
them. We assume a basic familiarity with coercions and direct readers
who are not familiar with them to \citet{siek2012interpretations}.
%We 
%will highlight the similarity of normal coercion and hypercoercion, and hope 
%this would convince you that hypercoercion should be as difficult to implement 
%as normal coercions.
%\todo[inline]{I don't think we should try to convince the reader that
%  hypercoercions are easier to implement. We don't have real evidence
%  for that.}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{I}{injectable types (\lazyD)}{
		\POOfun{T}{T}}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOfun{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{coercions}{
		\ncInj{I} \mid
		\ncProj{I}{l} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncSeq{c}{c} \mid
		\ncFun{c}{c}
	}
	\stxrule{\bar{c}}{wrapper coercions}{	
		\ncInj{I} \mid
		\ncFun{\hat{c}}{\hat{c}} \mid
		\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}
	}
%	\stxrulecont{
%		\ncProd{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncProd{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
%		\ncSum{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncSum{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid	
%	}
	\stxrule{\hat{c}}{normal coercions}{
		\bar{c} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncProj{I}{l} \mid
		\ncSeq{\ncProj{I}{l}}{\ncFail{l}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncInj{I}}
	}
	\stxrulecont{
		\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}}
	}
	\end{array}
	\]
	\caption{Syntax of Normal Coercion}
	\label{fig:normal-coercion}
\end{figure}

\todo[inline]{Give a summary statement about the shape of the normal form. 
-JS
\\---\\The three-part shape is not obvious before the transformation at 
the end of the next paragraph. So the summary is given after that. -KC}

\figref{fig:normal-coercion} defines the normal coercion.
Types, pre-types, and blame labels are as before.
Let $I$ range over injectable types. An injectable type is a type that can 
be cast directly to (injection) and from (projection) $\TOOdyn$. The 
definition of injectable type depends on blame strategy. With \lazyD, all 
pre-types are injectable. With \lazyUD, only $\POOfun{\TOOdyn}{\TOOdyn}$
is injectable. 
Let $c$ range over coercions, a coercion is either injection, projection, 
identity, failure, sequencing, or function coercion.
Let $\bar{c}$ range over wrapper coercions, which represent casts in $
\vOOcast{v}{c}$.
Let $\hat{c}$ range over normal coercions. If we inline $\bar{c}$ and 
re-order the cases, the definition of $\hat{c}$ becomes:
\[
\begin{array}{rclr}
\stxrule{\hat{c}}{normal coercions}{
	\ncFun{\hat{c}}{\hat{c}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
	\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
	\ncId \mid
	\ncProj{I}{l} \mid
	\ncInj{I} \mid
	\ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
	\ncFail{l} \mid
}
\end{array}
\]

Three observations on this definition leads to hypercoercion: 
\begin{enumerate}
	\item The length of normal coercion is at most three.
	\item Projections are always at the beginning when present.
	\item Injections and failures are always at the end when present.
\end{enumerate}


\section{Definition of Hypercoercion} \label{sec:hypercoercion-definition}

\begin{figure}
	Syntax
	\[
	\begin{array}{lclr}
	\stxrule{I}{injectable types (\lazyD)}{P}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\TOOdyn}{\TOOdyn} \mid
		\POOprod{\TOOdyn}{\TOOdyn} \mid
		\POOsum{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{hypercoercions}{
		\hyperCoercionI \mid{}
		\hyperCoercionC{h}{m}{t}
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{m}{middles}{
		\POOunit \mid
		\POOfun{c_1}{c_2} \mid
		\POOprod{c_1}{c_2} \mid
		\POOsum{c_1}{c_2}
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
		
	hypercoercion typing \fbox{$c : T \Longrightarrow T$}
	\begin{gather*}
	\inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
	\quad
	\inference{
		\typingHC{h}{T_1}{P_1} &
		\typingHC{m}{P_1}{P_2} &
		\typingHC{t}{P_2}{T_2}
	}{
		\typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
	}
	\end{gather*}
	
	Head typing \fbox{$\typingHC{h}{T}{P}$}
	\begin{gather*}
	\inference{}{\typingHC{\epsilon}{P}{P}}
	\quad
	\inference{}{\typingHC{?^l}{\TOOdyn}{I}}
	\end{gather*}
	
	Middle typing \fbox{$\typingHC{m}{T}{T}$}
	\begin{gather*}
	\inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
	\quad
	\inference{
		\typingHC{c_1}{T_3}{T_1} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
	}
	\\
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
	}
	\quad
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
	}
		\end{gather*}
		
		Tail typing \fbox{$\typingHC{t}{P}{T}$}
		\begin{gather*}
		\inference{}{\typingHC{\epsilon}{P}{P}} \quad
		\inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
		\inference{}{\typingHC{\bot^l}{P}{T}} \quad
		\end{gather*}
	
	\caption{Definition of hypercoercion (HC)}
	\label{fig:hypercoercion}
\end{figure}

This section presents our first contribution, the definition of hypercoercion. 
The design of hypercoercion is motivated by observations on coercion normal 
forms: a normal coercion has at most three parts; projections are always at the 
beginning; injections and failures are always at the end. Hypercoercions have 
similar shape: a hypercion either is $\hyperCoercionI$, the identity cast for 
$\TOOdyn$, or contains three parts, where the first part is either a 
projection or a no-op while last part is either an injection, a failure, or a 
no-op.

\figref{fig:hypercoercion} defines the syntax of hypercoercions. Types, 
pre-types, and blame labels are as before.

Let $c$ range over hypercoercions. A hypercoercion either is the identity 
cast between the dynamic types, or includes a head, a middle, and a tail. 
Let $h$ range over heads. A head is either a no-op, or a projection.
Let $m$ range over middles. There is a one-to-one 
correspondence between middles and type constructors. 
We generalize shallow-consistency to middles $m \smile m$ in the obvious way.
Let $t$ range over tails. A tail is either a no-op, an injection, or a 
failure.

Subsection~\ref{sec:ld-hc} defines functions that construct \lazyD\ 
hypercoercions. Subsection~\ref{sec:lud-hc} defines the \lazyUD\ counterparts. 
Functions that apply hypercoercions to values are deferred to 
Section~\ref{sec:hypercoercion-correctness} because they depends on a new 
definition of values, which is part of the framework in
Section~\ref{sec:framework}.

\subsection{\lazyD{} hypercoercion}
\label{sec:ld-hc}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{\ell}{Maybe$l$}{\epsilon \mid l}
	\end{array}
	\]
	
	Composition of hypercoercions \fbox{$c \fatsemi^\ell c = c$}
	\[ 
	\begin{array}{rclclr}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{}
	
	\comprulel{
		\hyperCoercionI
	}{
		\hyperCoercionC{\epsilon}{m}{t}
	}{
		\hyperCoercionC{?^{l}}{m}{t}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{
		c
	}{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{t}
	}{
		\hyperCoercionI
	}{
		\hyperCoercionC{h}{m}{!}
	}{
		\sidecond{\forall l. t \neq \bot^{l}}
	}
	
	\comprule{
		\hyperCoercionC{h_1}{m_1}{t_1}
	}{
		\hyperCoercionC{?^l}{m_2}{t_2}
	}{
		\hyperCoercionC{h_1}{m_1}{\bot^l}
	}{
		\sidecond{
			\neg \; m_1 \smile m_2
			\; \text{and} \;
			\forall l. t \neq \bot^{l}
		}
	}

\comprulel{
\hyperCoercionC{h_1}{m_1}{t_1}
}{
\hyperCoercionC{\epsilon}{m_2}{t_2}
}{
\hyperCoercionC{h_1}{m_1}{\bot^l}
}{
\sidecond{
	\neg \; m_1 \smile m_2
	\; \text{and} \;
	\forall l. t \neq \bot^{l}
}
}
\comprule{
\hyperCoercionC{h_1}{m_1}{t_1}
}{
\hyperCoercionC{?^l}{m_2}{t_2}
}{
\hyperCoercionC{h_1}{m_1 \fatsemi^{l} m_2}{t_2}
}{
\sidecond{
	m_1 \smile m_2
	\; \text{and} \;
	\forall l. t \neq \bot^{l}
}
}
	\comprule{
		\hyperCoercionC{h_1}{m_1}{t_1}
	}{
		\hyperCoercionC{\epsilon}{m_2}{t_2}
	}{
		\hyperCoercionC{h_1}{m_1 \fatsemi^{\ell} m_2}{t_2}
	}{
		\sidecond{
			m_1 \smile m_2
			\; \text{and} \;
			\forall l. t \neq \bot^{l}
		}
	}
%
%	\comprule{
%		\hyperCoercionC{h}{m_1}{t_1}
%	}{
%		\hyperCoercionC{\epsilon}{m_2}{t_2}
%	}{
%		\hyperCoercionC{h}{m'}{t'}
%	}{
%		\sidecond{
%			m_1 \fatsemi^{\ell} (m_2, t_2) = (m', t')
%			 \; \text{and} \;
%			 \forall l. t \neq \bot^{l}
%		}
%	}
%	
%	\comprule{
%		\hyperCoercionC{h}{m_1}{t_1}
%	}{
%		\hyperCoercionC{?^{l'}}{m_2}{t_2}
%	}{
%		\hyperCoercionC{h}{m'}{t'}
%	}{
%		\sidecond{
%			m_1 \fatsemi^{l'} (m_2, t_2) = (m', t')
%			\; \text{and} \;
%			\forall l. t \neq \bot^{l} 
%		}
%	}
	\end{array}
	\]
	
	Composition of middles \fbox{$m \fatsemi^\ell m = m$}
	\[ 
	\begin{array}{rclclr}
	\comprule{\POOunit}{\POOunit}{
		\POOunit
	}{}
	\comprule{\POOfun{c_1}{c_2}}{\POOfun{c_3}{c_4}}{
		\POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4}
	}{}
	\comprule{\POOprod{c_1}{c_2}}{\POOprod{c_3}{c_4}}{
		\POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4}
	}{}
	\comprule{\POOsum{c_1}{c_2}}{\POOsum{c_3}{c_4}}{
		\POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4}
	}{}
	\end{array}
	\]
	
	\fbox{$seq(c,c) = c$}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^\epsilon c_2
	}{}
	\end{array}
	\]
	
	\fbox{$id( P ) = m$}
	\[
	\begin{array}{rclr}
	\funrule{id(\POOunit)}{\POOunit}{}
	\funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
	}{}
	\end{array}
	\]
	
	\fbox{$id( T ) = c$}
	\[
	\begin{array}{rclr}
	\funrule{id(\star)}{
		\hyperCoercionI
	}{}
	\funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
	}{}
	\end{array}
	\]
	
	\fbox{$cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	\caption{\lazyD{} Hypercoercions}
	\label{fig:HC-D}
\end{figure}

\figref{fig:HC-D} defines functions that construct \lazyD{} hypercoercions. We 
expect language implementations to call $id(T)$, which constructs an 
identity, $seq(c,c)$, which composes two hypercoercions, and $
cast(T_1,l,T_2)$, which translate a cast to a hypercoercion. Other functions 
in the figure are their helpers.

Let $\ell$ range over $\epsilon$ and labels.
$ c_1 \fatsemi^\ell c_2$ composes hypercoercion $c_1$ and hypercoercion $c_2$.
When both $c_1$ and $c_2$ are $\hyperCoercionI$, their 
composition is also $\hyperCoercionI$.
When $c_1$ is $\hyperCoercionI$ but $c_2$ is not, the head of the 
composition must be a projection. In this 
case, if the head of $c_2$ is a projection, we reuse it. Otherwise, we need a 
label to build the projection. Since the head of $c_2$ is $\epsilon$, its 
source type must be a pretype. Thus we know $\ell$ must be a label and put it 
in the projection. 
When $c_1$ ends with a failure, the composition is $c_1$ itself. In all 
remaining cases, we shall assume that $c_1$ does not end with 
a failure.
When $m_1$ and $m_2$ have different top constructors ($\neg\;m_1 \smile 
m_2$), proceeding to $m_2$ can not make sense. So we end the composition 
with a failure. To do so we need a label. When $c_2$ starts with a 
projection, we shall accuse it of casting a value to a shallowly inconsistent 
type. When $c_2$ starts with a no-op, $\ell$ must be a label. And we accuse 
it of composing shallowly inconsistent hypercoercions. The last two cases 
compose $m_1$ and $m_2$ with a helper function $m \fatsemi^\ell m$, which 
assumes its inputs have the same top constructor. The definition of $m 
\fatsemi^\ell m$ is straightforward. Going back to the last two cases of $c_1 
\fatsemi^\ell c_2$. When $c_2$ starts with a projection, we have no clue 
whether the target type of $m_1$ is the same as the source of $m_2$, 
although we know they are shallowly consistent. So we give the $l$ in the 
projection to $m \fatsemi^\ell m$. When $c_2$ starts with a no-op, we reuse 
the $\ell$.

$seq(c_1,c_2)$ requires that the target type of $c_1$ is the same as the 
source of $c_2$. $c \fatsemi^\ell c$ does the job for it.
$id(T)$ constructs an identity coercion of $T$ with the help of $id(P)$. 
Their definitions are straightforward.
$cast(T_1,l,T_2)$ constructs a coercion from a source type, a label, and a 
target type. $c \fatsemi^\ell c$ does the most job.

\begin{proposition}[\lazyD\ hypercoercion is a monoid]
	\label{thm:hc-monoid}
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	By induction on hypercoercion(s).
\end{proof}

\begin{proposition}[]
	For all $T$ and $l$, $cast(T,l,T) = id(T) $
\end{proposition}
\begin{proof}
	By induction on T.
\end{proof}

\subsection{\lazyUD{} hypercoercion [Jeremy]}
\label{sec:lud-hc}

Figure~\ref{fig:HC-UD}

\begin{figure}
  Composition of hypercoercions \fbox{$c \fatsemi c = c$}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
       \hyperCoercionC{p_2}{m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{\epsilon} &\fatsemi& \hyperCoercionC{\epsilon}{m_2}{i_2} &=&
       \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{i_2} &=&
  \begin{cases}
    \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{p_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{p_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
     \hyperCoercionC{p_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$id( P ) = m$}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$id( T ) = c$}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
		\hyperCoercionI
    }{}
    \funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]

  
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}


Figure~\ref{fig:HC-UD-cast}


\begin{figure}
  \fbox{$\mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$\mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$\mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$\mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxilliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\begin{proposition}[\lazyUD\ hypercoercions form a monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}


\section{A framework for proving correctness of cast representations}
\label{sec:framework}

This section presents our second contribution, a framework for proving
correctness of cast representations. The next section will apply this
framework to prove the correctness of the \lazyD{} hypercoercions.

We start by defining a CEK machine \effCEK{C} that is parameterized
over the cast representation $C$. This machine is space efficient
provided that the cast representation performs compression.  The
interface between the machine and the cast representation is defined
by an abstract data type, named Cast ADT, that we define shortly.
%

\todo[inline]{UNDER CONSTRUCTION. -JS}

If $C$, an implementation of the Cast ADT inteface, satisifies a collection of 
properties that we defined as Lazy D Cast ADT. We can instantiate our framework 
theorem that we define shortly to prove that evaluating an program in 
\effCEK{C} gives the same result as \ineffCEKD. We are working on a
similar theorem for \lazyUD{}. 

\todo[inline]{UNDER CONSTRUCTION. -KC}



The framework is a theorem saying that for all cast representation $C
$, if $C$ satisfies a collection of properties, then it would
respect the Lazy D semantics of cast calculi. We are working on a
similar theorem for \lazyUD{}.

%then instantiating our parameterized space-efficient interpreter with$C$
%gives an interpter that is extensionally equal to the standard interpreter for 
%\lazyD\ cast calculus. 

We captures the set of operators that every cast representation must provide 
with \emph{cast abstract data type} (Definition~\ref{def:cast-rep}). 
The first three operators allow \effCEK{C} to construct casts. 
So we call them \textit{cast constructors}. And the forth and last operator 
allows \effCEK{C} to apply casts onto values. 

\begin{definition}[Cast Abstract Data Type (Cast ADT)]
	\label{def:cast-rep}
	A cast abstract data type is a set $Cast$, which is indexed by two types, 
	with four operators:
	\begin{description}
		\item[$id(T)$] constructs an cast from a type
%		, where $c : T 
%		\Longrightarrow T $
		\item[$seq(c_1,c_2)$] composes two casts
%		, where $
%		\judgeTypeFT{c_1}{T_1}{T_2}$, $\judgeTypeFT{c_2}{T_2}{T_3}$, and $
%		\judgeTypeFT{c}{T_1}{T_3} $
		\item[$cast(T_1,l,T_2)$] constructs a cast from $T_1$ to $T_2$
		\item[$ applyCast(v,c)=r$] applies a cast onto a value
	\end{description}
	We denote by $c : T_1 \Longrightarrow T_2$ to mean $c$ is in $Cast \; 
	T_1 \; T_2$. And we say ``$c$ is from $T_1$ to $T_2$''.
\end{definition}

Some instances of Cast ADT (or "some Cast" for short) are also 
\textit{monoids}. This definition is useful in the proof of 
our framework.

\begin{definition}[Monoid]
	A Cast is a monoid if 
	for all
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c_1) = c_1$,
		\item $seq(c_1,id(T_2)) = c_1$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{definition}

To use our framework, users needs to prove that their cast representation
implements Lazy D Cast ADT (Definition~\ref{def:surely-lazyd}), a subset of 
Cast ADT. Property (1) 
states that $id(T)$ acts like the identity function. Property (2) states 
that $seq(c,c)$ acts like a sequence of casts. Properties (3) through 
(11) state that $cast(T_1,l,T_2)$ act like the Lazy D $applyCast$
(Fig.~\ref{fig:applyCast-D-C}).

\todo[inline]{We might need to values before Lazy D Cast ADT. This will reduce 
the extreme height of Fig.~\ref{fig:machine-cekcc} as well. -KC}

\begin{definition}[Lazy D Cast ADT]
	\label{def:surely-lazyd}
	A  Cast is a Lazy D Cast if:
	\begin{enumerate}
		\item if $v : T$, then$applyCast(v,id(T)) = \mathtt{succ} \; v $
		\item if $\judgeType{v}{T_1}$,
		$ \judgeTypeFT{c_1}{T_1}{T_2}$, and
		$ \judgeTypeFT{c_2}{T_2}{T_3}$,\\
		then$applyCast(v,seq(c_1,c_2)) = 
		applyCast(v,c_1) >>= \lambda v.applyCast(v,c_2)$\\
		where 
		\[
		\begin{array}{rcl}
		\rOOsucc{v} >>= f & = & f(v) \\
		\rOOfail{l} >>= f & = & \rOOfail{l}
		\end{array}
		\]
		\item if $v : T_1$ and $\neg T_1 \smile T_2$,
		then$applyCast(v,cast(T_1, l, T_2)) = \rOOfail{l} $
		\item if $v : \star$, 
		then$applyCast(v,cast(\TOOdyn,l,\TOOdyn)) = \rOOsucc{v} $
		\item if $v : P_1$,
		then$applyCast(\hcvOOinj{P_1}{v},cast(\star,l,P_2)) 
		= applyCast(v,cast(P_1,l,P_2)) $
		\item if $v : P$,
		then$applyCast(v,cast(P,l,\star)) = \rOOsucc{(\hcvOOinj{P}{v})} $
		\item if $v : \POOunit$,
		then$applyCast(v,cast(\POOunit,l,\POOunit)) = \rOOsucc{v} $
		\item if $(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}) : \POOfun{T_1}{T_2}$,
		then\\
		$ 
		applyCast(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}, 
		cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4})) \\
		= 
		\rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\rho}{x}{b}{seq(c_2,cast(T_2,l,T_4))})}$
		\item if $(\hcvOOcons{v_1}{c_1}{v_2}{c_2}) : \POOprod{T_1}{T_2}$,
		then \\
		$ 
		applyCast(\hcvOOcons{v_1}{c_1}{v_2}{c_2},cast(\POOprod{T_1}{T_2},l,T_3 
		\times 
		T_4))$\\
		$ = 
		\rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
		$ 
		\item if $(\hcvOOinl{v}{c}) : \POOsum{T_1}{T_2}$,
		then \\
		$ 
		applyCast(\hcvOOinl{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
		= \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))})} $
		\item if $(\hcvOOinr{v}{c}) : \POOsum{T_1}{T_2}$,
		then \\$
		applyCast(\hcvOOinr{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
		= \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_2,l,T_4))})} $
	\end{enumerate}
\end{definition}

%Lazy D Cast ADT confines the behavior of operators so narrowly that it 
%effectively allows us to ``run'' programs without referring to an actual 
%representation of cast.

After showing their cast representation is a Lazy D Cast, users of our 
frameworks can plug-in this cast representation to our space-efficient abstract 
machine in subsection~\ref{ssec:framework:cek}, and prove that this machine is 
equivalent to \ineffCEKD\ (subsection~\ref{secc:framework:all-correct}), which 
depends on lemmas in subsection~\ref{secc:framework:monoid-correct}.

\subsection{A Space-efficient CEK machine}
\label{sec:framework:cek}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	
	\stxrule{v}{values}{
		\hcvOOtt \mid
		\hcvOOfun{c}{\rho}{x}{e}{c} \mid
		\hcvOOcons{v}{c}{v}{c}
	}
	\stxrulecont{
		\hcvOOinl{v}{c} \mid
		\hcvOOinr{v}{c} \mid
		\hcvOOinj{P}{v}
	}
%	\stxrule{r}{cast results}{
%		\rOOsucc{v} \mid
%		\rOOfail{l}
%	}
%	\stxrule{s}{states}{
%		\sOOinspect{e}{\rho}{\kappa} \mid{}
%		\sOOreturn{v}{\kappa} \mid{}
%		\sOOhalt{o}
%	}
	\stxrule{\kappa}{continuation}{
		\kOOcast{c}{k}
	}
	\stxrule{k}{pre-continuations}{
		\kOOmt \mid{}
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa} \mid
		\kOOinr{\kappa}
	}
	\stxrulecont{
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa} \mid
		\kOOcdr{\kappa}
	}
	\stxrulecont{
		\kOOcaseI{e}{e}{\rho}{\kappa} \mid
		\kOOcaseII{v}{e}{\rho}{\kappa} \mid
		\kOOcaseIII{v}{v}{\kappa}
	}
	\end{array}
	\]
	
	Build continuation \fbox{$wrap(k) = \kappa$}
	\[
	\begin{array}{rclc}
	\funrule{wrap(k)}{\kOOcast{id(T_1)}{k}}{
		\sidecond{k : T_1 \Longrightarrow T_2}}
	\end{array}
	\]
	
	Extend continuation \fbox{$ext(c,\kappa) = \kappa$}
	\[
	\begin{array}{rclc}
	\funrule{ext(c_1,\kOOcast{c_2}{k})}{
		\kOOcast{seq(c_1,c_2)}{k}
	}{}
	\end{array}
	\]
	
	Reduction \fbox{$\judgeSreduce{C}{s}{s}$}
	\[
	\begin{array}{rclr}
	\hiredruleS{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
	}{}
	\redruleS{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho(x)}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\hcvOOtt}{\kappa}
	}{}
	\hiredruleS{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{E}{}
	}{}
	\redruleS{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{wrap(\kOOinl{\kappa})}
	}{}
	\redruleS{
		\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{wrap(\kOOinr{\kappa})}
	}{}
	\redruleS{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{wrap(\kOOappI{E}{e_2}{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
		\sOOinspect{e}{\rho}{wrap(\kOOcar{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
		\sOOinspect{e}{\rho}{wrap(\kOOcdr{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
		\sOOinspect{e_1}{\rho}{wrap(\kOOcaseI{\rho}{e_2}{e_3}{\kappa})}}{}
	\hiredruleS{
		\sOOreturn{v}{\kOOcast{c}{k}}
	}{
	\begin{cases}
	\continue{k}{v'} & \sidecond{applyCast(v,c) = \rOOsucc{v'}} 
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
	\end{cases}
	}{}
%\redruleS{
%	\sOOreturn{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
%	\sOOinspect{e_2}{\rho}{wrap(\kOOconsII{v_1}{\kappa})}}{}
%
%\redrule{
%\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
%\sOOreturn{(\hcvOOcons{v_1}{id(T_1)}{v_2}{id(T_2)})}{\kappa}}{
%\\&&
%\sidecond{v_1 : T_1 \wedge v_2 : T_2}}
%
%\redrule{
%\sOOreturn{v}{(\kOOinl{\kappa})}}{
%\sOOreturn{(\hcvOOinl{v}{id(T)})}{\kappa}}{
%\\&&
%\sidecond{v : T}}
%
%\redrule{
%\sOOreturn{v}{(\kOOinr{\kappa})}}{
%\sOOreturn{(\hcvOOinr{v}{id(T)})}{\kappa}}{
%\\&&
%\sidecond{v : T}}
%
%\redrule{
%\sOOreturn{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
%\sOOinspect{e_2}{\rho}{wrap(\kOOappII{v_1}{\kappa})}}{}
%
%	
%	& \vdots \\
%	\redruleS{
%		\sOOinspect{(\eOOlam{T_1}{T_2}{x}{e})}{\rho}{\kappa}
%	}{
%		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
%	}{}
%	\redruleS{
%		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
%	}{
%		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
%	}{}
%	\redruleS{
%		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
%	}{
%		\sOOinspect{e_1}{\rho}{wrap(\hckOOconsI{e_2}{\rho}{\kappa})}
%	}{}
%	\redruleS{
%		
%\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
%	}{
%		\begin{cases}
%		\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)} \\
%		\;\;\;\;\;\;\;\;\;\sidecond{applyCast(v,c_1) = \rOOsucc{v'}} 
%		\\
%		\sOOhalt{(\oOOblame{l})} \\
%		\;\;\;\;\;\;\;\;\;\sidecond{applyCast(v,c_1) = \rOOfail{l}}
%		\end{cases}
%		
%	}{}
	\end{array}
	\]
	
	Apply continuation
	\fbox{$continue(k,v) = s$}
	\[
	\begin{array}{rclr}
	

\funrule{
	\continue{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
	\sOOinspect{e_2}{\rho}{wrap(\kOOconsII{v_1}{\kappa})}}{}

\hifunrule{
	\continue{v_2}{(\kOOconsII{v_1}{\kappa})}}{
	\sOOreturn{(\hcvOOcons{v_1}{id(T_1)}{v_2}{id(T_2)})}{\kappa}}{}

\hifunrule{
	\continue{v}{(\kOOinl{\kappa})}}{
	\sOOreturn{(\hcvOOinl{v}{id(T)})}{\kappa}}{}

\hifunrule{
	\continue{v}{(\kOOinr{\kappa})}}{
	\sOOreturn{(\hcvOOinr{v}{id(T)})}{\kappa}}{}

\funrule{
	\continue{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
	\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

%\funrule{
%	\continue{v_2}{(\kOOappII{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{\kappa})}}{
%applyCast(v_2,c_1) >>= \lambda v. \sOOinspect{e}{\rho[x:=v]}{ext(c,\kappa)}
%}{}

\hifunrule{
	\continue{v_2}{(\kOOappII{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{\kappa})}}{
\begin{cases}
	\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)} \\
\;\;\;\;\;\sidecond{applyCast(v_2,c_1) = \rOOsucc{v'}}
\\
\sOOhalt{l} \\
\;\;\;\;\;\sidecond{applyCast(v_2,c_1) = \rOOfail{l}}
\end{cases}
}{}

\hifunrule{
	\continue{\hcvOOcons{v_1}{c_1}{v_2}{c_2}}{
		\kOOcar{\kappa}
	}
}{
	\sOOreturn{v_1}{ext(c_1,k)}
}{}
\hifunrule{
	\continue{\hcvOOcons{v_1}{c_1}{v_2}{c_2}}{
		\kOOcdr{\kappa}
	}
}{
	\sOOreturn{v_2}{ext(c_2,k)}
}{}

\funrule{
	\continue{v_1}{\kOOcaseI{e_2}{e_3}{\rho}{\kappa}}
}{
	\sOOinspect{e_2}{\rho}{
		wrap(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})
	}
}{}

\funrule{
	\continue{v_2}{
		\kOOcaseII{v_1}{e_3}{\rho}{\kappa}
	}
}{
	\sOOinspect{e_3}{\rho}{
	\kOOcaseIII{v_1}{v_2}{\kappa}
	}
}{}

\hifunrule{
	\continue{v_3}{(\mathtt{case_3}\;(\hcvOOinl{v}{c})\;
		(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})
		\;\kappa)}
}{
	\sOOreturn{v}{wrap(\kOOappII{(\hcvOOfun{seq(c,c_1)}{\rho}{x}{e}{c_2})}{\kappa})}
}{}

\hifunrule{
	\continue{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}
	{(\mathtt{case_3}\;(\hcvOOinr{v}{c})\;v_2\;\kappa)}
}{
	\sOOreturn{v}{wrap(\kOOappII{(\hcvOOfun{seq(c,c_1)}{\rho}{x}{e}{c_2})}{\kappa})}
}{}

\funrule{
	\continue{v}{\kOOmt}}{
	\sOOhalt{observe(v)}}{}
	
	\end{array}\]
	
%	Transitive closure of reduction \fbox{$s \longrightarrow_{S(C)}^{*} s$}
%	\[\dots\]
	
%	Evaluation \fbox{$\judgeSeval{C}{e}{o}$}
%	\[
%	\inference{
%		\judgeSreduceTrans{C}{
%			\sOOinspect{e}{\emptyset}{wrap(\hckOOmt)}
%		}{
%			\sOOhalt{o}
%		}		
%	}{
%		\judgeSeval{C}{e}{o}
%	}
%	\]
	
	\caption{Space-efficient CEK machine$\mathcal{S}(C)$}
	\label{fig:machine-cekcc}
\end{figure}
\figref{fig:machine-cekcc} defines \effCEK{C}, a space-efficient
CEK machine.  This machine is similar to \ineffCEK{}.
The keys differences are in values and continuations.

Let $v$ range over value. 
In \ineffCEK\, we have one value constructor for all casted value.
In \effCEK{C}, however, we do not have this generic value constructor, 
instead we push those casts into the ordinary values. For 
instance, $(\vOOcons{v_1}{v_2})$ corresponds to 
$(\hcvOOcons{v_1'}{id(T_1)}{v_2'}{id(T_2)})$. To construct values of the 
dynamic type, we use $(\hcvOOinj{P}{v})$.

Cast results ($r$) and machine states ($s$) are as before. 

Let $\kappa$ range over continuations and Let $k$ range over 
pre-continuations. 
A continuation is now a pre-continuation prefixed with a cast.
Pre-continuation are like the continuations in \ineffCEK, but there is no 
constructor for casts.
Continuations in \ineffCEKD\ have zero or more casts at the top.
In \effCEK{C}, however, every continuation has exactly one cast at the top.
Continuations in \ineffCEK\ that have no casts at the top correspond to 
continuations in \effCEK{C}\ whose casts are identity.
And continuations in \ineffCEK\ that have many casts at the top correspond to 
continuations in \effCEK{C}\ where those casts are composed by $seq(c,c)$.

\todoKC{describe transition rules}
We list a fraction of reduction rules due to space limitation.
\todo[inline]{Don't omit reduction rules, instead put some in the appendix. -JS
\\---\\They are all in the figure. I haven't updated this paragraph 
accordingly. -KC}


%When evaluating a cast expression, the machine moves the cast to the
%continuation and evaluates the inner expression.
%To apply a casted function, the machine first casts $v_1$, the
%operand, then applies the casted operand to $v_2$, the underlying
%function, and finally cast the result of the function application.
%%
%To take out the first (resp. second) part of a casted pair, the
%machine firstly take out the first (resp. second) part of $v$, the
%underlying pair, and cast the result.
%%
%%In case splitting, if the target value is a left injection, the
%%machine moves to a state that will apply the first continuation
%%function to the value inside the left injection. The case for right
%%injection is similar.
%%
%When the target value is a casted sum, the machine moves the cast from
%the target value to continuations functions.
%%
%To cast a value, the machine invokes $applyCast$ on the value.  If the
%cast succeeds, the machine returns the result to the next
%continuation.  If the cast fails, the machine halts with the blame
%label.

The transition relation $\judgeSreduce{C}{s}{s}$ uses functions provides by $C$ 
to represent cases and to apply casts.
%
When evaluating a cast expression, the machine extends the continuation with 
cast $cast(T_1,l,T_2)$. The function $ext(c,\kappa)$ composes $c$ with the cast 
at the top of $k$ by calling $seq$.
%
To construct a function, the machine fills the casts $id$.
%
To return a value to a continuation, the machine first applies the top cast to 
the value. If the application fails, the machine halts with the blame label 
from the failure. Otherwise, the machine handles the pre-continuation with 
$continue$.
%
When the machine constructs a pair, a left injection, or a right injection, it 
fills the casts with $id$ as well, just like how it did for functions. 
%
To apply a function, the machine applies the domain cast $c_1$ to the 
operand $v_2$, extends the continuation with the codomain cast $c_2$, and 
evaluate the function body.
%
To take out the first (resp. second) part of a pair ...
%
%%In case splitting, if the target value is a left injection, the
%%machine moves to a state that will apply the first continuation
%%function to the value inside the left injection. The case for right
%%injection is similar.
%%
%When the target value is a casted sum, the machine moves the cast from
%the target value to continuations functions.
To case spliting a variant, ...

%When values are constructed, their hypercoercion parts are filled with outputs 
%of $id$. For instance, when a function value is constructed, its first part 
%and last part are initialized to $id(T_1)$ and $id(T_2)$respectively.
%When evaluating a cast expression, the current continuation is extended with a 
%hypercoercion constructed by $cast$. $ext$ composes the new hypercoercion 
%with the hypercoercion on the top of the continuation.
%When evaluating a compound expression, the machine firstly construct the new 
%pre-continuation, then turn it to a continuation by adding an identity 
%hypercoercion at the top. For instance, when evaluating a \texttt{cons} 
%expression, the machine firstly construct $\hckOOconsI{e_2}{\rho}{\kappa}$, 
%the new pre-continuation, then call $cont$, which adds an identity cast to 
%form a continuation. 
%When a function call happens, the machine firstly cast the operand. If the 
%casting succeeds, the machine then evaluate the body in the extended 
%environment and the extended continuation. If the casting fails, the machine 
%then halts with the blame label.

Transitive closure of reduction ($\judgeSreduceTrans{C}{s}{s}$) and 
evaluation ($\judgeSeval{C}{e}{o}$) are standard. Value typing 
($\judgeType{v}{T}$) is straightforward.

\subsection{Relating Some \effCEK{C} to \ineffCEKD}
\label{secc:framework:monoid-correct}

In this subsection, we prove that if a instance of Cast ADT $C$ is Lazy D and 
is a monoid, then $eval_\mathcal{D} = eval_{\mathcal{S}(C)}$. We proof this 
theorem with a weak bisimulation between \effCEK{C} and \ineffCEKD.

Fig.~\ref{fig:bisim-SC-D} defines the bisimulation relation. Here we omit rules 
that make the relation a congruence.
%
The relation $\kappa \approx \kappa$ relates two continuations. 
%
If $k \approx \kappa$, adding an identity cast on top of $k$ gives a related 
continuation. 
%
If $\kappa_1 \approx \kappa_2$, extending $\kappa_1$ and $\kappa_2$ with the 
same cast gives related results.
%
%
The relation $v \approx v : T$ relates two value and also report their type. We 
will see shortly why reporting the type. 
%
If two values of type $P$ are related, injecting them to $\TOOdyn$ gives 
related values.
%
Unit values are of course related.
%
To relate to a non-casted function in \ineffCEKD, the casts in the \effCEK{C} 
function must be identity.
%
If functions are related, we can apply the same cast on both side.


\todo[inline]{In Fig.~\ref{fig:bisim-SC-D}, how to suppress rule numbers like 
(1), (2), etc.? -KC}
\begin{figure}
%	\fbox{$\text{\effCEK{C}} \approx \text{\ineffCEKD}$}
	\[\dots\]
	
	\fbox{$\kappa \approx \kappa$}
	\begin{gather*}
	\inference{
		k \approx \kappa
	}{
		wrap(k) \approx \kappa
	}
	\quad
	\inference{
		\kappa_1 \approx \kappa_2
	}{
		ext(cast(T_1,l,T_2),\kappa_1) \approx 
		\kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa_2}
	}
\\
	\end{gather*}
\\	
	\fbox{$v \approx v : T$}
	\begin{gather}
	\inference{
		v_1 \approx v_2 : P
	}{
		\hcvOOinj{P}{v_1} \approx \vOOcast{v_2}{\cOOcast{P}{l}{\TOOdyn}}
		: \TOOdyn
	}
\\ \\
	\inference{}{
		\hcvOOtt \approx \vOOtt : \POOunit
	}
	\quad
	\inference{}{
		\hcvOOtt \approx \vOOcast{\vOOtt}{\cOOcast{\POOunit}{l}{\POOunit}}
		: \POOunit
	}
	\\ \\
	\inference{
		\rho_1 \approx \rho_2 &
		dom(\rho_1) = dom(\rho_2) = \Gamma \\
		\Gamma , x : T_1 \vdash e : T_2
	}{
		\hcvOOfun{id(T_1)}{\rho_1}{x}{e}{id(T_2)}
		\approx
		\vOOfun{\rho_2}{x}{e}
		: \POOfun{T_1}{T_2}
	}
\\ \\
\inference{
\hcvOOfun{c_1}{\rho}{x}{e}{c_2} \approx v_2 : \POOfun{T_1}{T_2} \\
%		\judgeType{\hcvOOfun{c_1}{\rho}{x}{e}{c_2}}{\POOfun{T_1}{T_2}} \\
c_1' = seq(cast(T_3,l,T_1),c_1) \\
c_2' = seq(c_2,cast(T_2,l,T_4))
}{
\hcvOOfun{c_1'}{\rho}{x}{e}{c_2'}
\approx
\vOOcast{v}{\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}}
: \POOfun{T_3}{T_4}
}
\\ \\
	\inference{
		v_1 \approx v_2 : T_1 &
		v_3 \approx v_4 : T_2 &
	}{
		\hcvOOcons{v_1}{id(T_1)}{v_3}{id(T_2)}
		\approx
		\vOOcons{v_2}{v_3}
		: \POOprod{T_1}{T_2}
	}
\\ \\
	\inference{
		\hcvOOcons{v_1}{c_1}{v_3}{c_2} \approx v_2 : \POOsum{T_1}{T_2} \\
		c_1' = seq(c_1,cast(T_1,l,T_3)) \\
		c_2' = seq(c_2,cast(T_2,l,T_4))
	}{
		\hcvOOcons{v_1}{c_1'}{v_3}{c_2'} \approx
		\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{\POOprod{T_3}{T_4}}}
		: \POOprod{T_3}{T_4}
	}
\\ \\
	\inference{
		v_1 \approx v_2 : T
	}{
		\hcvOOinl{v_1}{id(T)} \approx \vOOinl{v_2}
		: \POOsum{T}{T'}
	}
	\quad
	\inference{
		\hcvOOinl{v_1}{c} \approx v_2
		: \POOsum{T_1}{T_2} &
		c' = seq(c,cast(T_1,l,T_3))
	}{
		\hcvOOinl{v_1}{c'} \approx
		\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
		: \POOsum{T}{T'}	
	}
	\\
	\inference{
	v_1 \approx v_2 : T
	}{
	\hcvOOinr{v_1}{id(T)} \approx \vOOinr{v_2}
	: \POOsum{T'}{T}
	}
	\quad
	\inference{
	\hcvOOinr{v_1}{c} \approx v_2
	: \POOsum{T_1}{T_2} &
	c' = seq(c,cast(T_2,l,T_4))
	}{
	\hcvOOinr{v_1}{c'} \approx
	\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
	: \POOsum{T'}{T}
	}
	\end{gather}
	\caption{Bisimulation between \effCEK{C} and \ineffCEKD}
	\label{fig:bisim-SC-D}
\end{figure}

Before proving the weak bisimulation between \effCEK{C} and \ineffCEKD, we 
introduce one more definition: $s_1 \approx^{*} s_2$ if and only if there 
exists $s_2' \in \text{\ineffCEKD}$
such that $\judgeCreduceTrans{s_2}{s_2'}$ and $s_1 \approx s_2'$.

\todo[inline]{Standardize theorem statement -KC}
\begin{lemma}[Weak Bisimulation between \effCEK{C} and \ineffCEKD]
	\label{thm:surely-monoidic-reduce}
	For all instance of Cast ADT $C$, 
	if $C$ is \lazyD{} and is a monoid and $cast(T,l,T)=id(T)$,
	$ s_{1}, s_{1}' \in \text{\effCEK{C}}$,
	$ s_{2}, s_{2}' \in \text{\ineffCEKD}$,
	$ s_{1} \approx s_{2}$,
	$ \judgeSreduce{C}{s_{1}}{s_{1}'}$, and
	$ \judgeDreduce{s_{2}}{s_{2}'}$, then
%	then there exist$s_2'' \in \text{\ineffCEKD}$such that
	\[ \exists s_2'' \in \text{\ineffCEKD}: \;
	\judgeDreduceTrans{s_{2}'}{s_{2}''} \;\text{and}\; s_1' \approx s_2'' \]
%	\begin{enumerate}
%		\item if $\judgeDreduce{s_1}{s_3}$,
%		then
%		there exist$s_5 \in \text{\ineffCEKD}$, $s_4 \in \mathcal{S}(C)$,
%		such that \begin{itemize}
%			\item$s_5 \approx s_4$, and
%			\item$\judgeSreduce{C}{s_2}{s_4}$,
%			\item$\judgeDreduceTrans{s_3}{s_5} $
%		\end{itemize}
%		\item if $\judgeSreduce{C}{s_2}{s_4}$,
%		then
%		there exist$s_3 \in \mathcal{C}$,
%		such that \begin{itemize}
%			\item$s_3 \approx s_4 $
%			\item$\judgeDreduceTrans{s_1}{s_3} $
%		\end{itemize}
%	\end{enumerate}

Or diagrammatically, 
\[\begin{array}{clclc}
s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
\rotatebox[origin=c]{90}{$\approx$} 
& & & \;\;\;\rotatebox[origin=c]{-20}{$\approx$} \\
s_{2} & 
\longrightarrow_{\text{\ineffCEKD}} & s_2' &
\longrightarrow^{*}_{\text{\ineffCEKD}} & s_2'' \\
\end{array}\]

\end{lemma}
\begin{proof}
	By following the transition rule of \ineffCEKD. See the supplementary 
	materials for details.
\end{proof}

\todo[inline]{An extra property is required after changing case to small-step 
-KC}
\begin{proposition}[Correctness of \effCEK{C}]
	\label{thm:surely-monoidic-eval}
	if $\judgetype{\emptyset}{e}{T}$ and $o : T$ and $C$ is a 
	\lazyD{} Cast ADT and a monoid,
	\[
	\text{\evalEqv{\effCEK{C}}{\ineffCEKD}}
	\]
\end{proposition}
\begin{proof}Proving left implies right is trivial.
To prove $\judgeDeval{e}{o}$ implies $\judgeSeval{C}{e}{o}$, 
we firstly take one steps in \effCEK{C}, and catch it up in \ineffCEKD\ by 
taking one or more steps in \ineffCEKD. As we just took a positive number of 
steps, we are closer to the halting state.
\end{proof}

\subsection{\lazyD\ Cast ADT Respect \ineffCEKD}
\label{secc:framework:all-correct}

In this subsection, we prove that for all $C$, if $C$ is a Lazy D Cast ADT, 
then \evalEqv{\ineffCEKD}{\effCEK{C}}. We first 
prove that all $S(C)$ where $C$ is a Lazy D Cast ADT are equivalent, then 
connect this theorem to Lemma~\ref{thm:surely-monoidic-eval}.

We prove the equivalence among \effCEK{S(C)} with strong bisimulation. This 
time almost all the bisimulation relations are all derived from definitions 
except the relaton for casts, which is by cast constructors:
\begin{gather*}
\inference{
}{
	cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
	id_1(T) \approx id_2(T)
}
\quad
\inference{
	c_1 \approx c_2 &
	c_3 \approx c_4
}{
	seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\todo[inline]{Standardize theorem statement -KC}
\begin{lemma}[Strong Bisimulation among $\mathcal{S}(\cdot)$]
	\label{thm:CEKS-bisim}
	If 
	$C_1$ and $C_2$ are instances of Lazy D Cast ADT,
	$s_1, s_1' \in S(C_1)$ and $s_2,s_2' \in S(C_2)$,
	$s_1 \approx s_2$,
	$\judgeSreduce{C_1}{s_1}{s_1'}$, and
	$\judgeSreduce{C_2}{s_2}{s_2'}$, then 
	$s_1' \approx s_2'$
	
	Or diagrammatically, 
	\[\begin{array}{clc}
	s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
	\rotatebox[origin=c]{90}{$\approx$} 
	& & \rotatebox[origin=c]{90}{$\approx$} \\
	s_{2} & 
	\longrightarrow_{\text{\ineffCEKD}} & s_2' \\
	\end{array}\]
\end{lemma}
\begin{proof} 
	This proof is effectively a duplication of the transition rule of 
	\effCEK{S(C)}.
	The key ideas of this proof are undoing sequencing with the property (2) of 
	Lazy D Cast ADT, and handling all possibly uses of $
	cast(T,l,T)$ with property (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of \lazyD{} Cast ADT]
	\label{thm:surely-lazyD-eqv}
	if $\judgetype{\emptyset}{e}{T}$, $o : T$, and $C_1$ and $C_2$
	are \lazyD\ Cast ADTs,
	\[
	eval_{S(C_1)} = eval_{S(C_2)}
	\]
\end{proposition}
\begin{proof}
	By induction with the help of Lemma~\ref{thm:CEKS-bisim}.
\end{proof}

\begin{theorem}[\lazyD\ Cast ADT Respects \ineffCEKD]
	\label{thm:surely-lazyD-correct}
	if $\judgetype{\emptyset}{e}{T}$ and $o : T$ and $C$ is a 
	\lazyD{} Cast ADT.
	\[
	\text{\evalEqv{\ineffCEKD}{\effCEK{C}}}
	\]
\end{theorem}
\begin{proof}
	If we have a Lazy D Cast ADT and it is a monoid, this 
	proof is immediately from Lemma~\ref{thm:surely-monoidic-eval} and 
	Proposition~\ref{thm:surely-lazyD-eqv}. One such representation is to 
	represent casts as a list of triples of type, label, and type, where 
	$id(T)$ is the empty list and $seq(c,c)$ is the list append. Another such 
	representation is the \lazyD\ hypercoercion!
\end{proof}


\section{Correctness Proof of \lazyD{} hypercoercions}
\label{sec:hypercoercion-correctness}

In this section we prove \lazyD\ hypercoercion is 
correct. First we define$applyCast(v,c)$ to make it an instance of Cast ADT, 
then prove that it is also Lazy D, and finally apply 
Theorem~\ref{thm:surely-lazyD-correct} to finish the proof.

\figref{hc-applyCast} defines$applyCast(v,c)$for \lazyD\ hypercoercion. 
Applying the identity cast for the 
dynamic type succeeds immediately. When applying a compound cast, we firstly 
apply the middle, then apply the tail. We denote by $r \; >>= \; f$ to mean 
that if $r$ is $\rOOsucc{v}$, the result is $f(v)$, otherwise the result 
is the failure.
$ applyMiddle(v,\ell,m)$ and $applyTail(v,t)$ are straightforward.
In the definition of $applyMiddle(v,\ell,m)$, we generalize 
shallow-consistency to compare middles and values ($v \smile m$) in the 
natural way.

\begin{figure}
	\fbox{$applyCast(v,c) = r$}
	\[
	\begin{array}{rclr}
	\funrule{applyCast(v,\hyperCoercionI,)}{\rOOsucc{v}}{}
	\funrule{applyCast(\hcvOOinj{P}{v},\hyperCoercionC{?^l}{m}{t})}{
		applyMiddle(v,l,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\funrule{applyCast(v,\hyperCoercionC{\epsilon}{m}{t})}{
		applyMiddle(v,\epsilon,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\end{array}
	\]
	
	\fbox{$applyMiddle(v,\ell,m) = r$}
	\[
	\begin{array}{rclr}
	\funrule{applyMiddle(\hcvOOtt,\ell,\POOunit)}{\rOOsucc{\hcvOOtt}}{}
	\funrule{applyMiddle(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}\ell,\POOfun{c_3}{c_4})}{
		\rOOsucc{(\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\rho}{x}{e}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOcons{v_1}{c_1}{v_2}{c_2},\ell,\POOprod{c_3}{c_4})}{
		\rOOsucc{(\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOinl{v}{c_1},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)})}
	}{}
	\funrule{applyMiddle(\hcvOOinr{v}{c_2},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(v,l,m)}{
		\rOOfail{l}
	}{
		\sidecond{\neg v \smile m}
	}
	\end{array}
	\]
	
	\fbox{$applyTail(v,t) = r$}
	\[
	\begin{array}{rclr}
	\funrule{applyTail(v,\bot^l)}{\rOOfail{l}}{}
	\funrule{applyTail(v,\epsilon)}{\rOOsucc{v}}{}
	\funrule{applyTail(v,!)}{\rOOsucc{(\hcvOOinj{P}{v})}}{}
	\end{array}
	\]
	\caption{\lazyD\ hypercoercion's $applyCast$}
	\label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} hypercoercion is a \lazyD Cast ADT]
	\label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof} See the supplementary material. \end{proof}

\begin{theorem}[\lazyD{} hypercoercion Respect \ineffCEKD]
	if $\judgetype{\emptyset}{e}{T}$ and $o : T$
	\[
	\text{\evalEqv{\ineffCEKD}{\effCEK{H}}}
	\]
\end{theorem}
\begin{proof}
	Immediately from Theorem~\ref{thm:surely-lazyD-correct} and 
	Lemma~\ref{thm:hc-surely-lazyD}.
	Alternatively, from Lemma~\ref{thm:surely-monoidic-eval},
	Lemma~\ref{thm:hc-surely-lazyD}, and 
	Proposition~\ref{thm:hc-monoid}.
\end{proof}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile,all}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots


\end{document}
