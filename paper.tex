%% For double-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{Lazy\;UD}
\newcommand{\lazyD}{Lazy\;D}
\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}
\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{#1 \; #2}
\newcommand{\eOOcons}[2]{\mathtt{cons} \; #1 \; #2}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{#1 \langle \cOOcast{#2}{#3}{#4} \rangle}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\cOOcast}[3]{#1 \overset{#2}{\Rightarrow} #3}
\newcommand{\oOOinj}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\vOOcast}[2]{#1\langle#2\rangle}
\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}
\newcommand{\kOOmt}[0]{\mathtt{stop}}
\newcommand{\kOOconsI}[3]{\mathtt{cons_1} \; #1 \; #2 \; #3}
\newcommand{\kOOconsII}[2]{\mathtt{cons_2} \; #1 \; #2}
\newcommand{\kOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\kOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\kOOappI}[3]{
	\mathtt{app_1} \; #1 \; #2 \; #3
}
\newcommand{\kOOappII}[2]{
	\mathtt{app_2} \; #1 \; #2}
\newcommand{\kOOcar}[1]{
	\mathtt{fst} \; #1}
\newcommand{\kOOcdr}[1]{
	\mathtt{snd} \; #1}
\newcommand{\kOOcaseI}[4]{
	\mathtt{case_1} \; #1 \; #2 \; #3 \; #4}
\newcommand{\kOOcaseII}[4]{
	\mathtt{case_2} \; #1 \; #2 \; #3 \; #4}
\newcommand{\kOOcaseIII}[3]{
	\mathtt{case_3} \; #1 \; #2 \; #3}
\newcommand{\kOOcast}[2]{
	\langle #1 \rangle #2}
\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{inj} \; #2}
\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D cast calculus on space-inefficient CEK
\newcommand{\judgeCreduce}[2]{#1 \longmapsto_{\mathcal{C}} #2}
\newcommand{\judgeCreduceTrans}[2]{#1 \longmapsto_{\mathcal{C}}^{*} #2}
\newcommand{\judgeCeval}[2]{eval_{\mathcal{C}}(#1) = #2}
\newcommand{\redrule}[3]{#1 & \longmapsto_\mathcal{C} & #2 & #3\\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longmapsto_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longmapsto_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{eval_{\mathcal{S}(#1)}(#2) = #3}
\newcommand{\redruleS}[3]{#1 & \longmapsto_{\mathcal{S}(C)} & #2 & #3\\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hypercoercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvSD}[3]{#2 \approx_{\mathcal{SD}} #3}
% to-dos
\newcommand{\todoKC}[1]{\todo[inline]{KC needs to #1}}
\newcommand{\todoKCFixed}[0]{\todo[inline]{Fixed. -KC}}
% abbrev
\newcommand{\castCalculus}[0]{$\lambda_{\rightarrow}^{\langle\cdot\rangle}$}
% names
\newcommand{\ineffCEK}{$ \mathcal{C} $}
\newcommand{\ineffCEKD}{$ \mathcal{D} $}
\newcommand{\ineffCEKUD}{$ \mathcal{UD} $}
\newcommand{\judgeDreduce}[2]{#1 \longmapsto_{\mathcal{D}} #2}
\newcommand{\judgeDreduceTrans}[2]{#1 \longmapsto_{\mathcal{D}}^{*} #2}
\newcommand{\judgeDeval}[2]{eval_{\mathcal{D}}(#1) = #2}
\newcommand{\effCEK}[1]{$ \mathcal{S}(#1) $}
\newcommand{\evalEqv}[2]{$ eval_{\text{#1}} = eval_{\text{#2}} $}

\begin{document}

%% Title information
\title{Hypercoercions and a Framework for Equivalence of Cast Calculi}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
	Designing a space-efficient cast representation that is good for both 
	mechanized metatheory and implementation is challenging. Existing solution 
	solutions have various strengths and weaknesses. We presents a new cast 
	representation, named hypercoercions, that is good for both. On our way to 
	prove the correctness of hypercoercions, we also step toward a framework 
	for proving correctness of cast representations.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\listoftodos{}


\section{Introduction}

\todo[inline]{I see lots of mistakes regarding when to make words
  plural (whether they should have an ``s'' at the end). Please review
  the rules of English regarding plurals. The rules are tricky...
  some words don't have a plural form, like ``blame''. -JS
  \\---\\
  Will fix grammar after fixing all other problems -KC}

Around 2006, several groups of researchers proposed ways to integrate
dynamic typing and static typing, notably gradual typing
\citep{siek2006gradual}, hybrid typing \citep{flanagan2006hybrid},
migratory typing \citep{Tobin-Hochstadt:2006fk}, and multi-language
iteroperability \citep{Gray:2005ij,Matthews:2007zr}. Researchers
usually define the semantics of gradually typed languages by
translation to an intermediate language with casts, such as the blame
calculus \citep{wadler2009well} and other cast calculi
\citep{siek2009exploring}. Unfortunately, straightforward
implementations of casts on higher-order values (functions, objects,
etc.) impose significant runtime overheads that can change the
asymptotic time and space complexity of a program
\citep{herman2010space}. There are several known space-efficient cast
representations, with various strengths and weaknesses
\citep{siek2015blame,siek2010threesomes,garcia2013calculating,kuhlenschmidt2018efficient,siek2012interpretations,garcia2014deriving}. This
paper presents a new cast representation, named \emph{hypercoercions},
that is good for both mechanized metatheory and good for
implementation. Recall that it is the composition operator in these
systems that enables space-efficiency by compressing casts.  The
composition operator for hypercoercions is structurally recursive and
hypercoercions are suggestive of a bit-level representation that
minimizes the need for pointers and fits all first-order casts into 64
bits.  Of course, an alternative cast representation must not change
the result of programs. This paper presents steps toward a framework
for proving the equivalence of cast calculi and, in particular, proves
that an abstract machine using hypercoercions is equivalent to an
abstract machine using standard casts.

%
%For example, translation to intermediate languages can wrap some expressions 
%with casts, including expressions at tail positions. Thus, mutually 
%tail-recursive functions in source language can consume unbounded space at 
%runtime. There are more examples of space leaking in \citet{herman2010space}.

The current state of the art regarding cast representations includes
\begin{itemize}
\item threesomes \citep{siek2010threesomes},
\item supercoercions \citep{garcia2014deriving}, and
\item coercions in normal form
  \citep{siek2012interpretations,siek2015blame}.
\end{itemize}
Threesomes and supercoercions are good for mechanized metatheory
because their compose operators are structurally recursive, making
them easy to define in a proof assistant such as Agda. In contrast,
the coercions in normal form have compose operators that are not
structurally recursive, which makes it more difficult to define in
Agda, requiring what amounts to an explicit proof of termination.
%
On the other hand, coercions in normal form are easier to understand
than threesomes (with a strange labelled bottom type), and
supercoercions (with 10 different kinds). 


%% There are two best studied ways to represent cast space-efficiently:
%% coercions
%% \citep{herman2010space}\citep{siek2009exploring}\citep{siek2012interpretations}
%% \citep{siek2015blame} and threesomes
%% \citep{siek2010threesomes}\citep{garcia2013calculating}. They have
%% different strength and weakness. \citet{garcia2013calculating} and
%% \citet{siek2015blame} claim that coercion is easy to understand, but
%% hard to implement, while threesome is easy to implement, but hard to
%% understand. \citet{garcia2013calculating} in addition claims that
%% coercion is more difficult to reason about formally because its
%% compose function is not structurally recurisive. For instance, the
%% developers of Grift \citep{kuhlenschmidt2018efficient} report that it
%% is tricky to convince their proof assistants that the compose function
%% terminates.

We present a new cast representation, hypercoercion, which has a structurally 
recursive composition. When we prove theorems about hypercoercion in Agda, the 
definition ``just works''. 
Besides, We believe hypercoercion is about as easy to understand as coercion 
because their syntax definitions are similar. For instance, the 
coercion approach represents $ 
\cOOcast{\TOOdyn}{l}{\cOOcast{\POOunit}{l'}{\TOOdyn}} $ as $ \POOunit 
?^{l} ; \POOunit\! $, while the hypercoercion approach gives $ 
\hyperCoercionC{?^l}{\POOunit}{!} $. In Section~\ref{sec:background}, we review 
coercion together with cast calculus 
\citep{siek2009exploring}\citep{kuhlenschmidt2018efficient}. And we 
present hypercoerion in Section~\ref{sec:hypercoercion-definition}.

Another strength of hypercoercion over coercion is that hypercoercion might 
have a more compact memory representations. In Grift 
\citep{kuhlenschmidt2018efficient}, the longest coercions are represented with
two cons boxes. But for hypercoercion, we are optimistic that one cons box 
suffices. Using less cons boxes saves memory as well as running time.
\todo[inline]{
	Could Jeremy help explain explaining why hypercoercion is more compact in 
	memory?
	Cons boxes seem to be non-standard, but I don't know a better name.
 -KC}

Many of the existing research on coercions or threesomes include proof(s) of 
correctness, that is, the evaluation (partial) function of cast calculus $ eval 
$ is equal to their space-efficient evaluation ($ eval_{*} $).
Despite the striking similarity of these proofs, they are all built from ground 
up.

We present a framework for proving correctness of cast reprensentation 
(Section~\ref{sec:framework}), and use it to prove the correctness of 
hypercoercion (Section~\ref{sec:hypercoercion-correctness}). We are optimistic 
that this framework is general enough to include coercion and threesome.

%Some readers might know that there are four blame strategies: $ \{Lazy, 
%Eager\} 
%\times \{D, UD\} $ \citep{siek2009exploring}. Eager strategies detect more 
%potential type errors, but 
%blame more programs. $ D $ and $ UD $ assign blame labels differently.

We focus on lazy cast strategies because we suspect that they are more
efficient that eager strategies, which is why lazy was chosen in the
Grift compiler \citep{Kuhlenschmidt:2019aa}, and because
\citet{new2019gradual} show that eager strategies are incompatible
with $\eta$-equivalence of functions. We are interested in the D blame
tracking strategy because it has a more straightforward notion safe
cast compared to UD \citep{siek2009exploring}, which is why D was
chosen Grift compiler. However, we are also intersted in UD because it
plays a prominent role in the gradual typing literature
\citep{wadler2009well}.


The primary contributions of this paper are:
\begin{itemize}
\item hypercoercions, a new space-efficient cast representation, which
  has a structurally recursive composition and a more compact memory
  representation.
\item a framework in Agda for proving correctness of cast
  represantations.  We conjecture that both coercion and
  threesome can fit into this framework.
\item a formal proof that hypercoercion respects the semantics
  of the \lazyD{} cast calculus.
\end{itemize}

%Around 2006, many work on integrating dynamic typing and static typing emerge, 
%notably gradual types \citep{siek2006gradual} and hybrid types 
%\citep{flanagan2006hybrid}. 
%Later \citet{wadler2009well} introduces Blame Calculus, an intermediate 
%language for gradual types and hybrid types. 
%Blame Calculus throws a blame label when a runtime type-check fails.
%Labels provide useful debugging information, therefore are necessary for 
%practical use of gradually typed languages.
%
%Implementing gradually typed languages naively on top of blame calculus, 
%however, suffices sever space leak.
%For example, translation to Blame Calculus can wrap some expressions with code 
%that performs runtime type-checking (casts), including expressions at 
%tail positions. Thus, mutually tail-recursive functions in source language can 
%consume unbounded space at runtime. There are more examples of space leaking 
%in 
%\citet{herman2010space}.
%
%In 2007, \citet{herman2010space} proposes a solution to this problem by 
%representing casts with coercion \citep{henglein1994dynamic}, 
%which can be composed and normalized. Every coercion looks like a list of 
%trees. For normal coercion, the length of the list is bounded by a small 
%constant. And the depths of trees do not grow during composition and
%normalization. These two facts implies that coercion is a space-efficient cast 
%representation. This coercion, however, does not support blame 
%tracking. 
%
%After that, many efforts have been made to combine blame tracking and 
%space efficiency. 
%
%\citet{siek2009exploring} present another intermediate langauge for gradually 
%typed language, cast calculus \castCalculus\ and achieve both blame-tracking 
%and space-efficiency for this language by decorating \citet{herman2010space}'s 
%coercions with labels. \castCalculus\ is simply typed lambda calculus extended 
%with the dynamic type and cast expressions. The labels in \castCalculus{}, 
%unlike their counterparts in the Blame Calculus, have no polarity. 
%They also propose that there are four blame strategies for \castCalculus{}:
%$ \{Lazy, Eager\} \times \{D, UD\} $. Eager strategies detect more potential 
%type errors, but blame more programs. $ D $ and $ UD $ assign blame labels 
%differently. They claim that their \lazyUD\ cast calculus is the same as the 
%Blame Calculus, modulo label polarity, and prove that their their \lazyUD\ 
%coercion calculus simulates their \lazyUD{} cast calculus. It is unknown, 
%however, whether the simulation in the other direction also works.
%\todo[inline]{Is it important to this paper whether there is a
%simulation in the other direction? -JS
%\\ --- \\
%I guessed to say coercion is correct the other direction is 
%necessary. -KC}
%
%\citet{siek2010threesomes} proposes another approach to combine blame 
%tracking and space efficiency. Their solution represents casts with 
%threesomes, 
%a novel cast representation. Threesome is proved space-efficient as well.
%They prove that their calculus bisimulates the \lazyUD{} coercion 
%calculus in \citet{siek2009exploring} and the Blame Calculus in 
%\citet{wadler2009well}.
%
%\citet{siek2012interpretations} present a revised coercion calculi.
%They simplify the coercion calculi by only 
%working with normal coercions (i.e. coercions in normal form). 
%They conjecture that their revised coercion calculi bisimulate the 
%corresponding cast calculi.
%
%\citet{garcia2013calculating} develops
%threesome for other blame strategies. After studying in depth the connection 
%between coercion and threesome,
%he claims that normal coercion with labels is easy to understand but hard to 
%implement and hard to reason about, and that 
%threesome with labels, however, is easy to implement and easy to reason about 
%but hard to understand. 
%His claim is mostly affirmed by the group of people who develop threesome 
%(\citet{siek2015blame}).
%His threesome calculi are equivalent to the coercion calculi of
%\citet{siek2009exploring} because the former ones are derived from the latter 
%ones.
%
%\citet{siek2015blame} revisit the coercion-based approach. They revise
%the \lazyUD{} coercion in \citet{siek2012interpretations} and prove
%that their revised coercion calculus bisimulates the \lazyUD{} Blame
%Calculus \citet{wadler2009well}.
%
%Last year, \citet{kuhlenschmidt2018efficient} present Grift, a compiler for a 
%gradually typed language of the same name. 
%This implementation is based on the \lazyD{} coercion in 
%\citet{siek2012interpretations}.
%Their result suggests that normal coercion is easy enough to implement in a 
%compiler. 
%
%So far, it seems that normal coercion is the best way to combine 
%space-efficiency and blame-tracking: normal coercion is claimed easy to 
%understand \citep{garcia2013calculating}\citep{siek2015blame} and is shown 
%easy enough to implement in a compiler \citep{kuhlenschmidt2018efficient}.
%Normal coercion is still not satisfactory, however, in at least two aspects.
%Firstly, as we mentioned above, it is hard to reason about normal coercion. 
%The 
%major difficulty is from its non-structurally recursive composition.
%For instance, the developers of Grift report it is tricky to convince
%their proof assistants that the composition terminates.
%
%Secondly, the definition of normal coercion lies unnecessarily on top 
%of coercion: all coercions are normal when they are initially constructed, and 
%\citet{siek2012interpretations} have shown an function that 
%composes and produces normal coercions.
%%
%\todo[inline]{Many researchers would view this as a positive thing,
%  not a negative. For example, the notion of normal forms comes up
%  over and over again in mathematics and logic. -JS
%\\ --- \\
%I guess having a notion of normal forms is more convenient when a 
%notion of normalization is convenient. But we don't even need a notion of 
%normalization for cast representations. -KC
%\\ --- \\
%FWIW, I agree with you. But the point is that the argument is not
%likely to be convincing to the reader, so we're probably better off
%not wasting space on it. -JS
%}
%
%Perhaps unsurprisingly, threesome has a structurally recursive compose and a 
%self-standing definition. Together with \citet{garcia2013calculating}'s 
%work, they suggest that there might be a cast representation whose definition 
%is self-standing, and whose composition is structurally recursive. 
%supercoercion introduced in \citet{garcia2013calculating} could be a promising 
%candidate. It is believed even more complicated than threesome 
%\citep{siek2015blame}. In fact, it uses 10 constructors to deal with an 
%elementary type system with only base types and 
%function types. And four constructors are directly related to function types. 
%Thus, supercoercion might not scale very well to more sophisticated type 
%systems. 
%
%We present hypercoercion, a cast representation whose composition is 
%structurally recursive, and whose definition is self-standing. What's more, it 
%should be at 
%least as easy to implement and understand as normal coercions, because there 
%is 
%a clear connection between them, as we will show in Section 
%\ref{sec:hypercoercion}.
%Our hypercoercion considers sum types and product types, which are not 
%considered in all proofs above. Adding each of them requires us to add only 
%one 
%new constructor to a component of hypercoercion. This suggests that 
%hypercoercion might scale better than supercoercion.
%
%We prove formally that the \lazyD{} (resp. \lazyUD{}) hypercoercion calculus 
%bisimulates the \lazyD{} (resp. \lazyUD{}) cast calculus. This is 
%the first bisimulation proof for the \lazyD{} cast calculus as far as we know.
%We care more about lazy strategies because recently, \citet{new2019gradual} 
%show that \eager{} strategies are incompatible with $\eta$-equivalence of 
%functions, which suggest that these strategies are not very ideal. 
%\todo[inline]{Explain why we care about \lazyD{} and \lazyUD{}. -JS
%  \\ --- \\ Explained, not sure if it suffice. -KC
%  \\ --- \\
%  That's good that you explained why lazy instead of eager.
%  (Also, you should add that we are interested in lazy because
%  that's what Grift does.)\\
%  But you haven't explained why we are interested in both D and UD. -JS
%}
%
%The structure of this paper is as follows. 
%Section \ref{sec:blame-calculus} reviews the state-of-art of $Lazy$ cast 
%calculi. 
%Section \ref{sec:coercion-calculus} reviews the state-of-art of $Lazy$ 
%Coercion 
%Calculi. 
%In section \ref{sec:hypercoercion} we present hypercoercion.
%Section \ref{sec:conclude} concludes.
%\todo[inline]{Lots of missing sections. -JS}

\section{Background} \label{sec:background}

In this section, we review lazy cast calculi (\ref{sec:cast-calculi}) and
normal coercion (\ref{sec:coercion-calculus}). 

\subsection{Cast Calculi}
\label{sec:cast-calculi}
\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P}{pre-types}{
		\POOunit \mid
		\POOfun{T_1}{T_2} \mid
		\POOprod{T_1}{T_2} \mid
		\POOsum{T_1}{T_2}
	}
	\stxrule{e}{terms}{
		\eOOvar{x} \mid{}
		\eOOsole{} \mid{}
		\eOOlam{T_1}{T_2}{x}{e} \mid
		\eOOapp{e_1}{e_2} \mid
		\eOOcons{e_1}{e_2} \mid
		\eOOcar{e} \mid
		\eOOcdr{e}
	}
	\stxrulecont{
		\eOOinl{e} \mid
		\eOOinr{e} \mid
		\eOOcase{e_1}{e_2}{e_3} \mid
		\eOOcast{e}{T_1}{l}{T_2} \mid
		\eOOblame{l}
	}
	\stxrule{v}{values}{
		\vOOtt{} \mid
		\vOOfun{\rho}{x}{e} \mid
		\vOOcons{v_1}{v_2} \mid
		\vOOinl{v} \mid
		\vOOinr{v} \mid		
		\vOOcast{v}{c}
	}
	\stxrule{c}{casts}{
		\cOOcast{T_1}{l}{T_2}
	}
	\stxrule{I}{injectable types (\lazyD)}{
		P
	}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\star}{\star} \mid
		\star \times \star \mid
		\star + \star
	}
	\stxrule{o}{observations}{
		\oOOinj \mid
		\oOOsole \mid
		\oOOfun \mid
		\oOOcons \mid
		\oOOinl \mid
		\oOOinr \mid
		\oOOblame{l}
	}
	\end{array}
	\]
	
	Consistency
	\fbox{$ T_1 \sim T_2 $}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	Shallow-consistency
	\fbox{$ T_1 \smile T_2 $}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
	} \quad
	\inference{}{
		T_{11} \times T_{12} \smile T_{21} \times T_{22}
	} \quad
	\inference{}{
	T_{11} \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	Term typing
	\fbox{$ \judgetype{\Gamma}{e}{T} $}
	\begin{gather*}
		\inference{
			\Gamma \vdash e : T_1 & T_1 \sim T_2
		}{
			\judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\eOOblame{l}}{T}
		}
	\end{gather*}
	
	Value typing \fbox{$ v : T $}
	\begin{gather*}
	\dots \quad
	\inference{
		v : I
	}{
		\vOOcast{v}{\cOOcast{I}{l}{\TOOdyn}} : \TOOdyn
	}
	\quad
	\inference{
		v : P_1 &
		P_1 \smile P_2
	}{
		\vOOcast{v}{\cOOcast{P_1}{l}{P_2}} : P_2
	}
	\end{gather*}

	\caption{Syntax and static semantics of the cast calculi.}
	\label{fig:blame-static}
\end{figure}

\figref{fig:blame-static} defines the syntax of cast calculi and its
static semantics. We extend the syntax of \citet{siek2009exploring}
with sum and product types.  Let $ T $ range over types. A type is
either the dynamic type $ \star $ (a.k.a. $ \mathtt{Dyn} $, $
\mathbb{?} $, or $ \mathtt{Unknown} $), or a type with a type
constructor at the top, that is, a pre-type, ranged over by $ P $. We
include just one base type, $\POOunit$. The other pre-types are
functions, products, and sums.

As usual we write $ T_1 \sim T_2 $ when $ T_1 $ and $ T_2 $ are
consistent. The intuition of $ T_1 \sim T_2 $ is that $ T_1 $ and $
T_2 $ have no conflicting type information. Two types are consistent
if one of them is $ \star $, or they have the same top-most type
constructor and the corresponding sub-parts are
consistent. Consistency is reflexive and symmetric, but not
transitive.

We write $ T_1 \smile T_2 $ when $ T_1 $ and $ T_2 $ are
shallowly-consistent, that is, if one of them is $ \star $, or they
have the same type constructor at the top. Shallow-inconsistency is
the root of all blame in lazy cast strategies -- casting a value to a
shallowly inconsistent type leads to a blame. Shallow-consistency is
reflexive, symmetric, but not transitive.

Let $ e $ range over terms. Most terms are standard for a simply-typed
lambda calculus. We annotate the codomain of a lambda abstraction
explicitly because we refer to it in the dynamic semantics. Becuase
this is a cast calculus, we have two additional terms: cast
expressions and blame expressions. Cast expressions perform runtime
type checks and blame expressions raise an error.

Let $ v $ range over values. A value is either the unit, a function (a
closure), a pair, a left injection, a right injection, or a casted
value. As shown by the value typing rules, if the target type of a
casted value is the dynamic type, the underlying value must be of an
injectable type. The definition of injectable types depends on blame
strategies: for the \lazyD\ strategy, every pre-type is injectable;
for the \lazyUD\ strategy, a pre-types is injectable if and only if
all its sub-parts are the dynamic type. If the target type of a casted
value is a pre-type, the type of the underlying value must have the
same type constructor.

Let $ c $ range over casts. A cast is a triple of a type, a label, and a type.

Let $ o $ range over observations. They are what would be observed if
a program terminates. Observations include all value constructors and
blame.  The function converting values to observations ($ observe(v) =
o $) is defined in the natural way.

\begin{figure}
	%	Continuation typing \fbox{$ \kappa : T_1 \Longrightarrow T_2 $}
	%	\begin{gather*}
	%	\dots \quad
	%	\inference{
	%		c : T_1 \Longrightarrow T_2 &
	%		\kappa : T_2 \Longrightarrow T_3
	%	}{
	%		\langle c \rangle \kappa : T_1 \Longrightarrow T_3
	%	}
	%	\end{gather*}
	
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	
	\stxrule{\kappa}{continuations}{
		\kOOmt \mid
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa} \mid
		\kOOinr{\kappa}
	}
	\stxrulecont{
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa} \mid
		\kOOcdr{\kappa} \mid
		\kOOcaseI{e_1}{e_2}{\rho}{\kappa}
	}
	\stxrulecont{	
		\kOOcaseII{v}{e}{\rho}{\kappa} \mid
		\kOOcaseIII{v_1}{v_2}{\kappa} \mid
		\kOOcast{c}{\kappa}
	}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeCreduce{s}{s} $}
	\[
	\begin{array}{rclr}
		\redrule{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{\langle\cOOcast{T_1}{l}{T_2}\rangle\kappa}
	}{}
	
	
	\redrule{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho[x]}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\vOOtt}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\vOOfun{\rho}{x}{e})}{\kappa}
	}{}
	\redrule{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{E}{}
	}{}
	\redrule{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{(\kOOinl{\kappa})}
	}{}
	\redrule{
	\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
	\sOOinspect{e}{\rho}{(\kOOinr{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
\sOOinspect{e_1}{\rho}{(\kOOappI{E}{e_2}{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
\sOOinspect{e}{\rho}{(\kOOcar{\kappa})}}{}

\redrule{
	\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
	\sOOinspect{e}{\rho}{(\kOOcdr{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
\sOOinspect{e_1}{\rho}{(\kOOcaseI{E}{e_2}{e_3}{\kappa})}}{}

\redrule{
\sOOreturn{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOconsII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
\sOOreturn{(\vOOcons{v_1}{v_2})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinl{\kappa})}}{
\sOOreturn{(\vOOinl{v})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinr{\kappa})}}{
\sOOreturn{(\vOOinr{v})}{\kappa}}{}

\redrule{
\sOOreturn{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOappII{(\vOOfun{\rho}{x}{e})}{\kappa})}}{
\sOOinspect{e}{\rho[x:=v_2]}{\kappa}}{}
	\redrule{
		\sOOreturn{v_1}{(\mathtt{app_2} \; \vOOcast{v_2}{
				\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
			} \; \kappa)}
	}{
		\sOOreturn{v_1}{
			\langle\cOOcast{T_3}{l}{T_1}\rangle
			(\mathtt{app_2} \; v_2 \; 
			\langle\cOOcast{T_2}{l}{T_4}\rangle \kappa)}
	}{}
	\redrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{fst} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{fst} \;
			\langle \cOOcast{T_1}{l}{T_3} \rangle \kappa
			)}
	}{}
	
	\redrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{snd} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{snd} \;
			\langle \cOOcast{T_2}{l}{T_4} \rangle \kappa
			)}
	}{}

\redrule{
\sOOreturn{v_1}{(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_3}{\rho}{
	(\kOOcaseIII{v_1}{v_2}{\kappa})
}}{}	

\redrule{
\sOOreturn{v_3}{(\mathtt{case_3}\;(\vOOinl{v})\;v_2\;\kappa)}
}{
\sOOreturn{v}{(\kOOappII{v_2}{\kappa})}
}{}

\redrule{
	\sOOreturn{v_3}{(\mathtt{case_3}\;(\vOOinr{v})\;v_2\;\kappa)}
}{
\sOOreturn{v}{(\kOOappII{v_3}{\kappa})}
}{}

\redrule{
	\sOOreturn{v_3}{(\mathtt{case_3}\;
		(\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}})
		\;v_2\;\kappa)}
}{
	\sOOreturn{v_3'}{
		(\mathtt{case_3}\;v
		\;v_2'\;\kappa)
	}
}{\\&&
\text{where}\;
v2' = \vOOcast{v_2}{\cOOcast{\POOfun{T_4}{T}}{l}{\POOfun{T_2}{T}}}
\\&&
\text{and}\;
v3' = \vOOcast{v_3}{\cOOcast{\POOfun{T_3}{T}}{l}{\POOfun{T_1}{T}}}
}
	
	\redrule{
		\sOOreturn{v}{(
			\mathtt{cast} \; c \; \kappa
			)}
	}{
\begin{cases}
	\sOOreturn{u}{\kappa} & \sidecond{applyCast(v,c) = \rOOsucc{u}}
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
\end{cases}
	}{}
\redrule{
\sOOreturn{v}{\kOOmt}}{
\sOOhalt{observe(v)}}{}

%\redrule{
%\sOOhalt{o}}{
%\sOOhalt{o}}{}
	\end{array}
	\]	
%	
%	\fbox{$case(v, \kappa, \kappa) = s$}
%	\[
%	\begin{array}{rclr}
%	\funrule{case(\vOOinl{v},\kappa_1,\kappa_2)}{
%		\sOOreturn{v}{\kappa_1}
%	}{}
%	\funrule{case(\vOOinr{v},\kappa_1,\kappa_2)}{
%		\sOOreturn{v}{\kappa_2}
%	}{}
%	
%\funrule{case(\vOOcast{v}{\cOOcast{\POOsum{T_{11}}{T_{12}}}{l}{\POOsum{T_{21}}{T_{22}}}},\kappa_1,\kappa_2)}{
%		case(v,
%		\langle \cOOcast{T_{11}}{l}{T_{21}} \rangle \kappa_1,
%		\langle \cOOcast{T_{12}}{l}{T_{22}} \rangle \kappa_2)
%	}{}
%	\end{array}
%	\]
		
	%	Transitive closure of reduction \fbox{$ s \longrightarrow_{D,B}^{*} s 
	%$}\\
	
	Evaluation \fbox{$\judgeCeval{e}{o}$}
	\[
	\inference{
		\sOOinspect{e}{\emptyset}{cont(\hckOOmt)} \longrightarrow_{B}^{*} 
		\sOOhalt{o}
	}{
		\judgeCeval{e}{o}
	}
	\]
	
	\caption{Dynamic semantics of the cast calculi as a CEK machine}
	\label{machine-cekc}
\end{figure}

Fig.~\ref{machine-cekc} defines the dynamic semantics of cast calculi as a 
CEK machine \citep{felleisen1986control}. CEK machines include continuation as 
part of their states. They evaluate expressions with two interleaving 
processes: 
(1) dive into an expression and extend the continuation;
(2) return a value to the current continuation.

Most existing proofs about cast calculi defines the dynamic semantics with 
reduction semantics. We use a CEK machine instead because the first author is 
more familiar with CEK machines, and that he believes CEK machines are more 
convenient because space-efficiency is about compressing continuations.

Let $ r $ range over cast results. A cast result is either a success, which 
brings back a value, or a failure, which brings a blame label.

Let $ s $ range over machine states. A state is either looking at an 
expression to decide what to do next, returning a value to a continuation, or 
halting with an observation.

Let $ \kappa $ range over continuations. $ \mathtt{stop} $ is the top 
continuation. The remaining continuations correspond to expressions. For 
example, $ (\mathtt{cons_1} \; e \; \rho \; \kappa) $ is the continuation where 
we are waiting for the value of the first argument to a $ \mathtt{cons} $. And 
the last continuation, $ \langle c \rangle \kappa $ is to cast the value before 
returning to $ \kappa $.

The reduction relation $ \judgeCreduce{s}{s} $ is parameterized over $ 
applyCast $. 
When evaluating a cast expression, the machine moves the cast to the 
continuation and evaluate the inner expression.
Other transition rules starting from $ Eval $ states are standard.
To apply a casted 
function, the machine firstly cast $ v_1 $, the operand, then apply the casted 
operand to $ v_2 $, the un-casted function, and finally cast the result of the 
function application. To take out the first (resp. second) part of a casted 
pair, the machine firstly take out the first (resp. second) part of $ v $, the 
un-casted pair, and cast the result. In case spliting, if the target value is a 
left injection, the machine moves to a state that will apply the first 
continuation function to the value inside the left injection. The case for 
right injection is similar. When the target value is a casted sum, the machine 
moves the cast from the target value to continuations functions. 
%Along the way, the machine accumulates the pending casts onto the 
%continuations. 
To cast a value, the machine try to apply the cast to the value. 
If the cast succeeds, the machine returns the result to the next continuation. 
If the cast fails, the machine halts with the blame label.
When the continuation is $ stop $, the machine enters a halting state. The 
When the machine is in a halting state, it stays in the same state.

The reflexive transitive closure of reduction ($ \judgeCreduceTrans{s}{s} $) 
and evaluation ($ eval_\mathcal{C}(e) $) are standard.

\subsection{The \lazyD{} cast calculus}

\begin{figure}
	
	\fbox{$applyCast(v,c) = r$}
	\[
	\begin{array}{rclr}
	\funrule{
		applyCast(v,\cOOcast{\star}{l}{\star})
	}{
		\rOOsucc{v}
	}{}
	\funrule{
		applyCast(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
	}{
		applyCast(v,\cOOcast{P_1}{l_2}{P_2})
	}{}
	\funrule{
		applyCast(v,\cOOcast{P}{l}{\star})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
	}{}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
	}{\sidecond{P_1 \smile P_2}}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOfail{l}
	}{\sidecond{\neg P_1 \smile P_2}}
	
	\end{array}
	\]
	\caption{Definition of $ applyCast $ for \lazyD}
	\label{fig:applyCast-D-C}
\end{figure}

\figref{fig:applyCast-D-C} defines the $ applyCast $ for \lazyD. 
We conjecture that with this $ applyCast $, the CEK machine in 
\figref{machine-cekc} would agree with the \lazyD{} cast calculus in 
\citet{siek2009exploring}. We denote this \lazyD{} machine by \ineffCEKD{},
and the corresponding relations by $ \judgeDreduce{s}{s} $, $ 
\judgeDreduceTrans{s}{s} $, and $ \judgeDeval{e}{o} $

\subsection{The \lazyUD{} cast calculus [Jeremy]}

The dynamic semantics of the \lazyUD{} cast calculus, which we define here as a
CEK machine, is similar to that of the \lazyD{} cast calculus
(Fig. \ref{machine-cekc}). The only difference is in the definition of
the $\mathit{applyCast}$ function, in which a cast whose source or
target is the unknown type $\star$ is always split into two casts that
go through an injectiable type, that is, a type in which all
sub-components are the unknown type, such as $\star \to \star$. The
definition of $\mathit{applyCast}$ for the \lazyUD{} cast calculus is given in
Fig.~\ref{fig:apply-Cast-UD}.

\begin{figure}
%
%  Syntax
%  \[
%  \begin{array}{rclr}
%    \stxrule{v}{values}{
%      \cdots \mid 
%      \vOOcast{v}{ \cOOcast{I}{l}{\star} } \mid
%      \vOOcast{v}{ \cOOcast{P}{l}{P} }
%    }
%  \end{array}
%  \]
%  
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& v \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        v \langle \cOOcast{P}{l}{I} \rangle
          \langle \cOOcast{I}{l}{\star} \rangle
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        v \langle \cOOcast{\star}{l}{I} \rangle
          \langle \cOOcast{I}{l}{P} \rangle
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& v \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
     v \langle \cOOcast{P_1}{l}{P_2} \rangle & \text{if } P_1 \smile P_2
  \end{array}
  \]


  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}


% the following are temporary -JS
\clearpage
\pagebreak

\subsection{Coercions in Normal Form} 
\label{sec:coercion-calculus}

In this section we review the normal coercions \citep{siek2012interpretations} 
to motivate the design of hypercoercion. 
We ignore sum types and product types in this 
section, because they were not in the paper. We assume a basic 
familiarity with coercion, and direct readers who do not know it to 
\citet{siek2012interpretations}.
%We 
%will highlight the similarity of normal coercion and hypercoercion, and hope 
%this would convince you that hypercoercion should be as difficult to implement 
%as normal coercions.
%\todo[inline]{I don't think we should try to convince the reader that
%  hypercoercions are easier to implement. We don't have real evidence
%  for that.}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{I}{injectable types (\lazyD)}{
		\POOfun{T}{T}}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOfun{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{coercions}{
		\ncInj{I} \mid
		\ncProj{I}{l} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncSeq{c}{c} \mid
		\ncFun{c}{c}
	}
	\stxrule{\bar{c}}{wrapper coercions}{	
		\ncInj{I} \mid
		\ncFun{\hat{c}}{\hat{c}} \mid
		\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}
	}
%	\stxrulecont{
%		\ncProd{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncProd{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
%		\ncSum{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncSum{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid	
%	}
	\stxrule{\hat{c}}{normal coercions}{
		\bar{c} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncProj{I}{l} \mid
		\ncSeq{\ncProj{I}{l}}{\ncFail{l}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncInj{I}}
	}
	\stxrulecont{
		\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}}
	}
	\end{array}
	\]
	\caption{Syntax of Normal Coercion}
	\label{fig:normal-coercion}
\end{figure}

\todo[inline]{Give a summary statement about the shape of the normal form. 
-JS
\\---\\The three-part shape is not obvious before the transformation at 
the end of the next paragraph. So the summary is given after that. -KC}

\figref{fig:normal-coercion} defines the normal coercion.
Types, pre-types, and blame labels are as before.
Let $ I $ range over injectable types. An injectable type is a type that can 
be cast directly to (injection) and from (projection) $ \TOOdyn $. The 
definition of injectable type depends on blame strategy. With \lazyD, all 
pre-types are injectable. With \lazyUD, only $ \POOfun{\TOOdyn}{\TOOdyn} $ 
is injectable. 
Let $ c $ range over coercions, a coercion is either injection, projection, 
identity, failure, sequencing, or function coercion.
Let $ \bar{c} $ range over wrapper coercions, which represent casts in $ 
\vOOcast{v}{c} $.
Let $ \hat{c} $ range over normal coercions. If we inline $ \bar{c} $ and 
re-order the cases, the definition of $ \hat{c} $ becomes:
\[
\begin{array}{rclr}
\stxrule{\hat{c}}{normal coercions}{
	\ncFun{\hat{c}}{\hat{c}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
	\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
	\ncId \mid
	\ncProj{I}{l} \mid
	\ncInj{I} \mid
	\ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
	\ncFail{l} \mid
}
\end{array}
\]

Three observations on this definition leads to hypercoercion: 
\begin{enumerate}
	\item The length of normal coercion is at most three.
	\item Projections are always at the beginning when present.
	\item Injections and failures are always at the end when present.
\end{enumerate}


\section{Definition of Hypercoercion} \label{sec:hypercoercion-definition}

\begin{figure}
	Syntax
	\[
	\begin{array}{lclr}
	\stxrule{I}{injectable types (\lazyD)}{P}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\TOOdyn}{\TOOdyn} \mid
		\POOprod{\TOOdyn}{\TOOdyn} \mid
		\POOsum{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{hypercoercions}{
		\hyperCoercionI \mid{}
		\hyperCoercionC{h}{m}{t}
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{m}{middles}{
		\POOunit \mid
		\POOfun{c_1}{c_2} \mid
		\POOprod{c_1}{c_2} \mid
		\POOsum{c_1}{c_2}
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
		
	hypercoercion typing \fbox{$ c : T \Longrightarrow T $}
	\begin{gather*}
	\inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
	\quad
	\inference{
		\typingHC{h}{T_1}{P_1} &
		\typingHC{m}{P_1}{P_2} &
		\typingHC{t}{P_2}{T_2}
	}{
		\typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
	}
	\end{gather*}
	
	Head typing \fbox{$ \typingHC{h}{T}{P} $}
	\begin{gather*}
	\inference{}{\typingHC{\epsilon}{P}{P}}
	\quad
	\inference{}{\typingHC{?^l}{\TOOdyn}{I}}
	\end{gather*}
	
	Middle typing \fbox{$ \typingHC{m}{T}{T} $}
	\begin{gather*}
	\inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
	\quad
	\inference{
		\typingHC{c_1}{T_3}{T_1} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
	}
	\\
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
	}
	\quad
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
	}
		\end{gather*}
		
		Tail typing \fbox{$ \typingHC{t}{P}{T} $}
		\begin{gather*}
		\inference{}{\typingHC{\epsilon}{P}{P}} \quad
		\inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
		\inference{}{\typingHC{\bot^l}{P}{T}} \quad
		\end{gather*}
	
	\caption{Definition of hypercoercion (HC)}
	\label{fig:hypercoercion}
\end{figure}

This section presents our first contribution, the definition of hypercoercion. 
The design of hypercoercion is motivated by observations on coercion normal 
forms: a normal coercion has at most three parts; projections are always at the 
beginning; injections and failures are always at the end. Hypercoercions have 
similar shape: a hypercion has either one part or three parts; for three-part 
hypercoercions, the first part is either a projection or a no-op, while the 
last part is either an injection, a failure, or a no-op.

\figref{fig:hypercoercion} defines the syntax of hypercoercion. Types, 
pre-types, and blame labels are as before.

Let $ c $ range over hypercoercions. A hypercoercion is either 
an identity cast between the dynamic types, or a complex including a head, a 
middle, and a tail. 
Let $ h $ range over heads. A head is either a no-op, or a projection.
Let $ m $ range over middles. There is a one-to-one 
correspondence between middles and type constructors. 
We generalize shallow-consistency to middles $ m \smile m $ in the natural way.
Let $ t $ range over tails. A tail is either a no-op, an injection, or a 
failure. 

We define hypercoercion constructs in the following subsections.
But functions that apply hypercoercions to values are deferred to 
Section~\ref{sec:hypercoercion-correctness} because 
they depends on a new definition of values, which is part of the framework in
Section~\ref{sec:framework}.

\subsection{\lazyD{} hypercoercion}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{\ell}{Maybe $ l $}{\epsilon \mid l}
	\end{array}
	\]
	
	Composition of hypercoercions \fbox{$ c \fatsemi^\ell c = c $}
	\[ 
	\begin{array}{rclclr}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{\epsilon}{m}{t}
	}{
		\hyperCoercionC{?^{l}}{m}{t}
	}{\sidecond{\ell = l}}
	
	\comprule{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{
		c
	}{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{t}
	}{
		\hyperCoercionI
	}{
		\hyperCoercionC{h}{m}{!}
	}{
		\sidecond{\forall l. t \neq \bot^{l}}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{\epsilon}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			m_1 \fatsemi^{\ell} (m_2, t_2) = (m', t')
			 \; \text{and} \;
			 \forall l. t \neq \bot^{l}
		}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{?^{l'}}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			m_1 \fatsemi^{l'} (m_2, t_2) = (m', t')
			\; \text{and} \;
			\forall l. t \neq \bot^{l} 
		}
	}
	\end{array}
	\]
	
	Composition of middles \fbox{$ m \fatsemi^\ell (m,t) = (m,t) $}
	\[ 
	\begin{array}{rclclr}
	\comprule{\POOunit}{(\POOunit,t)}{
		(\POOunit,t)
	}{}
	\comprule{\POOfun{c_1}{c_2}}{(\POOfun{c_3}{c_4},t)}{
		(\POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOprod{c_1}{c_2}}{(\POOprod{c_3}{c_4},t)}{
		(\POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOsum{c_1}{c_2}}{(\POOsum{c_3}{c_4},t)}{
		(\POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{m_1}{(m_2,t)}{
		(m_1,\bot^l)
	}{
		\sidecond{
			\ell = l \; \text{and} \;
			\neg m_1 \smile m_2 
		}
	}
	\end{array}
	\]
	
	\fbox{$ seq(c,c) = c $}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^\epsilon c_2
	}{}
	\end{array}
	\]
	
	\fbox{$ id( P ) = m $}
	\[
	\begin{array}{rclr}
	\funrule{id(\POOunit)}{\POOunit}{}
	\funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
	}{}
	\end{array}
	\]
	
	\fbox{$ id( T ) = c $}
	\[
	\begin{array}{rclr}
	\funrule{id(\star)}{
		\hyperCoercionI
	}{}
	\funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
	}{}
	\end{array}
	\]
	
	\fbox{$ cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	\caption{\lazyD{} hypercoercion}
	\label{fig:HC-D}
\end{figure}

\figref{fig:HC-D} defines the constructors of \lazyD{} hypercoercion.

Let $ \ell $ range over $ \epsilon $ and labels.
$ c_1 \fatsemi^\ell c_2 = c' $ composes two hypercoercions. The target of $ 
c_1 $ and the source of $ c_2 $ might be different, in which case $ \ell $ must 
be a label.
$ m_1 \fatsemi^\ell (m_2,t) = (m',t') $ composes a middle with a 
pair of a middle and a tail. Similarly, the target of $ m_1 $ and the source of 
$ m_2 $ might be different, in which case $ \ell $ must be a label.
$ seq(c_1,c_2) $ composes two coercions where the target type of $ c_1 $ is 
equal to the source type of $ T_2 $.
$ id(T) $ constructs an identity coercion of $ T $ with the help of $ id(P) $.
$ cast(T_1,l,T_2) $ constructs a coercion from a source type, a label, and a 
target type. 

\begin{proposition}[\lazyD\ hypercoercion is a monoid]
	\label{thm:hc-monoid}
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}

\subsection{\lazyUD{} hypercoercion [Jeremy]}

Figure~\ref{fig:HC-UD}

\begin{figure}
  Composition of hypercoercions \fbox{$ c \fatsemi c = c $}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
       \hyperCoercionC{p_2}{m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{\epsilon} &\fatsemi& \hyperCoercionC{\epsilon}{m_2}{i_2} &=&
       \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{i_2} &=&
  \begin{cases}
    \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{p_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{p_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
     \hyperCoercionC{p_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$ id( P ) = m $}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$ id( T ) = c $}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
		\hyperCoercionI
    }{}
    \funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]

  
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}


Figure~\ref{fig:HC-UD-cast}


\begin{figure}
  \fbox{$ \mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$ \mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$ \mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$ \mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$ cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxilliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\begin{proposition}[\lazyUD\ hypercoercions form a monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}


\section{a framework for proving correctness of cast representations}
\label{sec:framework}

This section presents our second contribution, a framework for proving 
correctness of cast representations. The framework is a theorem saying that for 
all cast representation $ C $, if $ C $ satisfies a collection of properties, 
then it would respect the Lazy D semantics of cast calculi. We are working on a 
similar theorem for \lazyUD{}.

%then instantiating our parameterized space-efficient interpreter with $ C $ 
%gives an interpter that is extensionally equal to the standard interpreter for 
%\lazyD\ cast calculus. 

We captures the set of operators that every cast representation must provide 
with \emph{cast abstract data type} (Definition~\ref{def:cast-rep}). 
The first three operators allow a language implementation to construct casts. 
So we call them \textit{cast constructors}. And the forth and last operator 
enable the implementation to use apply casts.

\begin{definition}[Cast Abstract Data Type (Cast ADT)]
	\label{def:cast-rep}
	A cast abstract data type is a set $ Cast $ indexed by two types with
	four operators:
	\begin{description}
		\item[$ id(T) = c $] constructs an identity cast
		\item[$ seq(c_1,c_2)=c $] composes two casts
		\item[$ cast(T_1,l,T_2)=c $] constructs a cast from $ T_1 $ to $ T_2 $
		\item[$ applyCast(v,c)=r $] applies a cast onto a value
	\end{description}
\end{definition}

To use our framework, users needs to prove that their cast representation 
implements Lazy D Cast ADT (Definition~\ref{def:surely-lazyd}). To be a Lazy D 
Cast ADT, $ id(T) $ must acts like the identity function. And $ seq(c,c) $ 
must acts like a sequence of casts. What's more, $ cast(T_1,l,T_2) $ must act 
like the Lazy D $ applyCast $ (Fig.~\ref{fig:applyCast-D-C}).

\begin{definition}[Lazy D Cast ADT]
	\label{def:surely-lazyd}
	A  Cast ADT is a Lazy D Cast ADT if:
	\begin{enumerate}
		\item If $ v : T $, then $ applyCast(v,id(T)) = \mathtt{succ} \; v $
		\item If $ \judgeType{v}{T_1} $,
		$ \judgeTypeFT{c_1}{T_1}{T_2} $, and
		$ \judgeTypeFT{c_2}{T_2}{T_3} $,\\
		then $ applyCast(v,seq(c_1,c_2)) = 
		applyCast(v,c_1) >>= \lambda v.applyCast(v,c_2) $ \\
		where 
		\[
		\begin{array}{rcl}
		\rOOsucc{v} >>= f & = & f(v) \\
		\rOOfail{l} >>= f & = & \rOOfail{l}
		\end{array}
		\]
		\item If $ v : T_1 $ and $ \neg T_1 \smile T_2 $,
		then $ applyCast(v,cast(T_1, l, T_2)) = \rOOfail{l} $
		\item If $ v : \star $, 
		then $ applyCast(v,cast(\TOOdyn,l,\TOOdyn)) = \rOOsucc{v} $
		\item If $ v : P_1 $,
		then $ applyCast(\hcvOOinj{P_1}{v},cast(\star,l,P_2)) 
		= applyCast(v,cast(P_1,l,P_2)) $
		\item If $ v : P $,
		then $ applyCast(v,cast(P,l,\star)) = \rOOsucc{(\hcvOOinj{P}{v})} $
		\item If $ v : \POOunit $,
		then $ applyCast(v,cast(\POOunit,l,\POOunit)) = \rOOsucc{v} $
		\item
		$ 
		applyCast(\hcvOOfun{c_1}{\rho}{x}{b}{c_2}, 
		cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4})) \\
		= 
		\rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\rho}{x}{b}{seq(c_2,cast(T_2,l,T_4))})}$
		
		\item $ 
		applyCast(\hcvOOcons{v_1}{c_1}{v_2}{c_2},cast(\POOprod{T_1}{T_2},l,T_3 
		\times 
		T_4)) $ \\
		$ = 
		\rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
		$ 
		\item $ 
		applyCast(\hcvOOinl{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
		= \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))})} $
		\item $ 
		applyCast(\hcvOOinr{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
		= \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_2,l,T_4))})} $
	\end{enumerate}
\end{definition}

%Lazy D Cast ADT confines the behavior of operators so narrowly that it 
%effectively allows us to ``run'' programs without referring to an actual 
%representation of cast.

If a cast representation is a Lazy D Cast ADT, people can apply our theorems 
and be confident that this cast representation is valid.

Some cast representations are also \textit{monoids}. This definition is useful 
in the proof of our framework, and might be interesting for other people.

\begin{definition}[Monoid]
	A Cast ADT is a monoid if 
	for all
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c_1) = c_1$,
		\item $seq(c_1,id(T_2)) = c_1$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{definition}

In subsection~\ref{ssec:framework:cek}, we introduce \effCEK{C}, a family 
of space-efficient semantics indexed by Cast ADT ($ C $). When $ C $ is a Lazy 
D Cast ADT, \effCEK{C} repects \ineffCEKD.
In subsection~\ref{secc:framework:monoid-correct}, we prove when $ C $ is
a Lazy D Cast ADT and a monoid as well, $ \judgeDeval{e}{o} $ if 
and only if $ \judgeSeval{C}{e}{o} $. In 
subsection~\ref{secc:framework:all-correct}, we further prove that when $ C $ is
a Lazy D Cast ADT, \evalEqv{\ineffCEKD}{\effCEK{C}}.

\subsection{A Space-efficient CEK machine}
\label{ssec:framework:cek}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	
	\stxrule{v}{values}{
		\hcvOOtt \mid
		\hcvOOfun{c}{\rho}{x}{e}{c} \mid
		\hcvOOcons{v}{c}{v}{c}
	}
	\stxrulecont{
		\hcvOOinl{v}{c} \mid
		\hcvOOinr{v}{c} \mid
		\hcvOOinj{P}{v}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuation}{
		\langle c \rangle k
	}
	\stxrule{k}{pre-continuations}{
		\hckOOmt \mid{}
		\mathtt{cons_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{cons_2} \; v \; \kappa \mid{}
		\mathtt{inl} \; \kappa \mid{}
		\mathtt{inr} \; \kappa
	}
	\stxrulecont{
		\mathtt{app_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{app_2} \; v \; \kappa \mid{}
		\mathtt{fst} \; \kappa \mid{}
		\mathtt{snd} \; \kappa
	}
	\stxrulecont{
		\mathtt{case_1} \; e \; e \; \rho \; \kappa \mid
		\mathtt{case_2} \; v \; e \; \rho \; \kappa \mid{}
		\mathtt{case_3} \; v \; v \; \rho \; \kappa
	}
	\end{array}
	\]
	
	Build continuation \fbox{$ cont(k) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{cont(k)}{\langle id(T_1) \rangle k}{
		\sidecond{k : T_1 \Longrightarrow T_2}}
	\end{array}
	\]
	
	Extend continuation \fbox{$ ext(c,\kappa) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{ext(c_1,\langle c_2 \rangle k)}{\langle seq(c_1,c_2) \rangle k}{}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeSreduce{C}{s}{s} $}
	\[
	\begin{array}{rclr}
	& \vdots \\
	\redruleS{
		\sOOinspect{(\eOOlam{T_1}{T_2}{x}{e})}{\rho}{\kappa}
	}{
		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
	}{}
	\redruleS{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{cont(\hckOOconsI{e_2}{\rho}{\kappa})}
	}{}
	\redruleS{
		\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
	}{
		\begin{cases}
		\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)} \\
		\;\;\;\;\;\;\;\;\;\sidecond{applyCast(v,c_1) = \rOOsucc{v'}} 
		\\
		\sOOhalt{(\oOOblame{l})} \\
		\;\;\;\;\;\;\;\;\;\sidecond{applyCast(v,c_1) = \rOOfail{l}}
		\end{cases}
		
	}{}
	\end{array}
	\]
	
%	Transitive closure of reduction \fbox{$ s \longrightarrow_{S(C)}^{*} s $}
%	\[\dots\]
	
	Evaluation \fbox{$ \judgeSeval{C}{e}{o} $}
	\[
	\inference{
		\judgeSreduceTrans{C}{
			\sOOinspect{e}{\emptyset}{cont(\hckOOmt)}
		}{
			\sOOhalt{o}
		}		
	}{
		\judgeSeval{C}{e}{o}
	}
	\]
	
	\caption{Space-efficient CEK machine $ \mathcal{S}(C) $}
	\label{machine-cekcc}
\end{figure}
\figref{machine-cekcc} defines, \effCEK{C}, a space-efficient semantics as a 
CEK machine.
This machine is similar to \ineffCEK{}. 
The most important differences are in values and continuations.

Let $ v $ range over value. 
In \ineffCEK\, we have one value constructor for all casted value.
In \effCEK{C}, however, we do not have this generic value constructor, 
instead we push those casts into the value constructors most of the time and 
use $ \hcvOOinj{P}{v} $ to construct values casted to $ \TOOdyn $.
Non-casted values in \ineffCEK\ correspond to values in \effCEK{C} where the 
casts are identity (i.e. constructed by $ id(T) $).

Cast results ($ r $) and machine states ($ s $) are as before. 

Let $ \kappa $ range over continuations and let $ k $ range over 
pre-continuations. 
A continuation is now a pre-continuation prefixed with a cast.
Pre-continuation are like the continuations in \ineffCEK.
In \ineffCEK\, a continuation have zero or more casts at the top.
In \effCEK{C}, however, every continuation has exactly one cast at the top.
Continuations in \ineffCEK\ that have no casts at the top correspond to 
continuations in \effCEK{C}\ whose casts are identity.
And continuations in \ineffCEK\ that have many casts at the top correspond to 
continuations in \effCEK{C}\ where those casts are composed by $ 
seq(c,c) $.

\todo[inline]{KC needs to add missing rules in and describe them. -KC}
We list a fraction of reduction rules due to space limitation.
When values are constructed, their hypercoercion parts are filled with outputs 
of $ id $. For instance, when a function value is constructed, its first part 
and last part are initialized to $ id(T_1) $ and $ id(T_2) $ respectively.
When evaluating a cast expression, the current continuation is extended with a 
hypercoercion constructed by $ cast $. $ ext $ composes the new hypercoercion 
with the hypercoercion on the top of the continuation.
When evaluating a compound expression, the machine firstly construct the new 
pre-continuation, then turn it to a continuation by adding an identity 
hypercoercion at the top. For instance, when evaluating a \texttt{cons} 
expression, the machine firstly construct $ \hckOOconsI{e_2}{\rho}{\kappa} $, 
the new pre-continuation, then call $ cont $, which adds an identity cast to 
form a continuation. 
When a function call happens, the machine firstly cast the operand. If the 
casting succeeds, the machine then evaluate the body in the extended 
environment and the extended continuation. If the casting fails, the machine 
then halts with the blame label.

Transitive closure of reduction ($ \judgeSreduceTrans{C}{s}{s} $) and 
evaluation are standard. Value typing ($ \judgeType{v}{T} $) is straightforward.

\subsection{\lazyD\ Cast ADTs Respect \ineffCEKD\ if They are 
Monoids}
\label{secc:framework:monoid-correct}

In this subsection, we prove that if a instance of Cast ADT $ C $ is Lazy D and 
is a monoid, then $ eval_\mathcal{D} = eval_{\mathcal{S}(C)} $. We proof this 
theorem with a weak bisimulation between \ineffCEKD\ and 
\effCEK{C}. 

The bisimulation relation between states ($\eqvSD{C}{s}{s}$) is mostly derived 
from the state definition: \begin{gather*}
\inference{
	\rho_1 \approx \rho_2 &
	\kappa_1 \approx \kappa_2
}{
	\sOOinspect{e}{\rho_1}{\kappa_1} \approx \sOOinspect{e}{\rho_2}{\kappa_2}
}
\quad
\inference{
	\kappa_1 \approx \kappa_2 &
	v_1 \approx v_2
}{
	\sOOreturn{v_1}{\kappa_1} \approx \sOOreturn{v_2}{\kappa_2}
}
\quad
\inference{
}{
	\sOOhalt{o} \approx \sOOhalt{o}
}
\end{gather*}

The bisimulation relation between environments and cast results are derived 
from their definitions as well. And the relation from continuations in 
\ineffCEKD\ and the pre-continuation in \effCEK{C} is in the natural way, for 
example: \begin{gather*}
\inference{
	\rho_1 \approx \rho_2 &
	\kappa_1 \approx \kappa_2
}{
	\kOOconsI{e}{\rho_1}{\kappa_1} \approx \kOOconsI{e}{\rho_2}{\kappa_2}
}
\end{gather*}

And the relation between continuations is defined in terms of $ cont(k) $ and $ 
ext(c,k) $: \begin{gather*}
\inference{
	k \approx \kappa
}{
	cont(k) \approx \kappa
}
\quad
\inference{
	\kappa_1 \approx \kappa_2
}{
	ext(cast(T_1,l,T_2),\kappa_1)
	\approx
	\kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa_2} 
}
\end{gather*}

The relation between values is more special. When the \ineffCEKD\ value is 
non-casted, the casts in the \effCEK{C} value are identity. Otherwise, we push 
the cast into the value constructors, except injections. For examples: 
\begin{gather*}
\inference{
	v_1, v_2 : P &
	v_1 \approx v_2
}{
	\hcvOOinj{P_1}{v_1} \approx \vOOcast{v_2}{\cOOcast{P}{l}{\TOOdyn}}
}
\quad
\inference{
	v_1, v_2 : T &
	v_1 \approx v_2
}{
	\hcvOOinl{v_1}{id(T)} \approx \vOOinl{v_2}
}
\quad
\inference{
	(\hcvOOinl{v}{c}, v_2) : \POOsum{T_1}{T_2}
}{
	\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))} \approx 
	\vOOcast{v_2}{\cOOcast{T_1}{l}{T_3}}
}
%\quad
%\inference{
%	\Gamma , x : T_1 \vdash T_2 &
%	\rho_1 \approx \rho_2
%}{
%	\hcvOOfun{id(T_1)}{\rho_1}{x}{e}{id(T_2)} \approx \vOOfun{\rho_2}{x}{e}
%}
%\quad
%\inference{
%	\hcvOOcons{v_1}{c_1}{v_2}{c_2}
%	\approx
%	v
%}{
%	\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))}
%}
%\\
%\inference{
%	\hcvOOfun{c_1}{\rho}{x}{e}{c_2} : \POOfun{T_1}{T_2} &
%	\hcvOOfun{c_1}{\rho}{x}{e}{c_2} \approx v
%}{
%	\hcvOOfun{seq(cast(T_3,l,T_1), c_1)}{\rho}{x}{e}{seq(c_2,cast(T_2,l,T_4))}
%	\approx
%	\vOOcast{v}{\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T3}{T_4}}}
%}
\end{gather*}

Before proving the weak bisimulation between \effCEK{C} and \ineffCEKD, we 
introduce one more definition: $ s_1 \approx^{*} s_2 $ if and only if there 
exists $ s_2' \in \text{\ineffCEKD} $ 
such that $ \judgeCreduceTrans{s_2}{s_2'}$ and $ s_1 \approx s_2' $.

\todo[inline]{Standardize theorem statement -KC}
\begin{lemma}[Weak Bisimulation between \effCEK{C} and \ineffCEKD]
	\label{thm:surely-monoidic-reduce}
	For all instance of Cast ADT $ C $, 
	if $ C $ is \lazyD{} and is a monoid, 
	$ s_{1}, s_{1}' \in \text{\effCEK{C}} $,
	$ s_{2}, s_{2}' \in \text{\ineffCEKD} $,
	$ s_{1} \approx s_{2} $,
	$ \judgeSreduce{C}{s_{1}}{s_{1}'} $, and
	$ \judgeDreduce{s_{2}}{s_{2}'} $, then
%	then there exist $ s_2'' \in \text{\ineffCEKD} $ such that
	\[ \exists s_2'' \in \text{\ineffCEKD}: \;
	\judgeDreduceTrans{s_{2}'}{s_{2}''} \;\text{and}\; s_1' \approx s_2'' \]
%	\begin{enumerate}
%		\item If $ \judgeDreduce{s_1}{s_3} $,
%		then
%		there exist $ s_5 \in \text{\ineffCEKD} $, $ s_4 \in \mathcal{S}(C) $,
%		such that \begin{itemize}
%			\item $ s_5 \approx s_4 $, and
%			\item $ \judgeSreduce{C}{s_2}{s_4} $,
%			\item $ \judgeDreduceTrans{s_3}{s_5} $
%		\end{itemize}
%		\item If $ \judgeSreduce{C}{s_2}{s_4} $,
%		then
%		there exist $ s_3 \in \mathcal{C} $,
%		such that \begin{itemize}
%			\item $ s_3 \approx s_4 $
%			\item $ \judgeDreduceTrans{s_1}{s_3} $
%		\end{itemize}
%	\end{enumerate}

Or diagrammatically, 
\[\begin{array}{clclc}
s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
\rotatebox[origin=c]{90}{$\approx$} 
& & & \;\;\;\rotatebox[origin=c]{-20}{$\approx$} \\
s_{2} & 
\longrightarrow_{\text{\ineffCEKD}} & s_2' &
\longrightarrow^{*}_{\text{\ineffCEKD}} & s_2'' \\
\end{array}\]

\end{lemma}
\begin{proof}
	By following the transition rule of \ineffCEKD. See the supplementary 
	materials for details.
\end{proof}

\begin{lemma}[$ \text{Lazy D Cast ADT} \cap \text{Monoid} $ Respects 
	$ \mathcal{C} $]
	\label{thm:surely-monoidic-eval}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is a 
	\lazyD{} Cast ADT and a monoid,
	\[
	\text{\evalEqv{\effCEK{C}}{\ineffCEKD}}
	\]
\end{lemma}
\begin{proof}Proving left implies right is trivial.
To prove $ \judgeDeval{e}{o} $ implies $ \judgeSeval{C}{e}{o} $, 
we firstly take one steps in \effCEK{C}, and catch it up in \ineffCEKD\ by 
taking one or more steps in \ineffCEKD. As we just took a positive number of 
steps, we are closer to the halting state.
\end{proof}

\subsection{\lazyD\ Cast ADT Respect \ineffCEKD}
\label{secc:framework:all-correct}

In this subsection, we prove that for all $ C $, if $ C $ is a Lazy D Cast ADT, 
then \evalEqv{\ineffCEKD}{\effCEK{C}}. We first 
prove that all $ S(C) $ where $ C $ is a Lazy D Cast ADT are equivalent, then 
connect this theorem to Lemma~\ref{thm:surely-monoidic-eval}.

We prove the equivalence among \effCEK{S(C)} with strong bisimulation. This 
time almost all the bisimulation relations are all derived from definitions 
except the relaton for casts, which is by cast constructors:
\begin{gather*}
\inference{
}{
	cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
	id_1(T) \approx id_2(T)
}
\quad
\inference{
	c_1 \approx c_2 &
	c_3 \approx c_4
}{
	seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\todo[inline]{Standardize theorem statement -KC}
\begin{lemma}[Strong Bi-simulation among $ \mathcal{S}(\cdot) $]
	\label{thm:CEKS-bisim}
	If 
	$ C_1 $ and $ C_2 $ are instances of Lazy D Cast ADT,
	$ s_1, s_1' \in S(C_1) $ and $ s_2,s_2' \in S(C_2) $,
	$ s_1 \approx s_2 $,
	$ \judgeSreduce{C_1}{s_1}{s_1'} $, and
	$ \judgeSreduce{C_2}{s_2}{s_2'} $, then 
	$ s_1' \approx s_2' $
	
	Or diagrammatically, 
	\[\begin{array}{clc}
	s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
	\rotatebox[origin=c]{90}{$\approx$} 
	& & \rotatebox[origin=c]{90}{$\approx$} \\
	s_{2} & 
	\longrightarrow_{\text{\ineffCEKD}} & s_2' \\
	\end{array}\]
\end{lemma}
\begin{proof} 
	This proof is effectively a duplication of the transition rule of 
	\effCEK{S(C)}.
	The key ideas of this proof are undoing sequencing with the property (2) of 
	Lazy D Cast ADT, and handling all possibly uses of $ 
	cast(T,l,T) $ with property (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of \lazyD{} Cast ADT]
	\label{thm:surely-lazyD-eqv}
	If $ \judgetype{\emptyset}{e}{T} $, $ o : T $, and $ C_1 $ and $ C_2 $ 
	are \lazyD\ Cast ADTs,
	\[
	eval_{S(C_1)} = eval_{S(C_2)}
	\]
\end{proposition}
\begin{proof}
	By induction with the help of Lemma~\ref{thm:CEKS-bisim}.
\end{proof}

\begin{theorem}[\lazyD\ Cast ADT Respects \ineffCEKD]
	\label{thm:surely-lazyD-correct}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is a 
	\lazyD{} Cast ADT.
	\[
	\text{\evalEqv{\ineffCEKD}{\effCEK{C}}}
	\]
\end{theorem}
\begin{proof}
	If we have a Lazy D Cast ADT and it is a monoid, this 
	proof is immediately from Lemma~\ref{thm:surely-monoidic-eval} and 
	Proposition~\ref{thm:surely-lazyD-eqv}. One such representation is to 
	represent casts as a list of triples of type, label, and type, where $ 
	id(T) $ is the empty list and $ seq(c,c) $ is the list append. Another such 
	representation is the \lazyD\ hypercoercion!
\end{proof}


\section{Correctness Proof of \lazyD{} hypercoercions}
\label{sec:hypercoercion-correctness}

In this section we prove \lazyD\ hypercoercion is 
correct. First we define $ applyCast(v,c) $ to make it an instance of Cast ADT, 
then prove that it is also Lazy D, and finally apply 
Theorem~\ref{thm:surely-lazyD-correct} to finish the proof.

\figref{hc-applyCast} defines $ applyCast(v,c) $ for \lazyD\ hypercoercion. 
Applying the identity cast for the 
dynamic type succeeds immediately. When applying a compound cast, we firstly 
apply the middle, then apply the tail. We denote by $ r \; >>= \; f $ to mean 
that if $ r $ is $ \rOOsucc{v} $, the result is $ f(v) $, otherwise the result 
is the failure.
$ applyMiddle(v,\ell,m) $ and $ applyTail(v,t) $ are straightforward.
In the definition of $ applyMiddle(v,\ell,m) $, we generalize 
shallow-consistency to compare middles and values ($ v \smile m $) in the 
natural way.

\begin{figure}
	\fbox{$ applyCast(v,c) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyCast(v,\hyperCoercionI,)}{\rOOsucc{v}}{}
	\funrule{applyCast(\hcvOOinj{P}{v},\hyperCoercionC{?^l}{m}{t})}{
		applyMiddle(v,l,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\funrule{applyCast(v,\hyperCoercionC{\epsilon}{m}{t})}{
		applyMiddle(v,\epsilon,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\end{array}
	\]
	
	\fbox{$ applyMiddle(v,\ell,m) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyMiddle(\hcvOOtt,\ell,\POOunit)}{\rOOsucc{\hcvOOtt}}{}
	\funrule{applyMiddle(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}\ell,\POOfun{c_3}{c_4})}{
		\rOOsucc{(\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\rho}{x}{e}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOcons{v_1}{c_1}{v_2}{c_2},\ell,\POOprod{c_3}{c_4})}{
		\rOOsucc{(\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOinl{v}{c_1},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)})}
	}{}
	\funrule{applyMiddle(\hcvOOinr{v}{c_2},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(v,l,m)}{
		\rOOfail{l}
	}{
		\sidecond{\neg v \smile m}
	}
	\end{array}
	\]
	
	\fbox{$ applyTail(v,t) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyTail(v,\bot^l)}{\rOOfail{l}}{}
	\funrule{applyTail(v,\epsilon)}{\rOOsucc{v}}{}
	\funrule{applyTail(v,!)}{\rOOsucc{(\hcvOOinj{P}{v})}}{}
	\end{array}
	\]
	\caption{\lazyD\ hypercoercion's $ applyCast $}
	\label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} hypercoercion is a \lazyD Cast ADT]
	\label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof} See the supplementary material. \end{proof}

\begin{theorem}[\lazyD{} hypercoercion Respect \ineffCEKD]
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ 
	\[
	\text{\evalEqv{\ineffCEKD}{\effCEK{H}}}
	\]
\end{theorem}
\begin{proof}
	Immediately from Theorem~\ref{thm:surely-lazyD-correct} and 
	Lemma~\ref{thm:hc-surely-lazyD}.
	Alternatively, from Lemma~\ref{thm:surely-monoidic-eval},
	Lemma~\ref{thm:hc-surely-lazyD}, and 
	Proposition~\ref{thm:hc-monoid}.
\end{proof}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile,all}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots


\end{document}
