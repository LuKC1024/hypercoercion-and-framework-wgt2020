%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}
                        
\newtheorem{theorem}{Theorem}[]
\newtheorem{proposition}{Proposition}[]
\newtheorem{corollary}{Corollary}[]
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 & = & #2 & #3\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^l & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}

\begin{document}

%% Title information
\title{Blame and Coercion: Together Again for the Second Time}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{School of Informatics, Computing, and Engineering}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy Siek}

\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
	Gradual Typing is great. Implementing gradually typed with blame tracking 
	and space efficiency is tricky. There exist two technique to do this: 
	coercion and threesome. Coercion is easy to understand, and easy enough to 
	implement, but difficult to reason about formally. Threesome is hard to 
	understand, easy to implement, and easy to reason about formally. We 
	propose hyper-coercion, which is easy to understand, as easy to implement 
	as coercion, and easy to reason about.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\section{Introduction}

\todo[inline]{KC: I want to add more citations here}

\citet{wadler2009well} introduces blame calculus, an intermediate language for 
gradually typed languages. Blame calculus includes blame labels, which tells 
the position of the cast that fails at run time (blame tracking).

Implementing gradually typed languages on top of blame calculus suffices sever 
space leak. Translation to blame calculus might wrap a tail call with a 
cast. Thus, at runtime, mutually tail-recursive functions can accumulate casts 
at tail position.

In 2007, \citet{herman2010space} proposes a solution to this problem by 
translating Blame Calculus to a variant of \citet{henglein1994dynamic}'s 
Coercions Calculus. The key idea is to represent casts with coercions. 
Coercions can be composed and normalized. Their solution, however, doesn't 
include blame tracking. 

After that, many efforts have been made to combine blame tracking and 
space efficiency. 

\citet{siek2009exploring} incorporate blame tracking into Coercion Calculus by 
decorating coercions with labels. They also propose that there are four blame 
strategies for their Coercion Calculi:
$ \{Lazy, Eager\} \times \{D, UD\} $. 
Lazy strategies blame fewer programs than eager ones,
but also detect less potential type errors.
$ D $ and $ UD $ assign blame labels differently.
They prove that $ Lazy UD $ simulates the Blame Calculus in 
\cite{wadler2009well}. But the counterparts of other strategies in Blame 
Calculus is unknown.

\citet{siek2010threesomes} proposes another approach to combine blame 
tracking and space efficiency. Their solution is based on Threesome Calculus, 
an novel alternative to Coercion Calculus. The key idea is to represent casts 
with threesomes. Threesomes, like coercions, can be composed. There is no 
separate normalization for threesome because every threesome is normalized. 
They prove that their Threesome Calculus bisimulate 
\citet{siek2009exploring}'s Coercion Calculus and
\citet{wadler2009well}'s Blame Calculus.

\citet{siek2012interpretations} introduces a $ lazy D $  Blame Calculus. They 
conjecture that this calculus bi-simulate the $ lazy D $ Coercion Calculi.

Following \citet{siek2010threesomes}, \citet{garcia2013calculating} 
implement all other blame strategies with Threesome Calculus. 
He claims that 
coercion with labels is easy to understand but hard to implement, 
and that 
threesome with labels, however, is easy to implement but hard to understand.
His claim is later affirmed by the group of people who develop threesome 
\citet{siek2015blame}. 
The connection 
between his Threesome Calculi and \citet{siek2009exploring}'s Coercion 
Calculi are established by the fact that the former are derived from the latter.
The connection between these calculi and Blame Calculus, however, 
is still unclear.

\citet{siek2015blame} revisit the coercion-based approach. They simplify the 
Coercion Calculi by only working with coercions in canonical forms.
Fortunately, coercions are canonical when initially constructed, and 
their empowered compose function produces canonical coercions as well. Again 
(\citet{siek2010threesomes}), they delegate all strategies other than 
$ Lazy UD $.

Last year, \citet{kuhlenschmidt2018efficient} present Grift, a space-efficient 
and blame-tracking compiler for a gradually typed language of the same name. 
This implementation is based on the $ Lazy D $ Coercion Calculus.
Their result suggests that implementing coercion is practical. And this is the 
first time product types is considered. Their treatment to products in 
coercions, however, is shown incorrect (\citet{Gradual-TypingType-based-casts}).

Recently, \citet{new2019gradual} show that $ Eager $ strategies are 
incompatible with $\eta$-equivalence of functions, which suggest that these 
strategies are not very ideal. Their research kills questions about $ Eager $ 
strategies, but some questions about $ Lazy $ strategies remain open:

\begin{itemize}
	\item Is the $ Lazy D $ coercion an ideal cast representation?
	\item Does the $ Lazy D $ Coercion Calculus bi-simulate the Blame Calculus?
\end{itemize}

The $ Lazy D $ coercion is claimed easy to understand 
(\cite{garcia2013calculating}, \cite{siek2015blame}) and is shown 
easy enough to implement in a compiler (\cite{kuhlenschmidt2018efficient}).
It is still undesirable, however, in a 
few aspects. Firstly, its compose function is not structurally recursive. Many 
developers of Grift report that it is tricky to convince their 
proof assistants that composition terminates. Secondly, canonical coercion
obscures the nature of a ``normalized cast'' because its definition lies on 
top of coercion. 

Perhaps unsurprisingly, threesome has a straightforward recursive 
implementation. And its definition is self-standing. Together with the research 
by \citet{garcia2013calculating}, they suggest that there can be a cast 
representation whose definition is self-standing, and whose composition is 
structurally recursive. Super-coercion introduced in 
\citet{garcia2013calculating} could 
be a promising candidate. However, its definition is a bit complicated. It uses 
10 constructors to deal with an elementary type system with only base types and 
function types. And four constructors are directly related to 
function types. Thus, super-coercion might not scale very well to more 
sophisticated type systems.

We present yet another cast representation, hyper-coercion. Its 
composition is structurally recursive. And its definition is self-standing. 
Besides, there is a clear connection between it and the canonical coercion, 
so we are optimistic that implementing hyper-coercion should be as easy (or 
as hard) as coercion.

Our hyper-coercion considers sum types and product types, which are not 
accounted in all proofs above. Adding each of them requires us to add only one 
new constructor to a component of hyper-coercion. This suggests that 
hyper-coercion might scale better than super-coercion.

We prove formally that $ Lazy D $ (resp. $ Lazy UD $) hyper-coercion calculi 
bi-simulate the $ Lazy D $ (resp. $ Lazy UD $) Blame Calculi. This is possibly 
the first bi-simulation proof for the $ Lazy D $ Blame Calculus.

The structure of this paper is as follows. Section \ref{sec:blame-calculus} 
reviews the state-of-art of $Lazy$ Coercion Calculi. In section 
\ref{sec:hyper-coercion} we present Hyper-coercion. Section \ref{sec:conclude} 
concludes.

\section{Blame Calculus} \label{sec:blame-calculus}

\begin{figure}
	\[
	\begin{array}{lclr}
	\stxrule{S,T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P,Q}{pre-types}{
		\iota \mid{}
		T_1 \rightarrow T_2 \mid{}
		T_1 \times T_2 \mid{}
		T_1 \plus T_2 \mid{}
	}
%	\stxrule{x,y,z}{variables}{\dots}
%	\stxrule{l}{labels}{\dots}
%	\stxrule{k}{constants}{sole}
	\stxrule{e}{terms}{
		x \mid{}
		\mathtt{tt} \mid{}
		\lambda^{S\rightarrow{}T}x.t \mid{}
		e_1 \; e_2 \mid{}
		\langle T \Leftarrow^l S \rangle t \mid{}
		\mathtt{blame} \; l
	}
	\stxrulecont{
		\mathtt{cons}\; e_1 \; e_2 \mid{}
		\mathtt{car}\; e \mid{}
		\mathtt{cdr}\; t
	}
	\stxrulecont{
		\mathtt{inl} \; e \mid{}
		\mathtt{inr} \; e \mid{}
		\mathtt{case}\; e_1 \; e_2 \; e_3
	}
	\stxrule{o}{observations}{
		\mathtt{tt} \mid{}
		\mathtt{fun}\mid{}
		\mathtt{cons}\mid{}
		\mathtt{inl}\mid{}
		\mathtt{inr}\mid{}
		\mathtt{blame}\; l
	}
	\end{array}
	\]
	
	\fbox{$ S \sim T $}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	\fbox{$ S \smile T $}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		S_1 \rightarrow T_1 \smile S_2 \rightarrow T_2
	}
	\inference{}{
	S_1 \times T_1 \smile S_2 \times T_2
	}
	\inference{}{
	S_1 \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	\fbox{$ \Gamma \vdash e \vdash T $}
	\begin{gather*}
		\inference{
			S \sim T & \Gamma \vdash e : S 
		}{
			\judgetype{\Gamma}{\langle T \Leftarrow^l S \rangle t}{T}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\mathtt{blame} l}{T}
		}
	\end{gather*}
	
	\caption{Blame Calculus and its static semantics}
	\label{fig:blame-static}
\end{figure}

\figref{fig:blame-static} defines the form of blame calculus and its static 
semantics. It is little changed from previous definitions. 
The dynamic semantics of Blame Calculi depend on blame strategies, so we defer 
them to sub-sections.

Blame Calculus is based on Simply Typed Lambda Calculus with sum types and 
product types ($ \mathtt{STLC+} $). 
Let $ S,T $ range over types. A type is either the dynamic type $ \star $
(a.k.a. $ \mathtt{Dyn} $, $ \mathbb{?} $, or $ \mathtt{Unknown} $), 
or a pre-type. 
Let $ P,Q $ range over pre-types. Every pre-type is a type with a 
traditional type constructor at the top.

$ S \sim T $ reads $ S $ and $ T $ are consistent. Two types are consistent if 
one of them is $ \star $, or they have the same top-most type constructor and 
the corresponding sub-parts are consistent. Consistency is reflexive and 
symmetric, but not transitive.

$ S \smile T $ reads $ S $ and $ T $ are shallowly-consistent. Two types are 
shallowly-consistent if one of them is $ \star $, or they have the same 
top-most type constructor. 
Shallow-consistency is also reflexive, symmetric, and not transitive.

Let $ e $ ranges over terms. Unlike $ \mathtt{STLC+} $, we annotate the 
co-domain of lambda abstractions explicitly. Besides, we add casts and blames.

Let $ o $ ranges over observations.

Now let's move to the dynamic semantics. 

\subsection{$Lazy D$ Blame Calculus}

We describe the dynamic semantics of Blame Calculus with the CEK machine 
(\citet{felleisen1986control}).

\subsection{$Lazy UD$ Blame Calculus}

subtyping, reduction ...

\section{Coercion Calculus}

\subsection{$Lazy D$ Coercion Calculus}

\subsection{$Lazy UD$ Coercion Calculus}

\section{Hyper-coercion} \label{sec:hyper-coercion}

\begin{figure}
	\[ 
	\begin{array}{lclr}
	\stxrule{c}{hyper-coercions}{
		id* \mid{}
		( h , ( b , t ) )
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{b}{bodies}{
		U \mid{}
		c_1 \rightarrow c_2 \mid{}
		c_1 \times c_2 \mid{}
		c_1 \plus c_2
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
	
	\fbox{$ c \fatsemi^l c = c $}
	\[ 
	\begin{array}{rclclr}
	\comprule{id*}{id*}{
		id*
	}{}
	\comprule{id*}{( ?^{l'} , ( b , t ) )}{
		( ?^{l'} , ( b , t ) )
	}{}
	\comprule{id*}{( ! , ( b , t ) )}{
		(?^{l} , ( b , t))
	}{}
	\comprule{(h , (b ,\bot^{l'}))}{c}{
		(h , (b ,\bot^{l'}))
	}{}
	\comprule{(h , (b_1 , t_1))}{id*}{
		(h , (b_1 , !))
	}{t_1 \neq \bot^{l'}}
	\comprule{(h , (b_1 , t_1))}{(\epsilon , (b_2 , t_2))}{
		(h , b_1 \fatsemi^{l} (b_2 , t_2))
	}{t_1 \neq \bot^{l'}}
	\comprule{(h , (b_1 , t_1))}{(?^{l'} , (b_2 , t_2))}{
		(h , b_1 \fatsemi^{l'} (b_2 , t_2))
	}{t_1 \neq \bot^{l'}}
	\end{array}
	\]
	
	\fbox{$ b \fatsemi^l (b,t) = (b,t) $}
	\[ 
	\begin{array}{rclclr}
	\comprule{U}{(U,t)}{
		(U,t)
	}{}
	\comprule{c_1 \rightarrow c_2}{(c_3 \rightarrow c_4,t)}{
		(c_3 \fatsemi^{l} c_1 \rightarrow c_2 \fatsemi^l c_4, t)
	}{}
	\comprule{c_1 \times c_2}{(c_3 \times c_4,t)}{
		(c_3 \fatsemi^{l} c_1 \times c_2 \fatsemi^l c_4, t)
	}{}
	\comprule{c_1 \plus c_2}{(c_3 \plus c_4,t)}{
		(c_3 \fatsemi^{l} c_1 \plus c_2 \fatsemi^l c_4, t)
	}{}
	\comprule{b_1}{(b_2,t_2)}{
		(b_1,\bot^l)
	}{}
	\end{array}
	\]
	
	\fbox{$ seq(c,c) = c $}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^l c_2
	}{}
	\end{array}
	\]
	
	\fbox{$ id( T ) = c $}
	\[
	\begin{array}{rclr}
	\funrule{id(*)}{
		id*
	}{}
	\funrule{id(P)}{
		(\epsilon,(id(P),\epsilon))
	}{}
	\end{array}
	\]
	
	\fbox{$ id( P ) = b $}
	\[
	\begin{array}{rclr}
	\funrule{id(U)}{U}{}
	\funrule{id(T_1 \rightarrow T_2)}{
		id(T_1) \rightarrow id(T_2)
	}{}
	\funrule{id(T_1 \times T_2)}{
		id(T_1) \times id(T_2)
	}{}
	\funrule{id(T_1 \plus T_2)}{
		id(T_1) \plus id(T_2)
	}{}
	\end{array}
	\]
	
	\fbox{$ cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	

	\caption{$Lazy D$ Hyper-coercion}
	\label{fig:HC-D}
\end{figure}

\subsection{$Lazy D$ Hyper-coercion}

The syntax of $ Lazy D $ Hyper-coercion is shown in \figref{fig:HC-D}.

\begin{theorem}[$ Lazy D $ Hyper-coercion is a proper cast representation]
	\  \\
\begin{enumerate}
	\item If $ v : T $, then $ id(T) \; v = \mathtt{succ} \; v $
	\item If $ v : T_1 $,
	$ c_1 $ is a hyper-coercion from $ T_1 $ to $ T_2 $, and 
	$ c_2 $ is from $ T_2 $ to $ T_3 $,\\
	then $ seq(c_1,c_2) \; v = (c_1 \; v) >>= c_2 $
	\item If $ v : T_1 $ and $ \neg T_1 \smile T_2 $,
	then $ cast(T_1, l, T_2) \; v = \mathtt{fail} \; l $
	\item If $ v : \star $, 
	then $ cast(\star,l,\star) \; v = \mathtt{succ} \; v $
	\item If $ v : P $,
	then $ cast(\star,l,Q) \; (inj \; P \; v) = cast(P,l,Q) \; v $
	\item If $ v : P $,
	then $ cast(P,l,\star) \; v = \mathtt{succ} \; (inj \; P \; v) $
	\item If $ v : \iota $,
	then $ cast(\iota,l,\iota) \; v = \mathtt{succ} \; v $
	\item $ cast(S_1 \rightarrow T_1,l,S_2 \rightarrow T_2) \; (fun \; c_1 \; 
	E \; b \; c_2) $ \\
	$ = \mathtt{succ} \; fun \; seq(cast(S_2,l,S_1),c_1) \; E \; b 
	\; seq(c_2,cast(T_1,l,T_2)) $ 
	\item $ cast(S_1 \times T_1,l,S_2 \times T_2) \; (cons \; v_1 \; c_1 \; 
	v_2 \; c_2) $ \\
	$ = \mathtt{succ} \; (cons \; v_1 \; seq(c_1,cast(S_1,l,S_2)) \; v_2 \; 
	seq(c_2,cast(T_1,l,T_2))) $ 
	\item $ cast(S_1 \plus T_1,l,S_2 \plus T_2) \; (inl \; v \; c) = 
	\mathtt{succ} \; (inl \; v \; seq(c,cast(S_1,l,T_1)) ) $ 
	\item $ cast(S_1 \plus T_1,l,S_2 \plus T_2) \; (inr \; v \; c) = 
	\mathtt{succ} \; (inr \; v \; seq(c,cast(S_2,l,T_2)) ) $ 
\end{enumerate}
\end{theorem}

\begin{proposition}[Every proper cast represenation is correct]
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $
	\[
	e \Downarrow_{B}^{D} o \; \text{if and only if} \; 
	e \Downarrow_{C}^{D} o
 	\]
\end{proposition}

\begin{corollary}[$ Lazy D $ hyper-coercion is correct]
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $
	\[
	e \Downarrow^{D}_{B} o \; \text{if and only if} \; 
	e \Downarrow^{D}_{H} o
	\]
\end{corollary}

\subsection{$Lazy UD$ Hyper-coercion}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
