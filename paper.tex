%% For double-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{Lazy\;UD}
\newcommand{\lazyD}{Lazy\;D}
\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}
\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{#1 \; #2}
\newcommand{\eOOcons}[2]{\mathtt{cons} \; #1 \; #2}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{#1 \langle \cOOcast{#2}{#3}{#4} \rangle}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\cOOcast}[3]{#1 \Rightarrow^{#2} #3}
\newcommand{\oOOinj}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\vOOcast}[2]{#1\langle#2\rangle}
\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}
\newcommand{\kOOmt}[0]{\mathtt{stop}}
\newcommand{\kOOconsI}[3]{\mathtt{cons_1} \; #1 \; #2 \; #3}
\newcommand{\kOOconsII}[2]{\mathtt{cons_2} \; #1 \; #2}
\newcommand{\kOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\kOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\kOOappI}[3]{
	\mathtt{app_1} \; #1 \; #2 \; #3
}
\newcommand{\kOOappII}[2]{
	\mathtt{app_2} \; #1 \; #2}
\newcommand{\kOOcar}[1]{
	\mathtt{fst} \; #1}
\newcommand{\kOOcdr}[1]{
	\mathtt{snd} \; #1}
\newcommand{\kOOcaseI}[4]{
	\mathtt{case_1} \; #1 \; #2 \; #3 \; #4}
\newcommand{\kOOcaseII}[4]{
	\mathtt{case_2} \; #1 \; #2 \; #3 \; #4}
\newcommand{\kOOcaseIII}[3]{
	\mathtt{case_3} \; #1 \; #2 \; #3}
\newcommand{\kOOcast}[2]{
	\langle #1 \rangle #2}
\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{inj} \; #2}
\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D cast calculus on space-inefficient CEK
\newcommand{\judgeCreduce}[2]{#1 \longmapsto_{\mathcal{C}} #2}
\newcommand{\judgeCreduceTrans}[2]{#1 \longmapsto_{\mathcal{C}}^{*} #2}
\newcommand{\judgeCeval}[2]{eval_{\mathcal{C}}(#1) = #2}
\newcommand{\redrule}[3]{#1 & \longmapsto_\mathcal{C} & #2 & #3\\}
\newcommand{\hiredrule}[3]{\highlight{#1} & \highlight{\longmapsto_\mathcal{C}} & \highlight{#2} & \highlight{#3} \\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longmapsto_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longmapsto_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{eval_{\mathcal{S}(#1)}(#2) = #3}
\newcommand{\redruleS}[3]{#1 & \longmapsto_{\mathcal{S}(C)} & #2 & #3\\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hypercoercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvSD}[3]{#2 \approx_{\mathcal{SD}} #3}
% to-dos
\newcommand{\todoKC}[1]{\todo[inline]{KC needs to #1}}
\newcommand{\todoKCFixed}[0]{\todo[inline]{Fixed. -KC}}
% abbrev
\newcommand{\castCalculus}[0]{$\lambda_{\rightarrow}^{\langle\cdot\rangle}$}
% names
\newcommand{\ineffCEK}{$ \mathcal{C} $}
\newcommand{\ineffCEKD}{$ \mathcal{D} $}
\newcommand{\ineffCEKUD}{$ \mathcal{UD} $}
\newcommand{\judgeDreduce}[2]{#1 \longmapsto_{\mathcal{D}} #2}
\newcommand{\judgeDreduceTrans}[2]{#1 \longmapsto_{\mathcal{D}}^{*} #2}
\newcommand{\judgeDeval}[2]{eval_{\mathcal{D}}(#1) = #2}
\newcommand{\effCEK}[1]{$ \mathcal{S}(#1) $}
\newcommand{\evalEqv}[2]{$ eval_{\text{#1}} = eval_{\text{#2}} $}
\newcommand{\continue}[2]{continue(#2,#1)}
\newcommand{\highlight}[1]{{\color{red} #1}}

\begin{document}

%% Title information
\title{Hypercoercions and a Framework for Equivalence of Cast Calculi}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  Designing a space-efficient cast representation that is good for
  both mechanized metatheory and implementation is
  challenging. Existing solutions are good for one or the other. This
  paper presents a new cast representation, named hypercoercions, that
  is good for both. On the way to proving the correctness of
  hypercoercions, this paper also makes progress on a general
  framework for proving the correctness of cast representations.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\listoftodos{}


\section{Introduction}

\todo[inline]{I see lots of mistakes regarding when to make words
  plural (whether they should have an ``s'' at the end). Please review
  the rules of English regarding plurals. The rules are tricky...
  some words don't have a plural form, like ``blame''. -JS
  \\---\\
  Will fix grammar after fixing all other problems -KC}

Around 2006, several groups of researchers proposed ways to integrate
dynamic typing and static typing, notably gradual typing
\citep{siek2006gradual}, hybrid typing \citep{flanagan2006hybrid},
migratory typing \citep{Tobin-Hochstadt:2006fk}, and multi-language
iteroperability \citep{Gray:2005ij,Matthews:2007zr}. Researchers
usually define the semantics of gradually typed languages by
translation to an intermediate language with casts, such as the blame
calculus \citep{wadler2009well} and other cast calculi
\citep{siek2009exploring}. Unfortunately, straightforward
implementations of casts on higher-order values (functions, objects,
etc.) impose significant runtime overheads that can change the
asymptotic time and space complexity of a program
\citep{herman2010space}. There are several known space-efficient cast
representations, with various strengths and weaknesses
\citep{siek2015blame,siek2010threesomes,garcia2013calculating,kuhlenschmidt2018efficient,siek2012interpretations,garcia2014deriving}.
The current state of the art includes
\begin{itemize}
\item threesomes \citep{siek2010threesomes},
\item supercoercions \citep{garcia2014deriving}, and
\item coercions in normal form
  \citep{siek2012interpretations,siek2015blame}.
\end{itemize}
Recall that in these systems, casts are compressed using a composition
operator.  Threesomes and supercoercions are good for mechanized
metatheory because their compose operators are structurally recursive,
making them easy to define in a proof assistant such as Agda. In
contrast, the coercions in normal form have compose operators that are
not structurally recursive, which makes it more difficult to define in
Agda, requiring what amounts to an explicit proof of termination.
%
On the other hand, coercions in normal form are easier to understand
than threesomes (with a strange labelled bottom type), and
supercoercions (10 different kinds).

This paper presents a new cast representation, named
\emph{hypercoercions}, that is good for both mechanized metatheory and
good for implementation. The composition operator for hypercoercions
is defined by structural recursion and hypercoercions are suggestive
of a bit-level representation that minimizes the need for pointers and
fits all first-order casts into 64 bits. We present two flavors of
hypercoercions to support the two blame tracking strategies from the
literature: D and UD~\citep{siek2009exploring}. We are interested in
the D blame tracking strategy because it comes with a more
straightforward notion safe cast compared to
UD~\citep{siek2009exploring}, which is why D was chosen Grift
compiler. We are also intersted in UD because it plays a prominent
role in the gradual typing literature \citep{wadler2009well}. The
semantics of casts can also be lazy or
eager~\citep{siek2009exploring}. In this paper we focus on lazy cast
strategies because we suspect that they are more efficient than eager
strategies and because \citet{new2019gradual} show that eager
strategies are incompatible with $\eta$-equivalence of functions.

Of course, an alternative cast representation must be proved
correct. This paper presents steps toward a general framework for
proving equivalence of cast calculi and, in particular, proves that an
abstract machine using \lazyD{} hypercoercions is equivalent to an
abstract machine using standard \lazyD{}
casts~\citep{siek2009exploring}. We conjecture that the framework can
be generalized to \lazyUD{} and that it can be applied to coercions in
normal form and threesomes.

To summarize, the primary contributions of this paper are:
\begin{itemize}
\item hypercoercions, a new space-efficient cast representation, which
  has a structurally recursive composition and a more compact memory
  representation.
\item a framework in Agda for proving the correctness of cast
  represantations.
\item a formal proof that hypercoercion respects the semantics
  of the \lazyD{} cast calculus.
\end{itemize}

In Section~\ref{sec:background} we review cast calculi and coercions.
We present hypercoercions in
Section~\ref{sec:hypercoercion-definition}.  We present a framework
for proving correctness of cast reprensentations in
Section~\ref{sec:framework} and use it to prove the correctness of
\lazyD{} hypercoercions in
Section~\ref{sec:hypercoercion-correctness}.

\section{Background} \label{sec:background}

In this section, we review lazy cast calculi
(Section~\ref{sec:cast-calculi}) and coercion in normal form
(Section~\ref{sec:coercion-calculus}).

\subsection{Cast Calculi}
\label{sec:cast-calculi}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P}{pre-types}{
		\POOunit \mid
		\POOfun{T_1}{T_2} \mid
		\POOprod{T_1}{T_2} \mid
		\POOsum{T_1}{T_2}
	}
	\stxrule{e}{terms}{
		\eOOvar{x} \mid{}
		\eOOsole{} \mid{}
		\eOOlam{T_1}{T_2}{x}{e} \mid
		\eOOapp{e_1}{e_2} \mid
		\eOOcons{e_1}{e_2} \mid
		\eOOcar{e} \mid
		\eOOcdr{e}
	}
	\stxrulecont{
		\eOOinl{e} \mid
		\eOOinr{e} \mid
		\eOOcase{e_1}{e_2}{e_3} \mid
		\eOOcast{e}{T_1}{l}{T_2} \mid
		\eOOblame{l}
	}
	\end{array}
	\]
	
	Consistency
	\fbox{$ T_1 \sim T_2 $}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\[1ex]
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	Term typing
	\fbox{$ \judgetype{\Gamma}{e}{T} $}
	\begin{gather*}
          \dots \qquad
		\inference{
			\Gamma \vdash e : T_1 & T_1 \sim T_2
		}{
			\judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\eOOblame{l}}{T}
		}
	\end{gather*}
	
	\caption{Syntax and static semantics of the cast calculi.}
	\label{fig:blame-static}
\end{figure}


\paragraph{Syntax and Static Semantics}

The syntax and static semantics is the same for the \lazyD{} and
\lazyUD{} cast calculi, and is reviewed in \figref{fig:blame-static}.
As usual, the important features are the cast expressions,
$\eOOcast{e}{T_1}{l}{T_2}$, which are responsible for runtime type
checking, and blame expressions, $\eOOblame{l}$, that raise errors.
The syntax and static semantics is the same that of
\citet{siek2009exploring} except for a few minor exceptions:
\begin{itemize}
\item We add sum, product, and unit types.
\item We separate types into those with a type constructor at the top,
  the \emph{pretypes} ($\POOunit$, functions, products, and sums),
  versus the dynamic type $\star$ (a.k.a. $ \mathtt{Dyn} $ or
  $\mathbb{?}$).
\item We annotate the codomain of a lambda abstraction explicitly
  because we refer to it in the dynamic semantics. 
\end{itemize}
As usual, the source $T_1$ and target types $T_2$ of a cast
$\eOOcast{e}{T_1}{l}{T_2}$ are required to be consistent, written $T_1
\sim T_2$. The consistency relation is standard and defined in
\figref{fig:blame-static}.

%% defines the syntax of the cast calculus and
%% its static semantics. We extend the syntax of
%%  with sum and product types.  Let $ T $ range
%% over types. A type is either the dynamic type $ \star $ (a.k.a. $
%% \mathtt{Dyn} $, $ \mathbb{?} $, or $ \mathtt{Unknown} $), or a type

%% As usual we write $ T_1 \sim T_2 $ when $ T_1 $ and $ T_2 $ are
%% consistent. The intuition of $ T_1 \sim T_2 $ is that $ T_1 $ and $
%% T_2 $ have no conflicting type information. Two types are consistent
%% if one of them is $ \star $, or they have the same top-most type
%% constructor and the corresponding sub-parts are
%% consistent. Consistency is reflexive and symmetric, but not
%% transitive.

%% We write $ T_1 \smile T_2 $ when $ T_1 $ and $ T_2 $ are
%% shallowly-consistent, that is, if one of them is $ \star $, or they
%% have the same type constructor at the top. Shallow-inconsistency is
%% the root of all blame in lazy cast strategies -- casting a value to a
%% shallowly inconsistent type leads to a blame. Shallow-consistency is
%% reflexive, symmetric, but not transitive.

%% Let $ e $ range over terms. Most terms are standard for a simply-typed
%% lambda calculus. We annotate the codomain of a lambda abstraction
%% explicitly because we refer to it in the dynamic semantics. Becuase
%% this is a cast calculus, we have two additional terms: cast
%% expressions and blame expressions. Cast expressions perform runtime
%% type checks and blame expressions raise an error.


\paragraph{Dynamic Semantics}

The dynamic semantics of a cast calculus is typically defined with a
reduction semantics. Here we use a CEK machine
\citep{felleisen1986control} instead because the first author is more
familiar with CEK machines and believes that a CEK machine is more
convenient to use for the space-efficient semantics in
Section~\ref{sec:framework:cek} (space-efficiency is about compressing
continuations). So using an abstract machine for the cast calculi in
this section makes it easier prove correctness of the space-efficient
machines. Of course, one should prove that the abstract machine
presented here is equivalent to the standard reduction semantics for
cast calculi, but we have not yet done so.

Fig.~\ref{fig:machine-cekc} defines the transition relation of the CEK
machine and Fig.~\ref{fig:state} gives a grammar for machine states
$s$, including a definition of values and value typing. The
transitions involving casts are highlighted in red and described in
more detail below. The other transitions are standard for a CEK
machine for an extended simply typed lambda calculus.
%
Recall that CEK machine involves two kinds of transitions, (1) those
that dive further into an expression (looking for a redex) and push an
entry onto the continuation, and (2) those that return a value to the
current continuation and possibly perform a computation.
Corresponding to (1) and (2), the machine state is either in an
$\mathtt{Eval}$ or $\mathtt{Cont}$ configuration, respectively.
Additionally, there is the $\mathtt{Halt}$ configuration.

The transition relation $\judgeCreduce{s}{s}$ is parameterized over
$applyCast$ to allow for the differences between D and UD.
%
When evaluating a cast expression, the machine moves the cast to the
continuation and evaluates the inner expression.
%% Other
%% transition rules starting from $ Eval $ states are standard.
To apply a casted function, the machine first casts $ v_1 $, the
operand, then applies the casted operand to $ v_2 $, the underlying
function, and finally cast the result of the function application.
%
To take out the first (resp. second) part of a casted pair, the
machine firstly take out the first (resp. second) part of $ v $, the
underlying pair, and cast the result.
%
In case splitting, if the target value is a left injection, the
machine moves to a state that will apply the first continuation
function to the value inside the left injection. The case for right
injection is similar.
%
When the target value is a casted sum, the machine moves the cast from
the target value to continuations functions.
%
To cast a value, the machine invokes $applyCast$ on the value.  If the
cast succeeds, the machine returns the result to the next
continuation.  If the cast fails, the machine halts with the blame
label.
%
%% When the continuation is $ stop $, the machine enters a halting
%% state. The When the machine is in a halting state, it stays in the
%% same state.

The reflexive transitive closure of reduction ($
\judgeCreduceTrans{s}{s} $) and evaluation ($ eval_\mathcal{C}(e) $)
are standard~\citep{felleisen03:_pllc}.


\begin{figure}
  Machine state and other runtime data structures
  \[
  \begin{array}{rclr}
	\stxrule{v}{values}{
		\vOOtt{} \mid
		\vOOfun{\rho}{x}{e} \mid
		\vOOcons{v_1}{v_2} \mid
		\vOOinl{v} \mid
		\vOOinr{v} \mid		
		\vOOcast{v}{c}
	}
	\stxrule{c}{casts}{
		\cOOcast{T_1}{l}{T_2}
	}
	\stxrule{I}{injectable types (\lazyD)}{
		P
	}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\star}{\star} \mid
		\star \times \star \mid
		\star + \star
	}
	\stxrule{o}{observations}{
		\oOOinj \mid
		\oOOsole \mid
		\oOOfun \mid
		\oOOcons \mid
		\oOOinl \mid
		\oOOinr \mid
		\oOOblame{l}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuations}{
		\kOOmt \mid
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa} \mid
		\kOOinr{\kappa}
	}
	\stxrulecont{
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa} \mid
		\kOOcdr{\kappa} \mid
		\kOOcaseI{e_1}{e_2}{\rho}{\kappa}
	}
	\stxrulecont{	
		\kOOcaseII{v}{e}{\rho}{\kappa} \mid
		\kOOcaseIII{v_1}{v_2}{\kappa} \mid
		\kOOcast{c}{\kappa}
	}
  \end{array}
  \]

        Shallow-consistency
	\fbox{$ T_1 \smile T_2 $}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
	} \quad
	\inference{}{
		T_{11} \times T_{12} \smile T_{21} \times T_{22}
	} \quad
	\inference{}{
	T_{11} \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	Value typing \fbox{$ v : T $}
	\begin{gather*}
	\dots \qquad
	\inference{
		v : I
	}{
		\vOOcast{v}{\cOOcast{I}{l}{\TOOdyn}} : \TOOdyn
	}
	\quad
	\inference{
		v : P_1 &
		P_1 \smile P_2
	}{
		\vOOcast{v}{\cOOcast{P_1}{l}{P_2}} : P_2
	}
	\end{gather*}
        \caption{Definition of machine state and auxilliary data
          structures.}
        \label{fig:state}
\end{figure}

Let $ v $ range over values. A value is either the unit, a function (a
closure), a pair, a left injection, a right injection, or a casted
value. As shown by the value typing rules, if the target type of a
casted value is the dynamic type, the underlying value must be of an
injectable type. The definition of injectable types depends on blame
strategies: for the \lazyD\ strategy, every pre-type is injectable;
for the \lazyUD\ strategy, a pre-types is injectable if and only if
all its sub-parts are the dynamic type. If the target type of a casted
value is a pre-type, the type of the underlying value must have the
same type constructor.

Let $ c $ range over casts. A cast is a triple of a type, a label, and a type.

Let $ o $ range over observations. They are what would be observed if
a program terminates. Observations include all value constructors and
blame.  The function converting values to observations ($ observe(v) =
o $) is defined in the natural way.

\begin{figure}
	%	Continuation typing \fbox{$ \kappa : T_1 \Longrightarrow T_2 $}
	%	\begin{gather*}
	%	\dots \quad
	%	\inference{
	%		c : T_1 \Longrightarrow T_2 &
	%		\kappa : T_2 \Longrightarrow T_3
	%	}{
	%		\langle c \rangle \kappa : T_1 \Longrightarrow T_3
	%	}
	%	\end{gather*}
	
	\[
	\begin{array}{rclr}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeCreduce{s}{s} $}
	\[
	\begin{array}{rclr}
		\hiredrule{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{\langle\cOOcast{T_1}{l}{T_2}\rangle\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho(x)}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\vOOtt}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\vOOfun{\rho}{x}{e})}{\kappa}
	}{}
	\redrule{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{(\kOOconsI{e_2}{\rho}{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{(\kOOinl{\kappa})}
	}{}
	\redrule{
	\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
	\sOOinspect{e}{\rho}{(\kOOinr{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
\sOOinspect{e_1}{\rho}{(\kOOappI{E}{e_2}{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
\sOOinspect{e}{\rho}{(\kOOcar{\kappa})}}{}

\redrule{
	\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
	\sOOinspect{e}{\rho}{(\kOOcdr{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
\sOOinspect{e_1}{\rho}{(\kOOcaseI{E}{e_2}{e_3}{\kappa})}}{}

\redrule{
\sOOreturn{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOconsII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
\sOOreturn{(\vOOcons{v_1}{v_2})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinl{\kappa})}}{
\sOOreturn{(\vOOinl{v})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinr{\kappa})}}{
\sOOreturn{(\vOOinr{v})}{\kappa}}{}

\redrule{
\sOOreturn{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOappII{(\vOOfun{\rho}{x}{e})}{\kappa})}}{
\sOOinspect{e}{\rho[x:=v_2]}{\kappa}}{}
	\hiredrule{
		\sOOreturn{v_1}{(\mathtt{app_2} \; \vOOcast{v_2}{
				\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
			} \; \kappa)}
	}{
		\sOOreturn{v_1}{
			\langle\cOOcast{T_3}{l}{T_1}\rangle
			(\mathtt{app_2} \; v_2 \; 
			\langle\cOOcast{T_2}{l}{T_4}\rangle \kappa)}
	}{}
	\redrule{
	\sOOreturn{
		(\vOOcons{v_1}{v_2})
	}{(\mathtt{fst} \; \kappa)}
	}{
	\sOOreturn{v_1}{\kappa}
	}{}
	\hiredrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{fst} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{fst} \;
			\langle \cOOcast{T_1}{l}{T_3} \rangle \kappa
			)}
	}{}
	\redrule{
	\sOOreturn{
		(\vOOcons{v_1}{v_2})
	}{(\mathtt{snd} \; \kappa)}
	}{
	\sOOreturn{v_2}{\kappa}
	}{}
	
	\hiredrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{snd} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{snd} \;
			\langle \cOOcast{T_2}{l}{T_4} \rangle \kappa
			)}
	}{}

\redrule{
\sOOreturn{v_1}{(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_3}{\rho}{
	(\kOOcaseIII{v_1}{v_2}{\kappa})
}}{}	

\redrule{
\sOOreturn{v_3}{(\mathtt{case_3}\;(\vOOinl{v})\;v_2\;\kappa)}
}{
\sOOreturn{v}{(\kOOappII{v_2}{\kappa})}
}{}

\redrule{
	\sOOreturn{v_3}{(\mathtt{case_3}\;(\vOOinr{v})\;v_2\;\kappa)}
}{
\sOOreturn{v}{(\kOOappII{v_3}{\kappa})}
}{}

\redrule{
	\highlight{\sOOreturn{v_3}{(\mathtt{case_3}\;
		(\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}})
		\;v_2\;\kappa)}}
}{
	\highlight{\sOOreturn{v_3'}{
		(\mathtt{case_3}\;v
		\;v_2'\;\kappa)
	}}
}{\\&&
\highlight{\text{where}\;
v2' = \vOOcast{v_2}{\cOOcast{\POOfun{T_4}{T}}{l}{\POOfun{T_2}{T}}}}
\\&&
\highlight{\text{and}\;
v3' = \vOOcast{v_3}{\cOOcast{\POOfun{T_3}{T}}{l}{\POOfun{T_1}{T}}}}
}
	
	\redrule{
		\highlight{\sOOreturn{v}{(
			\mathtt{cast} \; c \; \kappa
			)}}
	}{
\highlight{          
\begin{cases}
	\sOOreturn{u}{\kappa} & \sidecond{applyCast(v,c) = \rOOsucc{u}}
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
\end{cases}}
	}{}
\redrule{
\sOOreturn{v}{\kOOmt}}{
\sOOhalt{observe(v)}}{}
	\end{array}
	\]	
	
	Evaluation \fbox{$\judgeCeval{e}{o}$}
	\[
	\inference{
		\sOOinspect{e}{\emptyset}{cont(\hckOOmt)} \longrightarrow_{B}^{*} 
		\sOOhalt{o}
	}{
		\judgeCeval{e}{o}
	}
	\]
	
	\caption{Dynamic semantics of the cast calculi as a CEK
          machine. The transitions that involve casts are highlighted
          in red.}
	\label{fig:machine-cekc}
\end{figure}

\todo[inline]{There are missing transition rules for fst and snd. -JS}

Let $ r $ range over cast results. A cast result is either a success, which 
brings back a value, or a failure, which brings a blame label.

Let $ s $ range over machine states. A state is either looking at an 
expression to decide what to do next, returning a value to a continuation, or 
halting with an observation.

Let $ \kappa $ range over continuations. $ \mathtt{stop} $ is the top 
continuation. The remaining continuations correspond to expressions. For 
example, $ (\mathtt{cons_1} \; e \; \rho \; \kappa) $ is the continuation where 
we are waiting for the value of the first argument to a $ \mathtt{cons} $. And 
the last continuation, $ \langle c \rangle \kappa $ is to cast the value before 
returning to $ \kappa $.


\subsection{The \lazyD{} cast calculus}

\begin{figure}
	
	\fbox{$applyCast(v,c) = r$}
	\[
	\begin{array}{rclr}
	\funrule{
		applyCast(v,\cOOcast{\star}{l}{\star})
	}{
		\rOOsucc{v}
	}{}
	\funrule{
		applyCast(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
	}{
		applyCast(v,\cOOcast{P_1}{l_2}{P_2})
	}{}
	\funrule{
		applyCast(v,\cOOcast{P}{l}{\star})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
	}{}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
	}{\sidecond{P_1 \smile P_2}}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOfail{l}
	}{\sidecond{\neg P_1 \smile P_2}}
	
	\end{array}
	\]
	\caption{Definition of $ applyCast $ for \lazyD}
	\label{fig:applyCast-D-C}
\end{figure}

\figref{fig:applyCast-D-C} defines the $ applyCast $ for \lazyD. 
We conjecture that with this $ applyCast $, the CEK machine in 
\figref{fig:machine-cekc} would agree with the \lazyD{} cast calculus in 
\citet{siek2009exploring}. We denote this \lazyD{} machine by \ineffCEKD{},
and the corresponding relations by $ \judgeDreduce{s}{s} $, $ 
\judgeDreduceTrans{s}{s} $, and $ \judgeDeval{e}{o} $

\subsection{The \lazyUD{} cast calculus [Jeremy]}

\todo[inline]{I need to update this subsection. -JS}

The dynamic semantics of the \lazyUD{} cast calculus, which we define here as a
CEK machine, is similar to that of the \lazyD{} cast calculus
(Fig. \ref{fig:machine-cekc}). The only difference is in the definition of
the $\mathit{applyCast}$ function, in which a cast whose source or
target is the unknown type $\star$ is always split into two casts that
go through an injectiable type, that is, a type in which all
sub-components are the unknown type, such as $\star \to \star$. The
definition of $\mathit{applyCast}$ for the \lazyUD{} cast calculus is given in
Fig.~\ref{fig:apply-Cast-UD}.

\begin{figure}
%
%  Syntax
%  \[
%  \begin{array}{rclr}
%    \stxrule{v}{values}{
%      \cdots \mid 
%      \vOOcast{v}{ \cOOcast{I}{l}{\star} } \mid
%      \vOOcast{v}{ \cOOcast{P}{l}{P} }
%    }
%  \end{array}
%  \]
%  
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& v \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        v \langle \cOOcast{P}{l}{I} \rangle
          \langle \cOOcast{I}{l}{\star} \rangle
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        v \langle \cOOcast{\star}{l}{I} \rangle
          \langle \cOOcast{I}{l}{P} \rangle
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& v \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
     v \langle \cOOcast{P_1}{l}{P_2} \rangle & \text{if } P_1 \smile P_2
  \end{array}
  \]


  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}


% the following are temporary -JS
\clearpage
\pagebreak

\subsection{Coercions in Normal Form} 
\label{sec:coercion-calculus}

In this section we review the coercions in normal form of
\citet{siek2012interpretations} to motivate the design of
hypercoercions.  We ignore sum types and product types in this
section, because \citet{siek2012interpretations} did not discuss
them. We assume a basic familiarity with coercions and direct readers
who are not familiar with them to \citet{siek2012interpretations}.
%We 
%will highlight the similarity of normal coercion and hypercoercion, and hope 
%this would convince you that hypercoercion should be as difficult to implement 
%as normal coercions.
%\todo[inline]{I don't think we should try to convince the reader that
%  hypercoercions are easier to implement. We don't have real evidence
%  for that.}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{I}{injectable types (\lazyD)}{
		\POOfun{T}{T}}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOfun{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{coercions}{
		\ncInj{I} \mid
		\ncProj{I}{l} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncSeq{c}{c} \mid
		\ncFun{c}{c}
	}
	\stxrule{\bar{c}}{wrapper coercions}{	
		\ncInj{I} \mid
		\ncFun{\hat{c}}{\hat{c}} \mid
		\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}
	}
%	\stxrulecont{
%		\ncProd{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncProd{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
%		\ncSum{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncSum{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid	
%	}
	\stxrule{\hat{c}}{normal coercions}{
		\bar{c} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncProj{I}{l} \mid
		\ncSeq{\ncProj{I}{l}}{\ncFail{l}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncInj{I}}
	}
	\stxrulecont{
		\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}}
	}
	\end{array}
	\]
	\caption{Syntax of Normal Coercion}
	\label{fig:normal-coercion}
\end{figure}

\todo[inline]{Give a summary statement about the shape of the normal form. 
-JS
\\---\\The three-part shape is not obvious before the transformation at 
the end of the next paragraph. So the summary is given after that. -KC}

\figref{fig:normal-coercion} defines the normal coercion.
Types, pre-types, and blame labels are as before.
Let $ I $ range over injectable types. An injectable type is a type that can 
be cast directly to (injection) and from (projection) $ \TOOdyn $. The 
definition of injectable type depends on blame strategy. With \lazyD, all 
pre-types are injectable. With \lazyUD, only $ \POOfun{\TOOdyn}{\TOOdyn} $ 
is injectable. 
Let $ c $ range over coercions, a coercion is either injection, projection, 
identity, failure, sequencing, or function coercion.
Let $ \bar{c} $ range over wrapper coercions, which represent casts in $ 
\vOOcast{v}{c} $.
Let $ \hat{c} $ range over normal coercions. If we inline $ \bar{c} $ and 
re-order the cases, the definition of $ \hat{c} $ becomes:
\[
\begin{array}{rclr}
\stxrule{\hat{c}}{normal coercions}{
	\ncFun{\hat{c}}{\hat{c}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
	\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
	\ncId \mid
	\ncProj{I}{l} \mid
	\ncInj{I} \mid
	\ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
	\ncFail{l} \mid
}
\end{array}
\]

Three observations on this definition leads to hypercoercion: 
\begin{enumerate}
	\item The length of normal coercion is at most three.
	\item Projections are always at the beginning when present.
	\item Injections and failures are always at the end when present.
\end{enumerate}


\section{Definition of Hypercoercion} \label{sec:hypercoercion-definition}

\begin{figure}
	Syntax
	\[
	\begin{array}{lclr}
	\stxrule{I}{injectable types (\lazyD)}{P}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\TOOdyn}{\TOOdyn} \mid
		\POOprod{\TOOdyn}{\TOOdyn} \mid
		\POOsum{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{hypercoercions}{
		\hyperCoercionI \mid{}
		\hyperCoercionC{h}{m}{t}
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{m}{middles}{
		\POOunit \mid
		\POOfun{c_1}{c_2} \mid
		\POOprod{c_1}{c_2} \mid
		\POOsum{c_1}{c_2}
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
		
	hypercoercion typing \fbox{$ c : T \Longrightarrow T $}
	\begin{gather*}
	\inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
	\quad
	\inference{
		\typingHC{h}{T_1}{P_1} &
		\typingHC{m}{P_1}{P_2} &
		\typingHC{t}{P_2}{T_2}
	}{
		\typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
	}
	\end{gather*}
	
	Head typing \fbox{$ \typingHC{h}{T}{P} $}
	\begin{gather*}
	\inference{}{\typingHC{\epsilon}{P}{P}}
	\quad
	\inference{}{\typingHC{?^l}{\TOOdyn}{I}}
	\end{gather*}
	
	Middle typing \fbox{$ \typingHC{m}{T}{T} $}
	\begin{gather*}
	\inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
	\quad
	\inference{
		\typingHC{c_1}{T_3}{T_1} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
	}
	\\
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
	}
	\quad
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
	}
		\end{gather*}
		
		Tail typing \fbox{$ \typingHC{t}{P}{T} $}
		\begin{gather*}
		\inference{}{\typingHC{\epsilon}{P}{P}} \quad
		\inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
		\inference{}{\typingHC{\bot^l}{P}{T}} \quad
		\end{gather*}
	
	\caption{Definition of hypercoercion (HC)}
	\label{fig:hypercoercion}
\end{figure}

This section presents our first contribution, the definition of hypercoercion. 
The design of hypercoercion is motivated by observations on coercion normal 
forms: a normal coercion has at most three parts; projections are always at the 
beginning; injections and failures are always at the end. Hypercoercions have 
similar shape: a hypercion has either one part or three parts; for three-part 
hypercoercions, the first part is either a projection or a no-op, while the 
last part is either an injection, a failure, or a no-op.

\figref{fig:hypercoercion} defines the syntax of hypercoercion. Types, 
pre-types, and blame labels are as before.

Let $ c $ range over hypercoercions. A hypercoercion is either 
an identity cast between the dynamic types, or a complex including a head, a 
middle, and a tail. 
Let $ h $ range over heads. A head is either a no-op, or a projection.
Let $ m $ range over middles. There is a one-to-one 
correspondence between middles and type constructors. 
We generalize shallow-consistency to middles $ m \smile m $ in the natural way.
Let $ t $ range over tails. A tail is either a no-op, an injection, or a 
failure. 

We define hypercoercion constructs in the following subsections.
But functions that apply hypercoercions to values are deferred to 
Section~\ref{sec:hypercoercion-correctness} because 
they depends on a new definition of values, which is part of the framework in
Section~\ref{sec:framework}.

\subsection{\lazyD{} hypercoercion}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{\ell}{Maybe $ l $}{\epsilon \mid l}
	\end{array}
	\]
	
	Composition of hypercoercions \fbox{$ c \fatsemi^\ell c = c $}
	\[ 
	\begin{array}{rclclr}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{\epsilon}{m}{t}
	}{
		\hyperCoercionC{?^{l}}{m}{t}
	}{\sidecond{\ell = l}}
	
	\comprule{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{
		c
	}{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{t}
	}{
		\hyperCoercionI
	}{
		\hyperCoercionC{h}{m}{!}
	}{
		\sidecond{\forall l. t \neq \bot^{l}}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{\epsilon}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			m_1 \fatsemi^{\ell} (m_2, t_2) = (m', t')
			 \; \text{and} \;
			 \forall l. t \neq \bot^{l}
		}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{?^{l'}}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			m_1 \fatsemi^{l'} (m_2, t_2) = (m', t')
			\; \text{and} \;
			\forall l. t \neq \bot^{l} 
		}
	}
	\end{array}
	\]
	
	Composition of middles \fbox{$ m \fatsemi^\ell (m,t) = (m,t) $}
	\[ 
	\begin{array}{rclclr}
	\comprule{\POOunit}{(\POOunit,t)}{
		(\POOunit,t)
	}{}
	\comprule{\POOfun{c_1}{c_2}}{(\POOfun{c_3}{c_4},t)}{
		(\POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOprod{c_1}{c_2}}{(\POOprod{c_3}{c_4},t)}{
		(\POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOsum{c_1}{c_2}}{(\POOsum{c_3}{c_4},t)}{
		(\POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{m_1}{(m_2,t)}{
		(m_1,\bot^l)
	}{
		\sidecond{
			\ell = l \; \text{and} \;
			\neg m_1 \smile m_2 
		}
	}
	\end{array}
	\]
	
	\fbox{$ seq(c,c) = c $}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^\epsilon c_2
	}{}
	\end{array}
	\]
	
	\fbox{$ id( P ) = m $}
	\[
	\begin{array}{rclr}
	\funrule{id(\POOunit)}{\POOunit}{}
	\funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
	}{}
	\end{array}
	\]
	
	\fbox{$ id( T ) = c $}
	\[
	\begin{array}{rclr}
	\funrule{id(\star)}{
		\hyperCoercionI
	}{}
	\funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
	}{}
	\end{array}
	\]
	
	\fbox{$ cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	\caption{\lazyD{} hypercoercion}
	\label{fig:HC-D}
\end{figure}

\figref{fig:HC-D} defines the constructors of \lazyD{} hypercoercion.

Let $ \ell $ range over $ \epsilon $ and labels.
$ c_1 \fatsemi^\ell c_2 = c' $ composes two hypercoercions. The target of $ 
c_1 $ and the source of $ c_2 $ might be different, in which case $ \ell $ must 
be a label.
$ m_1 \fatsemi^\ell (m_2,t) = (m',t') $ composes a middle with a 
pair of a middle and a tail. Similarly, the target of $ m_1 $ and the source of 
$ m_2 $ might be different, in which case $ \ell $ must be a label.
$ seq(c_1,c_2) $ composes two coercions where the target type of $ c_1 $ is 
equal to the source type of $ T_2 $.
$ id(T) $ constructs an identity coercion of $ T $ with the help of $ id(P) $.
$ cast(T_1,l,T_2) $ constructs a coercion from a source type, a label, and a 
target type. 

\begin{proposition}[\lazyD\ hypercoercion is a monoid]
	\label{thm:hc-monoid}
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}

\subsection{\lazyUD{} hypercoercion [Jeremy]}

Figure~\ref{fig:HC-UD}

\begin{figure}
  Composition of hypercoercions \fbox{$ c \fatsemi c = c $}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
       \hyperCoercionC{p_2}{m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{\epsilon} &\fatsemi& \hyperCoercionC{\epsilon}{m_2}{i_2} &=&
       \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{i_2} &=&
  \begin{cases}
    \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{p_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{p_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
     \hyperCoercionC{p_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$ id( P ) = m $}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$ id( T ) = c $}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
		\hyperCoercionI
    }{}
    \funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]

  
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}


Figure~\ref{fig:HC-UD-cast}


\begin{figure}
  \fbox{$ \mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$ \mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$ \mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$ \mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$ cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxilliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\begin{proposition}[\lazyUD\ hypercoercions form a monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}


\section{a framework for proving correctness of cast representations}
\label{sec:framework}

This section presents our second contribution, a framework for proving 
correctness of cast representations. The framework is a theorem saying that for 
all cast representation $ C $, if $ C $ satisfies a collection of properties, 
then it would respect the Lazy D semantics of cast calculi. We are working on a 
similar theorem for \lazyUD{}.

%then instantiating our parameterized space-efficient interpreter with $ C $ 
%gives an interpter that is extensionally equal to the standard interpreter for 
%\lazyD\ cast calculus. 

We captures the set of operators that every cast representation must provide 
with \emph{cast abstract data type} (Definition~\ref{def:cast-rep}). 
The first three operators allow a language implementation to construct casts. 
So we call them \textit{cast constructors}. And the forth and last operator 
enable the implementation to apply casts on values. 

\begin{definition}[Cast Abstract Data Type (Cast ADT)]
	\label{def:cast-rep}
	A cast abstract data type is a set $ Cast $ indexed by two types with
	four operators:
	\begin{description}
		\item[$ id(T) = c $] constructs an identity cast
		\item[$ seq(c_1,c_2)=c $] composes two casts
		\item[$ cast(T_1,l,T_2)=c $] constructs a cast from $ T_1 $ to $ T_2 $
		\item[$ applyCast(v,c)=r $] applies a cast onto a value
	\end{description}
\end{definition}

Some instances of Cast ADT (or "some Cast" for short) are also 
\textit{monoids}. This definition is useful in the proof of 
our framework, and might be interesting for other people.

\begin{definition}[Monoid]
	A Cast is a monoid if 
	for all
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c_1) = c_1$,
		\item $seq(c_1,id(T_2)) = c_1$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{definition}

To use our framework, users needs to prove that their cast representation
implements Lazy D Cast ADT (Definition~\ref{def:surely-lazyd}). Property (1) 
states that $ id(T) $ must acts like the identity function. Property (2) states 
that $ seq(c,c) $ must acts like a sequence of casts. Properties (3) through 
(11) state that $ cast(T_1,l,T_2) $ must act like the Lazy D $ applyCast $ 
defined in Fig.~\ref{fig:applyCast-D-C}.

\begin{definition}[Lazy D Cast ADT]
	\label{def:surely-lazyd}
	A  Cast is a Lazy D Cast if:
	\begin{enumerate}
		\item If $ v : T $, then $ applyCast(v,id(T)) = \mathtt{succ} \; v $
		\item If $ \judgeType{v}{T_1} $,
		$ \judgeTypeFT{c_1}{T_1}{T_2} $, and
		$ \judgeTypeFT{c_2}{T_2}{T_3} $,\\
		then $ applyCast(v,seq(c_1,c_2)) = 
		applyCast(v,c_1) >>= \lambda v.applyCast(v,c_2) $ \\
		where 
		\[
		\begin{array}{rcl}
		\rOOsucc{v} >>= f & = & f(v) \\
		\rOOfail{l} >>= f & = & \rOOfail{l}
		\end{array}
		\]
		\item If $ v : T_1 $ and $ \neg T_1 \smile T_2 $,
		then $ applyCast(v,cast(T_1, l, T_2)) = \rOOfail{l} $
		\item If $ v : \star $, 
		then $ applyCast(v,cast(\TOOdyn,l,\TOOdyn)) = \rOOsucc{v} $
		\item If $ v : P_1 $,
		then $ applyCast(\hcvOOinj{P_1}{v},cast(\star,l,P_2)) 
		= applyCast(v,cast(P_1,l,P_2)) $
		\item If $ v : P $,
		then $ applyCast(v,cast(P,l,\star)) = \rOOsucc{(\hcvOOinj{P}{v})} $
		\item If $ v : \POOunit $,
		then $ applyCast(v,cast(\POOunit,l,\POOunit)) = \rOOsucc{v} $
		\item If $ (\hcvOOfun{c_1}{\rho}{x}{e}{c_2}) : \POOfun{T_1}{T_2} $,
		then\\
		$ 
		applyCast(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}, 
		cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4})) \\
		= 
		\rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\rho}{x}{b}{seq(c_2,cast(T_2,l,T_4))})}$
		\item If $ (\hcvOOcons{v_1}{c_1}{v_2}{c_2}) : \POOprod{T_1}{T_2} $,
		then \\
		$ 
		applyCast(\hcvOOcons{v_1}{c_1}{v_2}{c_2},cast(\POOprod{T_1}{T_2},l,T_3 
		\times 
		T_4)) $ \\
		$ = 
		\rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
		$ 
		\item If $ (\hcvOOinl{v}{c}) : \POOsum{T_1}{T_2} $ ,
		then \\
		$ 
		applyCast(\hcvOOinl{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
		= \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))})} $
		\item If $ (\hcvOOinr{v}{c}) : \POOsum{T_1}{T_2} $ ,
		then \\ $ 
		applyCast(\hcvOOinr{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
		= \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_2,l,T_4))})} $
	\end{enumerate}
\end{definition}

%Lazy D Cast ADT confines the behavior of operators so narrowly that it 
%effectively allows us to ``run'' programs without referring to an actual 
%representation of cast.

After showing their cast representation is a Lazy D Cast, users of our 
frameworks can plug-in this cast representation to our space-efficient abstract 
machine in subsection~\ref{ssec:framework:cek}, and prove that this machine is 
equivalent to \ineffCEKD\ (subsection~\ref{secc:framework:all-correct}), which 
depends on lemmas in subsection~\ref{secc:framework:monoid-correct}.

\subsection{A Space-efficient CEK machine}
\label{sec:framework:cek}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	
	\stxrule{v}{values}{
		\hcvOOtt \mid
		\hcvOOfun{c}{\rho}{x}{e}{c} \mid
		\hcvOOcons{v}{c}{v}{c}
	}
	\stxrulecont{
		\hcvOOinl{v}{c} \mid
		\hcvOOinr{v}{c} \mid
		\hcvOOinj{P}{v}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuation}{
		\langle c \rangle k
	}
	\stxrule{k}{pre-continuations}{
		\hckOOmt \mid{}
		\mathtt{cons_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{cons_2} \; v \; \kappa \mid{}
		\mathtt{inl} \; \kappa \mid{}
		\mathtt{inr} \; \kappa
	}
	\stxrulecont{
		\mathtt{app_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{app_2} \; v \; \kappa \mid{}
		\mathtt{fst} \; \kappa \mid{}
		\mathtt{snd} \; \kappa
	}
	\stxrulecont{
		\mathtt{case_1} \; e \; e \; \rho \; \kappa \mid
		\mathtt{case_2} \; v \; e \; \rho \; \kappa \mid{}
		\mathtt{case_3} \; v \; v \; \rho \; \kappa
	}
	\end{array}
	\]
	
	Build continuation \fbox{$ cont(k) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{cont(k)}{\langle id(T_1) \rangle k}{
		\sidecond{k : T_1 \Longrightarrow T_2}}
	\end{array}
	\]
	
	Extend continuation \fbox{$ ext(c,\kappa) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{ext(c_1,\langle c_2 \rangle k)}{\langle seq(c_1,c_2) \rangle k}{}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeSreduce{C}{s}{s} $}
	\[
	\begin{array}{rclr}
	\redruleS{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
	}{}
	\redruleS{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho[x]}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\hcvOOtt}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{E}{}
	}{}
	\redruleS{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{cont(\kOOinl{\kappa})}
	}{}
	\redruleS{
		\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{cont(\kOOinr{\kappa})}
	}{}
	\redruleS{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{cont(\kOOappI{E}{e_2}{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
		\sOOinspect{e}{\rho}{cont(\kOOcar{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
		\sOOinspect{e}{\rho}{cont(\kOOcdr{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
		\sOOinspect{e_1}{\rho}{cont(\kOOcaseI{E}{e_2}{e_3}{\kappa})}}{}
	\redruleS{
		\sOOreturn{v}{\langle c \rangle k}
	}{
	\begin{cases}
	continue(k,v) & \sidecond{applyCast(v,c) = \rOOsucc{v'}} 
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
	\end{cases}
	}{}
%\redruleS{
%	\sOOreturn{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
%	\sOOinspect{e_2}{\rho}{cont(\kOOconsII{v_1}{\kappa})}}{}
%
%\redrule{
%\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
%\sOOreturn{(\hcvOOcons{v_1}{id(T_1)}{v_2}{id(T_2)})}{\kappa}}{
%\\&&
%\sidecond{v_1 : T_1 \wedge v_2 : T_2}}
%
%\redrule{
%\sOOreturn{v}{(\kOOinl{\kappa})}}{
%\sOOreturn{(\hcvOOinl{v}{id(T)})}{\kappa}}{
%\\&&
%\sidecond{v : T}}
%
%\redrule{
%\sOOreturn{v}{(\kOOinr{\kappa})}}{
%\sOOreturn{(\hcvOOinr{v}{id(T)})}{\kappa}}{
%\\&&
%\sidecond{v : T}}
%
%\redrule{
%\sOOreturn{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
%\sOOinspect{e_2}{\rho}{cont(\kOOappII{v_1}{\kappa})}}{}
%
%	
%	& \vdots \\
%	\redruleS{
%		\sOOinspect{(\eOOlam{T_1}{T_2}{x}{e})}{\rho}{\kappa}
%	}{
%		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
%	}{}
%	\redruleS{
%		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
%	}{
%		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
%	}{}
%	\redruleS{
%		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
%	}{
%		\sOOinspect{e_1}{\rho}{cont(\hckOOconsI{e_2}{\rho}{\kappa})}
%	}{}
%	\redruleS{
%		
%\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
%	}{
%		\begin{cases}
%		\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)} \\
%		\;\;\;\;\;\;\;\;\;\sidecond{applyCast(v,c_1) = \rOOsucc{v'}} 
%		\\
%		\sOOhalt{(\oOOblame{l})} \\
%		\;\;\;\;\;\;\;\;\;\sidecond{applyCast(v,c_1) = \rOOfail{l}}
%		\end{cases}
%		
%	}{}
	\end{array}
	\]
	
	Apply continuation
	\fbox{$ continue(k,v) = s $}
	\[
	\begin{array}{rclr}
	

\funrule{
	\continue{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
	\sOOinspect{e_2}{\rho}{(\kOOconsII{v_1}{\kappa})}}{}

\funrule{
	\continue{v_2}{(\kOOconsII{v_1}{\kappa})}}{
	\sOOreturn{(\hcvOOcons{v_1}{id(T_1)}{v_2}{id(T_2)})}{\kappa}}{}

\funrule{
	\continue{v}{(\kOOinl{\kappa})}}{
	\sOOreturn{(\hcvOOinl{v}{id(T)})}{\kappa}}{}

\funrule{
	\continue{v}{(\kOOinr{\kappa})}}{
	\sOOreturn{(\hcvOOinr{v}{id(T)})}{\kappa}}{}

\funrule{
	\continue{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
	\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

\funrule{
	\continue{v_2}{(\kOOappII{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{\kappa})}}{
\begin{cases}
	\sOOinspect{e}{\rho[x:=v_2]}{ext(c_2,\kappa)} &
	\sidecond{applyCast(v,c) = \rOOsucc{v'}}
\\
\sOOhalt{l} &
\sidecond{applyCast(v,c) = \rOOfail{l}}
\end{cases}
}{}
\funrule{
	\continue{v_3}{(\mathtt{case_3}\;(\vOOinl{v})\;v_2\;\kappa)}
}{
	\sOOreturn{v}{(\kOOappII{v_2}{\kappa})}
}{}

\funrule{
	\continue{v_3}{(\mathtt{case_3}\;(\vOOinr{v})\;v_2\;\kappa)}
}{
	\sOOreturn{v}{(\kOOappII{v_3}{\kappa})}
}{}

\funrule{
	\continue{v}{\kOOmt}}{
	\sOOhalt{observe(v)}}{}
	
	\end{array}\]
	
%	Transitive closure of reduction \fbox{$ s \longrightarrow_{S(C)}^{*} s $}
%	\[\dots\]
	
	Evaluation \fbox{$ \judgeSeval{C}{e}{o} $}
	\[
	\inference{
		\judgeSreduceTrans{C}{
			\sOOinspect{e}{\emptyset}{cont(\hckOOmt)}
		}{
			\sOOhalt{o}
		}		
	}{
		\judgeSeval{C}{e}{o}
	}
	\]
	
	\caption{Space-efficient CEK machine $ \mathcal{S}(C) $}
	\label{fig:machine-cekcc}
\end{figure}
\figref{fig:machine-cekcc} defines, \effCEK{C}, a space-efficient
semantics as a CEK machine.  This machine is similar to \ineffCEK{}.
The most important differences are in values and continuations.

Let $ v $ range over value. 
In \ineffCEK\, we have one value constructor for all casted value.
In \effCEK{C}, however, we do not have this generic value constructor, 
instead we push those casts into the ordinary values. For instance, $ 
(\vOOcons{v_1}{v_2}) $ corresponds to $ 
(\hcvOOcons{v_1'}{id(T_1)}{v_2'}{id(T_2)}) $. To construct values of the 
dynamic type, we use $ (\hcvOOinj{P}{v}) $.

Cast results ($ r $) and machine states ($ s $) are as before. 

Let $ \kappa $ range over continuations and let $ k $ range over 
pre-continuations. 
A continuation is now a pre-continuation prefixed with a cast.
Pre-continuation are like the continuations in \ineffCEK, but there is no 
constructor for casts.
Continuations in \ineffCEKD\ have zero or more casts at the top.
In \effCEK{C}, however, every continuation has exactly one cast at the top.
Continuations in \ineffCEK\ that have no casts at the top correspond to 
continuations in \effCEK{C}\ whose casts are identity.
And continuations in \ineffCEK\ that have many casts at the top correspond to 
continuations in \effCEK{C}\ where those casts are composed by $ 
seq(c,c) $.

\todo[inline]{KC needs to add missing rules in and describe them. -KC}
We list a fraction of reduction rules due to space limitation.
When values are constructed, their hypercoercion parts are filled with outputs 
of $ id $. For instance, when a function value is constructed, its first part 
and last part are initialized to $ id(T_1) $ and $ id(T_2) $ respectively.
When evaluating a cast expression, the current continuation is extended with a 
hypercoercion constructed by $ cast $. $ ext $ composes the new hypercoercion 
with the hypercoercion on the top of the continuation.
When evaluating a compound expression, the machine firstly construct the new 
pre-continuation, then turn it to a continuation by adding an identity 
hypercoercion at the top. For instance, when evaluating a \texttt{cons} 
expression, the machine firstly construct $ \hckOOconsI{e_2}{\rho}{\kappa} $, 
the new pre-continuation, then call $ cont $, which adds an identity cast to 
form a continuation. 
When a function call happens, the machine firstly cast the operand. If the 
casting succeeds, the machine then evaluate the body in the extended 
environment and the extended continuation. If the casting fails, the machine 
then halts with the blame label.

Transitive closure of reduction ($ \judgeSreduceTrans{C}{s}{s} $) and 
evaluation ($ \judgeSeval{C}{e}{o} $) are standard. Value typing ($ 
\judgeType{v}{T} $) is straightforward.

\subsection{\lazyD\ Cast ADTs Respect \ineffCEKD\ if They are 
Monoids}
\label{secc:framework:monoid-correct}

In this subsection, we prove that if a instance of Cast ADT $ C $ is Lazy D and 
is a monoid, then $ eval_\mathcal{D} = eval_{\mathcal{S}(C)} $. We proof this 
theorem with a weak bisimulation between \ineffCEKD\ and 
\effCEK{C}. 

The bisimulation relation between states ($\eqvSD{C}{s}{s}$) is mostly derived 
from the state definition: \begin{gather*}
\inference{
	\rho_1 \approx \rho_2 &
	\kappa_1 \approx \kappa_2
}{
	\sOOinspect{e}{\rho_1}{\kappa_1} \approx \sOOinspect{e}{\rho_2}{\kappa_2}
}
\quad
\inference{
	\kappa_1 \approx \kappa_2 &
	v_1 \approx v_2
}{
	\sOOreturn{v_1}{\kappa_1} \approx \sOOreturn{v_2}{\kappa_2}
}
\quad
\inference{
}{
	\sOOhalt{o} \approx \sOOhalt{o}
}
\end{gather*}

The bisimulation relation between environments and cast results are derived 
from their definitions as well. And the relation from continuations in 
\ineffCEKD\ and the pre-continuation in \effCEK{C} is in the natural way, for 
example: \begin{gather*}
\inference{
	\rho_1 \approx \rho_2 &
	\kappa_1 \approx \kappa_2
}{
	\kOOconsI{e}{\rho_1}{\kappa_1} \approx \kOOconsI{e}{\rho_2}{\kappa_2}
}
\end{gather*}

And the relation between continuations is defined in terms of $ cont(k) $ and $ 
ext(c,k) $: \begin{gather*}
\inference{
	k \approx \kappa
}{
	cont(k) \approx \kappa
}
\quad
\inference{
	\kappa_1 \approx \kappa_2
}{
	ext(cast(T_1,l,T_2),\kappa_1)
	\approx
	\kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa_2} 
}
\end{gather*}

The relation between values is more special. When the \ineffCEKD\ value is 
non-casted, the casts in the \effCEK{C} value are identity. Otherwise, we push 
the cast into the value constructors, except injections. For examples: 
\begin{gather*}
\inference{
	v_1, v_2 : P &
	v_1 \approx v_2
}{
	\hcvOOinj{P_1}{v_1} \approx \vOOcast{v_2}{\cOOcast{P}{l}{\TOOdyn}}
}
\quad
\inference{
	v_1, v_2 : T &
	v_1 \approx v_2
}{
	\hcvOOinl{v_1}{id(T)} \approx \vOOinl{v_2}
}
\quad
\inference{
	(\hcvOOinl{v}{c}, v_2) : \POOsum{T_1}{T_2}
}{
	\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))} \approx 
	\vOOcast{v_2}{\cOOcast{T_1}{l}{T_3}}
}
%\quad
%\inference{
%	\Gamma , x : T_1 \vdash T_2 &
%	\rho_1 \approx \rho_2
%}{
%	\hcvOOfun{id(T_1)}{\rho_1}{x}{e}{id(T_2)} \approx \vOOfun{\rho_2}{x}{e}
%}
%\quad
%\inference{
%	\hcvOOcons{v_1}{c_1}{v_2}{c_2}
%	\approx
%	v
%}{
%	\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))}
%}
%\\
%\inference{
%	\hcvOOfun{c_1}{\rho}{x}{e}{c_2} : \POOfun{T_1}{T_2} &
%	\hcvOOfun{c_1}{\rho}{x}{e}{c_2} \approx v
%}{
%	\hcvOOfun{seq(cast(T_3,l,T_1), c_1)}{\rho}{x}{e}{seq(c_2,cast(T_2,l,T_4))}
%	\approx
%	\vOOcast{v}{\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T3}{T_4}}}
%}
\end{gather*}

Before proving the weak bisimulation between \effCEK{C} and \ineffCEKD, we 
introduce one more definition: $ s_1 \approx^{*} s_2 $ if and only if there 
exists $ s_2' \in \text{\ineffCEKD} $ 
such that $ \judgeCreduceTrans{s_2}{s_2'}$ and $ s_1 \approx s_2' $.

\todo[inline]{Standardize theorem statement -KC}
\begin{lemma}[Weak Bisimulation between \effCEK{C} and \ineffCEKD]
	\label{thm:surely-monoidic-reduce}
	For all instance of Cast ADT $ C $, 
	if $ C $ is \lazyD{} and is a monoid, 
	$ s_{1}, s_{1}' \in \text{\effCEK{C}} $,
	$ s_{2}, s_{2}' \in \text{\ineffCEKD} $,
	$ s_{1} \approx s_{2} $,
	$ \judgeSreduce{C}{s_{1}}{s_{1}'} $, and
	$ \judgeDreduce{s_{2}}{s_{2}'} $, then
%	then there exist $ s_2'' \in \text{\ineffCEKD} $ such that
	\[ \exists s_2'' \in \text{\ineffCEKD}: \;
	\judgeDreduceTrans{s_{2}'}{s_{2}''} \;\text{and}\; s_1' \approx s_2'' \]
%	\begin{enumerate}
%		\item If $ \judgeDreduce{s_1}{s_3} $,
%		then
%		there exist $ s_5 \in \text{\ineffCEKD} $, $ s_4 \in \mathcal{S}(C) $,
%		such that \begin{itemize}
%			\item $ s_5 \approx s_4 $, and
%			\item $ \judgeSreduce{C}{s_2}{s_4} $,
%			\item $ \judgeDreduceTrans{s_3}{s_5} $
%		\end{itemize}
%		\item If $ \judgeSreduce{C}{s_2}{s_4} $,
%		then
%		there exist $ s_3 \in \mathcal{C} $,
%		such that \begin{itemize}
%			\item $ s_3 \approx s_4 $
%			\item $ \judgeDreduceTrans{s_1}{s_3} $
%		\end{itemize}
%	\end{enumerate}

Or diagrammatically, 
\[\begin{array}{clclc}
s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
\rotatebox[origin=c]{90}{$\approx$} 
& & & \;\;\;\rotatebox[origin=c]{-20}{$\approx$} \\
s_{2} & 
\longrightarrow_{\text{\ineffCEKD}} & s_2' &
\longrightarrow^{*}_{\text{\ineffCEKD}} & s_2'' \\
\end{array}\]

\end{lemma}
\begin{proof}
	By following the transition rule of \ineffCEKD. See the supplementary 
	materials for details.
\end{proof}

\begin{lemma}[$ \text{Lazy D Cast ADT} \cap \text{Monoid} $ Respects 
	$ \mathcal{C} $]
	\label{thm:surely-monoidic-eval}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is a 
	\lazyD{} Cast ADT and a monoid,
	\[
	\text{\evalEqv{\effCEK{C}}{\ineffCEKD}}
	\]
\end{lemma}
\begin{proof}Proving left implies right is trivial.
To prove $ \judgeDeval{e}{o} $ implies $ \judgeSeval{C}{e}{o} $, 
we firstly take one steps in \effCEK{C}, and catch it up in \ineffCEKD\ by 
taking one or more steps in \ineffCEKD. As we just took a positive number of 
steps, we are closer to the halting state.
\end{proof}

\subsection{\lazyD\ Cast ADT Respect \ineffCEKD}
\label{secc:framework:all-correct}

In this subsection, we prove that for all $ C $, if $ C $ is a Lazy D Cast ADT, 
then \evalEqv{\ineffCEKD}{\effCEK{C}}. We first 
prove that all $ S(C) $ where $ C $ is a Lazy D Cast ADT are equivalent, then 
connect this theorem to Lemma~\ref{thm:surely-monoidic-eval}.

We prove the equivalence among \effCEK{S(C)} with strong bisimulation. This 
time almost all the bisimulation relations are all derived from definitions 
except the relaton for casts, which is by cast constructors:
\begin{gather*}
\inference{
}{
	cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
	id_1(T) \approx id_2(T)
}
\quad
\inference{
	c_1 \approx c_2 &
	c_3 \approx c_4
}{
	seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\todo[inline]{Standardize theorem statement -KC}
\begin{lemma}[Strong Bi-simulation among $ \mathcal{S}(\cdot) $]
	\label{thm:CEKS-bisim}
	If 
	$ C_1 $ and $ C_2 $ are instances of Lazy D Cast ADT,
	$ s_1, s_1' \in S(C_1) $ and $ s_2,s_2' \in S(C_2) $,
	$ s_1 \approx s_2 $,
	$ \judgeSreduce{C_1}{s_1}{s_1'} $, and
	$ \judgeSreduce{C_2}{s_2}{s_2'} $, then 
	$ s_1' \approx s_2' $
	
	Or diagrammatically, 
	\[\begin{array}{clc}
	s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
	\rotatebox[origin=c]{90}{$\approx$} 
	& & \rotatebox[origin=c]{90}{$\approx$} \\
	s_{2} & 
	\longrightarrow_{\text{\ineffCEKD}} & s_2' \\
	\end{array}\]
\end{lemma}
\begin{proof} 
	This proof is effectively a duplication of the transition rule of 
	\effCEK{S(C)}.
	The key ideas of this proof are undoing sequencing with the property (2) of 
	Lazy D Cast ADT, and handling all possibly uses of $ 
	cast(T,l,T) $ with property (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of \lazyD{} Cast ADT]
	\label{thm:surely-lazyD-eqv}
	If $ \judgetype{\emptyset}{e}{T} $, $ o : T $, and $ C_1 $ and $ C_2 $ 
	are \lazyD\ Cast ADTs,
	\[
	eval_{S(C_1)} = eval_{S(C_2)}
	\]
\end{proposition}
\begin{proof}
	By induction with the help of Lemma~\ref{thm:CEKS-bisim}.
\end{proof}

\begin{theorem}[\lazyD\ Cast ADT Respects \ineffCEKD]
	\label{thm:surely-lazyD-correct}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is a 
	\lazyD{} Cast ADT.
	\[
	\text{\evalEqv{\ineffCEKD}{\effCEK{C}}}
	\]
\end{theorem}
\begin{proof}
	If we have a Lazy D Cast ADT and it is a monoid, this 
	proof is immediately from Lemma~\ref{thm:surely-monoidic-eval} and 
	Proposition~\ref{thm:surely-lazyD-eqv}. One such representation is to 
	represent casts as a list of triples of type, label, and type, where $ 
	id(T) $ is the empty list and $ seq(c,c) $ is the list append. Another such 
	representation is the \lazyD\ hypercoercion!
\end{proof}


\section{Correctness Proof of \lazyD{} hypercoercions}
\label{sec:hypercoercion-correctness}

In this section we prove \lazyD\ hypercoercion is 
correct. First we define $ applyCast(v,c) $ to make it an instance of Cast ADT, 
then prove that it is also Lazy D, and finally apply 
Theorem~\ref{thm:surely-lazyD-correct} to finish the proof.

\figref{hc-applyCast} defines $ applyCast(v,c) $ for \lazyD\ hypercoercion. 
Applying the identity cast for the 
dynamic type succeeds immediately. When applying a compound cast, we firstly 
apply the middle, then apply the tail. We denote by $ r \; >>= \; f $ to mean 
that if $ r $ is $ \rOOsucc{v} $, the result is $ f(v) $, otherwise the result 
is the failure.
$ applyMiddle(v,\ell,m) $ and $ applyTail(v,t) $ are straightforward.
In the definition of $ applyMiddle(v,\ell,m) $, we generalize 
shallow-consistency to compare middles and values ($ v \smile m $) in the 
natural way.

\begin{figure}
	\fbox{$ applyCast(v,c) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyCast(v,\hyperCoercionI,)}{\rOOsucc{v}}{}
	\funrule{applyCast(\hcvOOinj{P}{v},\hyperCoercionC{?^l}{m}{t})}{
		applyMiddle(v,l,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\funrule{applyCast(v,\hyperCoercionC{\epsilon}{m}{t})}{
		applyMiddle(v,\epsilon,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\end{array}
	\]
	
	\fbox{$ applyMiddle(v,\ell,m) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyMiddle(\hcvOOtt,\ell,\POOunit)}{\rOOsucc{\hcvOOtt}}{}
	\funrule{applyMiddle(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}\ell,\POOfun{c_3}{c_4})}{
		\rOOsucc{(\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\rho}{x}{e}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOcons{v_1}{c_1}{v_2}{c_2},\ell,\POOprod{c_3}{c_4})}{
		\rOOsucc{(\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOinl{v}{c_1},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)})}
	}{}
	\funrule{applyMiddle(\hcvOOinr{v}{c_2},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(v,l,m)}{
		\rOOfail{l}
	}{
		\sidecond{\neg v \smile m}
	}
	\end{array}
	\]
	
	\fbox{$ applyTail(v,t) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyTail(v,\bot^l)}{\rOOfail{l}}{}
	\funrule{applyTail(v,\epsilon)}{\rOOsucc{v}}{}
	\funrule{applyTail(v,!)}{\rOOsucc{(\hcvOOinj{P}{v})}}{}
	\end{array}
	\]
	\caption{\lazyD\ hypercoercion's $ applyCast $}
	\label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} hypercoercion is a \lazyD Cast ADT]
	\label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof} See the supplementary material. \end{proof}

\begin{theorem}[\lazyD{} hypercoercion Respect \ineffCEKD]
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ 
	\[
	\text{\evalEqv{\ineffCEKD}{\effCEK{H}}}
	\]
\end{theorem}
\begin{proof}
	Immediately from Theorem~\ref{thm:surely-lazyD-correct} and 
	Lemma~\ref{thm:hc-surely-lazyD}.
	Alternatively, from Lemma~\ref{thm:surely-monoidic-eval},
	Lemma~\ref{thm:hc-surely-lazyD}, and 
	Proposition~\ref{thm:hc-monoid}.
\end{proof}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile,all}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots


\end{document}
