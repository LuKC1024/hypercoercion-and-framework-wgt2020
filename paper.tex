%% For double-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\hifunrule}[3]{\highlight{#1} &\highlight{=}& \highlight{#2} & 
\highlight{#3}\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\comprulel}[4]{#1 & \fatsemi^l & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{Lazy\;UD}
\newcommand{\lazyD}{Lazy\;D}

\newcommand{\sOOinspect}[3]{\langle\langle#1,#2\rangle,#3\rangle}
\newcommand{\sOOreturn}[2]{\langle#1,#2\rangle}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}

%\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
%\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
%\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}

\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{(#1 \; #2)}
\newcommand{\eOOcons}[2]{\mathtt{cons} \; #1 \; #2}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
%\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
%\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{#1 \langle \cOOcast{#2}{#3}{#4} \rangle}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\cOOcast}[3]{#1 \Rightarrow^{#2} #3}
\newcommand{\oOOinj}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\vOOcast}[2]{#1\langle#2\rangle}
\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
%\newcommand{\rOOsucc}[1]{#1}
%\newcommand{\rOOfail}[1]{#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}

\newcommand{\kOOmt}[0]{\mathtt{stop}}
\newcommand{\kOOconsI}[3]{[\mathtt{cons} \; \square \; \langle#1,#2\rangle ]#3}
\newcommand{\kOOconsII}[2]{[\mathtt{cons} \; #1 \; \square]#2}
\newcommand{\kOOinl}[1]{[\mathtt{inl}\; \square]#1}
\newcommand{\kOOinr}[1]{[\mathtt{inr}\; \square]#1}
\newcommand{\kOOappI}[3]{
	[\square \; \langle#1,#2\rangle]#3
}
\newcommand{\kOOappII}[2]{
	[#1 \; \square]#2}
\newcommand{\kOOcar}[1]{[\mathtt{fst} \; \square]#1}
\newcommand{\kOOcdr}[1]{[\mathtt{snd} \; \square]#1}
\newcommand{\kOOcaseI}[4]{
	[\mathtt{case} \; \square \; \langle#1,#3\rangle \; \langle#2,#3\rangle ]#4}
\newcommand{\kOOcaseII}[4]{
	[\mathtt{case} \; #1 \; \square \; \langle#2,#3\rangle ]#4}
\newcommand{\kOOcaseIII}[3]{
	[\mathtt{case} \; #1 \; #2 \; \square]#3}
\newcommand{\kOOcast}[2]{
	[\square \langle #1 \rangle]#2}

%\newcommand{\kOOmt}[0]{\mathtt{stop}}
%\newcommand{\kOOconsI}[3]{\mathtt{cons_1} \; #1 \; #2 \; #3}
%\newcommand{\kOOconsII}[2]{\mathtt{cons_2} \; #1 \; #2}
%\newcommand{\kOOinl}[1]{\mathtt{inl} \; #1}
%\newcommand{\kOOinr}[1]{\mathtt{inr} \; #1}
%\newcommand{\kOOappI}[3]{
%	\mathtt{app_1} \; #1 \; #2 \; #3
%}
%\newcommand{\kOOappII}[2]{
%	\mathtt{app_2} \; #1 \; #2}
%\newcommand{\kOOcar}[1]{
%	\mathtt{fst} \; #1}
%\newcommand{\kOOcdr}[1]{
%	\mathtt{snd} \; #1}
%\newcommand{\kOOcaseI}[4]{
%	\mathtt{case_1} \; #1 \; #2 \; #3 \; #4}
%\newcommand{\kOOcaseII}[4]{
%	\mathtt{case_2} \; #1 \; #2 \; #3 \; #4}
%\newcommand{\kOOcaseIII}[3]{
%	\mathtt{case_3} \; #1 \; #2 \; #3}
%\newcommand{\kOOcast}[2]{
%	\langle #1 \rangle #2}

\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{inj} \; #2}
%\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #2 \; #1 \; #3 \; #4 \; #5}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
%\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\langle#2\rangle\;#3\langle#4\rangle}
%\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
%\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\langle#2\rangle}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\langle#2\rangle}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D cast calculus on space-inefficient CEK
\newcommand{\judgeCreduce}[2]{#1 \longmapsto_{\mathcal{C}} #2}
\newcommand{\judgeCreduceTrans}[2]{#1 \longmapsto_{\mathcal{C}}^{*} #2}
\newcommand{\judgeCeval}[2]{eval_{\mathcal{C}}(#1) = #2}
\newcommand{\redrule}[3]{#1 & \longmapsto_\mathcal{C} & #2 & #3\\}
\newcommand{\hiredrule}[3]{\highlight{#1} & \highlight{\longmapsto_\mathcal{C}} & \highlight{#2} & \highlight{#3} \\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longmapsto_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longmapsto_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{eval_{\mathcal{S}(#1)}(#2) = #3}
\newcommand{\redruleS}[3]{#1 & \longmapsto_{\mathcal{S}(C)} & #2 & #3\\}
\newcommand{\hiredruleS}[3]{\highlight{#1} & 
\highlight{\longmapsto_{\mathcal{S}(C)}} & \highlight{#2} & \highlight{#3} \\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hypercoercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvSD}[3]{#2 \approx_{\mathcal{SD}} #3}
% to-dos
\newcommand{\todoKC}[1]{\todo[inline]{KC needs to #1}}
\newcommand{\todoKCFixed}[0]{\todo[inline]{Fixed. -KC}}
% abbrev
\newcommand{\castCalculus}[0]{$\lambda_{\rightarrow}^{\langle\cdot\rangle}$}
% names
\newcommand{\ineffCEK}{$\mathcal{C}$}
\newcommand{\ineffCEKD}{$\mathcal{D}$}
\newcommand{\ineffCEKUD}{$\mathcal{UD}$}
\newcommand{\judgeDreduce}[2]{#1 \longmapsto_{\mathcal{D}} #2}
\newcommand{\judgeDreduceTrans}[2]{#1 \longmapsto_{\mathcal{D}}^{*} #2}
\newcommand{\judgeDeval}[2]{eval_{\mathcal{D}}(#1) = #2}
\newcommand{\judgeUDreduce}[2]{#1 \longmapsto_{\mathcal{UD}} #2}
\newcommand{\judgeUDreduceTrans}[2]{#1 \longmapsto_{\mathcal{UD}}^{*} #2}
\newcommand{\judgeUDeval}[2]{eval_{\mathcal{UD}}(#1) = #2}
\newcommand{\effCEK}[1]{$\mathcal{S}(#1)$}
\newcommand{\evalEqv}[2]{\ensuremath{eval_{\text{#1}} = eval_{\text{#2}}}}
\newcommand{\continue}[2]{cont(#2,#1)}
\newcommand{\highlight}[1]{{\color{red} #1}}

\begin{document}

%% Title information
\title{Hypercoercions and a Framework for Equivalence of Cast Calculi}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  Designing a space-efficient cast representation that is good for
  both mechanized metatheory and implementation is
  challenging. Existing solutions are good for one or the other. This
  paper presents a new cast representation, named hypercoercions, that
  is good for both. On the way to proving the correctness of
  hypercoercions, this paper also makes progress on a general
  framework for proving the correctness of cast representations.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\listoftodos{}


\section{Introduction}

\todo[inline]{I see lots of mistakes regarding when to make words
  plural (whether they should have an ``s'' at the end). Please review
  the rules of English regarding plurals. The rules are tricky...
  some words don't have a plural form, like ``blame''. -JS
  \\---\\
  Will fix grammar after fixing all other problems -KC}

Around 2006, several groups of researchers proposed ways to integrate
dynamic typing and static typing, notably gradual typing
\citep{siek2006gradual}, hybrid typing \citep{flanagan2006hybrid},
migratory typing \citep{Tobin-Hochstadt:2006fk}, and multi-language
iteroperability \citep{Gray:2005ij,Matthews:2007zr}. Researchers
usually define the semantics of gradually typed languages by
translation to an intermediate language with casts, such as the blame
calculus \citep{wadler2009well} and other cast calculi
\citep{siek2009exploring}. Unfortunately, straightforward
implementations of casts on higher-order values (functions, objects,
etc.) impose significant runtime overheads that can change the
asymptotic space complexity of a program
\citep{herman2010space}. There are several known space-efficient cast
representations, with various strengths and weaknesses
\citep{siek2015blame,siek2010threesomes,garcia2013calculating,kuhlenschmidt2018efficient,siek2012interpretations,garcia2014deriving}.
The current state of the art includes

\begin{itemize}
\item threesomes \citep{siek2010threesomes,garcia2013calculating},
\item supercoercions \citep{garcia2013calculating}, and
\item coercions in normal form
  \citep{siek2012interpretations,siek2015blame}.
\end{itemize}
Recall that in these systems, casts are compressed using a composition
operator.  Threesomes and supercoercions are good for mechanized
metatheory because their compose operators are structurally recursive,
making them easy to define in a proof assistant such as Agda. In
contrast, the coercions in normal form have compose operators that are
not structurally recursive, which makes it more difficult to define in
Agda, requiring what amounts to an explicit proof of termination.
%
On the other hand, coercions in normal form are easier to understand
than threesomes (with a strange labelled bottom type), and
supercoercions (10 different kinds).

This paper presents a new cast representation, named
\emph{hypercoercions}, that is good for both mechanized metatheory and
good for implementation. The composition operator for hypercoercions
is defined by structural recursion and hypercoercions are suggestive
of a bit-level representation that minimizes the need for pointers and
fits all first-order casts into 64 bits. We present two flavors of
hypercoercions to support the two blame tracking strategies from the
literature: D and UD~\citep{siek2009exploring}. We are interested in
the D blame tracking strategy because it comes with a more
straightforward notion safe cast compared to
UD~\citep{siek2009exploring}, which is why D was chosen Grift
compiler. We are also intersted in UD because it plays a prominent
role in the gradual typing literature \citep{wadler2009well}. The
semantics of casts can also be lazy or
eager~\citep{siek2009exploring}. In this paper we focus on lazy cast
strategies because we suspect that they are more efficient than eager
strategies and because \citet{new2019gradual} show that eager
strategies are incompatible with $\eta$-equivalence of functions.

Of course, an alternative cast representation must be proved
correct. This paper presents steps toward a general framework for
proving equivalence of cast calculi and, in particular, proves that an
abstract machine using \lazyD{} hypercoercions is equivalent to an
abstract machine using standard \lazyD{}
casts~\citep{siek2009exploring}. We conjecture that the framework can
be generalized to \lazyUD{} and that it can be applied to coercions in
normal form and threesomes.

To summarize, the primary contributions of this paper are:
\begin{itemize}
\item hypercoercions, a new space-efficient cast representation, which
  has a structurally recursive composition and a more compact memory
  representation.
\item a framework in Agda for proving the correctness of \lazyD{} cast
  represantations.
\item a formal proof that hypercoercions respect the semantics
  of the \lazyD{} cast calculus.
\end{itemize}

In Section~\ref{sec:background} we review cast calculi and coercions.
We present hypercoercions in
Section~\ref{sec:hypercoercion-definition}.  We present a framework
for proving correctness of cast reprensentations in
Section~\ref{sec:framework} and use it to prove the correctness of
\lazyD{} hypercoercions in
Section~\ref{sec:hypercoercion-correctness}.

\section{Background} \label{sec:background}

In this section, we review lazy cast calculi
(Section~\ref{sec:cast-calculi}) and coercion in normal form
(Section~\ref{sec:coercion-calculus}).

\subsection{Cast Calculi}
\label{sec:cast-calculi}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P}{pre-types}{
		\POOunit \mid
		\POOfun{T_1}{T_2} \mid
		\POOprod{T_1}{T_2} \mid
		\POOsum{T_1}{T_2}
	}
	\stxrule{e}{terms}{
		\eOOvar{x} \mid{}
		\eOOsole{} \mid{}
		\eOOlam{T_1}{T_2}{x}{e} \mid
		\eOOapp{e_1}{e_2} \mid
		\eOOcons{e_1}{e_2} \mid
		\eOOcar{e} \mid
		\eOOcdr{e}
	}
	\stxrulecont{
		\eOOinl{e} \mid
		\eOOinr{e} \mid
		\eOOcase{e_1}{e_2}{e_3} \mid
		\eOOcast{e}{T_1}{l}{T_2} \mid
		\eOOblame{l}
	}
	\end{array}
	\]
	
	Consistency
	\fbox{$T_1 \sim T_2$}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\[1ex]
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	Term typing
	\fbox{$\judgetype{\Gamma}{e}{T}$}
	\begin{gather*}
          \dots \qquad
		\inference{
			\Gamma \vdash e : T_1 & T_1 \sim T_2
		}{
			\judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\eOOblame{l}}{T}
		}
	\end{gather*}
	
	\caption{Syntax and static semantics of the cast calculi.}
	\label{fig:blame-static}
\end{figure}


\paragraph{Syntax and Static Semantics}

The syntax and static semantics is the same for the \lazyD{} and
\lazyUD{} cast calculi, and is reviewed in \figref{fig:blame-static}.
As usual, the important features are the cast expressions,
$\eOOcast{e}{T_1}{l}{T_2}$, which are responsible for runtime type
checking, and blame expressions, $\eOOblame{l}$, that raise errors.
The syntax and static semantics is the same that of
\citet{siek2009exploring} except for a few minor exceptions:
\begin{itemize}
\item We add sum, product, and unit types.
\item We separate types into those with a type constructor at the top,
  the \emph{pretypes} ($\POOunit$, functions, products, and sums),
  versus the dynamic type $\star$ (a.k.a. $\mathtt{Dyn}$ or
  $\mathbb{?}$).
\item We annotate the codomain of a lambda abstraction explicitly
  because we refer to it in the dynamic semantics. 
\end{itemize}
As usual, the source $T_1$ and target types $T_2$ of a cast
$\eOOcast{e}{T_1}{l}{T_2}$ are required to be consistent, written $T_1
\sim T_2$. The consistency relation is standard and defined in
\figref{fig:blame-static}.

%% defines the syntax of the cast calculus and
%% its static semantics. We extend the syntax of
%%  with sum and product types.  Let $T$ range
%% over types. A type is either the dynamic type$\star$(a.k.a. $
%% \mathtt{Dyn}$, $\mathbb{?}$, or$\mathtt{Unknown}$), or a type

%% As usual we write$T_1 \sim T_2$when$T_1$ and $T_2$ are
%% consistent. The intuition of $T_1 \sim T_2$ is that $T_1$and $
%% T_2$have no conflicting type information. Two types are consistent
%% if one of them is $\star$, or they have the same top-most type
%% constructor and the corresponding sub-parts are
%% consistent. Consistency is reflexive and symmetric, but not
%% transitive.

%% We write$T_1 \smile T_2$when$T_1$ and $T_2$ are
%% shallowly-consistent, that is, if one of them is $\star$, or they
%% have the same type constructor at the top. Shallow-inconsistency is
%% the root of all blame in lazy cast strategies -- casting a value to a
%% shallowly inconsistent type leads to a blame. Shallow-consistency is
%% reflexive, symmetric, but not transitive.

%% Let $e$ range over terms. Most terms are standard for a simply-typed
%% lambda calculus. We annotate the codomain of a lambda abstraction
%% explicitly because we refer to it in the dynamic semantics. Becuase
%% this is a cast calculus, we have two additional terms: cast
%% expressions and blame expressions. Cast expressions perform runtime
%% type checks and blame expressions raise an error.


\paragraph{Dynamic Semantics}

The dynamic semantics of a cast calculus is typically defined with a
reduction semantics. Here we use a CEK machine
\citep{felleisen1986control} instead because the first author is more
familiar with CEK machines and believes that a CEK machine is more
convenient to use for the space-efficient semantics in
Section~\ref{sec:framework:cek} (a major point of space-efficiency is about 
compressing continuations). So using an abstract machine for the cast calculi in
this section makes it easier prove correctness of the space-efficient
machines. Of course, one should prove that the abstract machine
presented here is equivalent to the standard reduction semantics for
cast calculi, but we have not yet done so.

Fig.~\ref{fig:machine-cekc} defines the transition relation of the CEK
machine and Fig.~\ref{fig:state} gives a grammar for machine states
$s$, including a definition of values and value typing. The
transitions involving casts are highlighted in red and described in
more detail below. The other transitions are standard for a CEK
machine for an extended simply typed lambda calculus.
%
Recall that CEK machine involves two kinds of transitions, (1) those
that dive further into an expression (looking for a redex) and push an
entry onto the continuation, and (2) those that return a value to the
current continuation and possibly perform a computation.
Corresponding to (1) and (2), the machine state is either in an
$\mathtt{Eval}$ or $\mathtt{Cont}$ configuration, respectively.
Additionally, there is the $\mathtt{Halt}$ configuration.

The transition relation $\judgeCreduce{s}{s}$ is parameterized over
$applyCast$ to allow for the differences between D and UD.
%
When evaluating a cast expression, the machine moves the cast to the
continuation and evaluates the inner expression.
%% Other
%% transition rules starting from$Eval$states are standard.
To apply a casted function, the machine first casts $v_1$, the
operand, then applies the casted operand to $v_2$, the underlying
function, and finally cast the result of the function application.
%
To take out the first (resp. second) part of a casted pair, the
machine firstly take out the first (resp. second) part of $v$, the
underlying pair, and cast the result.
%
%In case splitting, if the target value is a left injection, the
%machine moves to a state that will apply the first continuation
%function to the value inside the left injection. The case for right
%injection is similar.
%
When the target value is a casted sum, the machine moves the cast from
the target value to continuations functions.
%
To cast a value, the machine invokes $applyCast$ on the value.  If the
cast succeeds, the machine returns the result to the next
continuation.  If the cast fails, the machine halts with the blame
label.
%
%% When the continuation is $stop$, the machine enters a halting
%% state. The When the machine is in a halting state, it stays in the
%% same state.

The reflexive transitive closure of reduction ($\judgeCreduceTrans{s}{s}$) and 
evaluation ($eval_\mathcal{C}(e)$)
are standard~\citep{felleisen03:_pllc}.


\begin{figure}
  Machine state and other runtime data structures
  \[
  \begin{array}{rclr}
	\stxrule{v}{values}{
		\vOOtt{} \mid
		\vOOfun{\rho}{x}{e} \mid
		\vOOcons{v_1}{v_2} \mid
		\vOOinl{v} \mid
		\vOOinr{v} \mid		
		\vOOcast{v}{c}
	}
	\stxrule{c}{casts}{
		\cOOcast{T_1}{l}{T_2}
	}
	\stxrule{I}{injectable types (\lazyD)}{
		P
	}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\star}{\star} \mid
		\star \times \star \mid
		\star + \star
	}
	\stxrule{o}{observations}{
		\oOOinj \mid
		\oOOsole \mid
		\oOOfun \mid
		\oOOcons \mid
		\oOOinl \mid
		\oOOinr \mid
		\oOOblame{l}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuations}{
		\kOOmt \mid
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa}
	}
	\stxrulecont{
		\kOOinr{\kappa} \mid
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa}
	}
	\stxrulecont{	
		\kOOcdr{\kappa}\mid
		\kOOcaseI{e}{e}{\rho}{\kappa}\mid
		\kOOcaseII{v}{e}{\rho}{\kappa}
	}
	\stxrulecont{
		\kOOcaseIII{v}{v}{\kappa} \mid
		\kOOcast{c}{\kappa}
	}
  \end{array}
  \]

        Shallow-consistency
	\fbox{$T \smile T$}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
	} \quad
	\inference{}{
		T_{11} \times T_{12} \smile T_{21} \times T_{22}
	} \quad
	\inference{}{
	T_{11} \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	Value typing \fbox{$v : T$}
	\begin{gather*}
	\dots \qquad
	\inference{
		v : I
	}{
		\vOOcast{v}{\cOOcast{I}{l}{\TOOdyn}} : \TOOdyn
	}
	\quad
	\inference{
		v : P_1 &
		P_1 \smile P_2
	}{
		\vOOcast{v}{\cOOcast{P_1}{l}{P_2}} : P_2
	}
	\end{gather*}
        \caption{Definition of machine state and auxilliary data
          structures.}
        \label{fig:state}
\end{figure}

Let $v$ range over values. A value is either the unit, a function (a
closure), a pair, a left injection, a right injection, or a casted
value. As shown by the value typing rules, if the target type of a
casted value is the dynamic type, the underlying value must be of an
injectable type. The definition of injectable types depends on blame
strategies: for the \lazyD\ strategy, every pre-type is injectable;
for the \lazyUD\ strategy, a pre-types is injectable if and only if
all its sub-parts are the dynamic type. If the target type of a casted
value is a pre-type, the type of the underlying value must have the
same type constructor.

Let $c$ range over casts. A cast is a triple of a type, a label, and a type.

Let $o$ range over observations. They are what would be observed if
a program terminates. Observations include all value constructors and
blame.  The function converting values to observations ($observe(v) =
o$) is defined in the natural way.

\begin{figure}
	%	Continuation typing \fbox{$\kappa : T_1 \Longrightarrow T_2$}
	%	\begin{gather*}
	%	\dots \quad
	%	\inference{
	%		c : T_1 \Longrightarrow T_2 &
	%		\kappa : T_2 \Longrightarrow T_3
	%	}{
	%		\langle c \rangle \kappa : T_1 \Longrightarrow T_3
	%	}
	%	\end{gather*}
	
	\[
	\begin{array}{rclr}
	\end{array}
	\]
	
	Reduction \fbox{$\judgeCreduce{s}{s}$}
	\[
	\begin{array}{rclr}
		\hiredrule{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{
			\kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa}
%			\langle\cOOcast{T_1}{l}{T_2}\rangle\kappa
		}
	}{}
	\redrule{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho(x)}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\vOOtt}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\vOOfun{\rho}{x}{e})}{\kappa}
	}{}
	\redrule{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{(\kOOconsI{e_2}{\rho}{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{(\kOOinl{\kappa})}
	}{}
	\redrule{
	\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
	\sOOinspect{e}{\rho}{(\kOOinr{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
\sOOinspect{e_1}{\rho}{(\kOOappI{e_2}{\rho}{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
\sOOinspect{e}{\rho}{(\kOOcar{\kappa})}}{}

\redrule{
	\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
	\sOOinspect{e}{\rho}{(\kOOcdr{\kappa})}}{}

\redrule{
\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
\sOOinspect{e_1}{\rho}{(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{}

\redrule{
\sOOreturn{v_1}{(\kOOconsI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOconsII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
\sOOreturn{(\vOOcons{v_1}{v_2})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinl{\kappa})}}{
\sOOreturn{(\vOOinl{v})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinr{\kappa})}}{
\sOOreturn{(\vOOinr{v})}{\kappa}}{}

\redrule{
\sOOreturn{v_1}{(\kOOappI{e_2}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOappII{(\vOOfun{\rho}{x}{e})}{\kappa})}}{
\sOOinspect{e}{\rho[x:=v_2]}{\kappa}}{}
	\hiredrule{
		\sOOreturn{v_1}{
			\kOOappII{\vOOcast{v_2}{
					\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
			}}{\kappa}
%			(\mathtt{app_2} \; \vOOcast{v_2}{
%				\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
%			} \; \kappa)
		}
	}{
		\sOOreturn{v_1}{
			\kOOcast{\cOOcast{T_3}{l}{T_1}}{
				\kOOappII{v_2}{
					\kOOcast{\cOOcast{T_2}{l}{T_4}}{\kappa}
				}
			}
%			\langle\rangle
%			(\mathtt{app_2} \; v_2 \; 
%			\langle\cOOcast{T_2}{l}{T_4}\rangle \kappa)}
		}
	}{}
	\redrule{
	\sOOreturn{
		(\vOOcons{v_1}{v_2})
	}{(\kOOcar{\kappa})}
	}{
	\sOOreturn{v_1}{\kappa}
	}{}
	\hiredrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{fst} \; \kappa)}
	}{
		\sOOreturn{v}{
			\kOOcar{
				\kOOcast{\cOOcast{T_1}{l}{T_3}}{\kappa}
			}}
	}{}
	\redrule{
	\sOOreturn{
		(\vOOcons{v_1}{v_2})
	}{(\kOOcdr{\kappa})}
	}{
	\sOOreturn{v_2}{\kappa}
	}{}
	
	\hiredrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{snd} \; \kappa)}
	}{
		\sOOreturn{v}{
			\kOOcdr{\kOOcast{\cOOcast{T_2}{l}{T_4}}{\kappa}}}
	}{}

\redrule{
\sOOreturn{v_1}{(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})}}{
\sOOinspect{e_3}{\rho}{
	(\kOOcaseIII{v_1}{v_2}{\kappa})
}}{}	

\redrule{
\sOOreturn{v_3}{
	(\kOOcaseIII{(\vOOinl{v})}{v_2}{\kappa})
%	(\mathtt{case_3}\;(\vOOinl{v})\;v_2\;\kappa)
}
}{
\sOOreturn{v}{(\kOOappII{v_2}{\kappa})}
}{}

\redrule{
	\sOOreturn{v_3}{
		(\kOOcaseIII{(\vOOinr{v})}{v_2}{\kappa})
%		(\mathtt{case_3}\;(\vOOinr{v})\;v_2\;\kappa)
	}
}{
\sOOreturn{v}{(\kOOappII{v_3}{\kappa})}
}{}

\redrule{
	\highlight{\sOOreturn{v_3}{
		(	\kOOcaseIII{
				\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
			}{v_2}{\kappa})
%		
%			(\mathtt{case_3}\;
%		(\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}})
%		\;v_2\;\kappa)
	}}
}{
	\highlight{\sOOreturn{v_3'}{
			(\kOOcaseIII{v}{v_2'}{\kappa})
	}}
}{\\&&
\highlight{\text{where}\;
v2' = \vOOcast{v_2}{\cOOcast{\POOfun{T_4}{T}}{l}{\POOfun{T_2}{T}}}}
\\&&
\highlight{\text{and}\;
v3' = \vOOcast{v_3}{\cOOcast{\POOfun{T_3}{T}}{l}{\POOfun{T_1}{T}}}}
}
	
	\redrule{
		\highlight{\sOOreturn{v}{(
				\kOOcast{c}{\kappa}
			)}}
	}{
\highlight{          
\begin{cases}
	\sOOreturn{v'}{\kappa} & \sidecond{applyCast(v,c) = \rOOsucc{v'}}
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
\end{cases}}
	}{}
\redrule{
\sOOreturn{v}{\kOOmt}}{
\sOOhalt{observe(v)}}{}
	\end{array}
	\]	
	
	Evaluation \fbox{$\judgeCeval{e}{o}$}
	\[
	\inference{
		\sOOinspect{e}{\emptyset}{wrap(\hckOOmt)} \longrightarrow_{B}^{*} 
		\sOOhalt{o}
	}{
		\judgeCeval{e}{o}
	}
	\]
	
	\caption{Dynamic semantics of the cast calculi as a CEK
          machine. The transitions that involve casts are highlighted
          in red.}
	\label{fig:machine-cekc}
\end{figure}

Let $r$ range over cast results. A cast result is either a success, which 
brings back a value, or a failure, which brings a blame label.

Let $s$ range over machine states. A state is either looking at an 
expression to decide what to do next, returning a value to a continuation, or 
halting with an observation.

Let $\kappa$ range over continuations. $\mathtt{stop}$ is the top 
continuation. The remaining continuations correspond to expressions. For 
example, $(\mathtt{cons_1} \; e \; \rho \; \kappa)$ is the continuation where 
we are waiting for the value of the first argument to a $\mathtt{cons}$. And 
the last continuation, $\langle c \rangle \kappa$ is to cast the value before 
returning to $\kappa$.

\begin{figure}
	
	\fbox{$applyCast(v,c) = r$}
	\[
	\begin{array}{rclr}
	\funrule{
		applyCast(v,\cOOcast{\star}{l}{\star})
	}{
		\rOOsucc{v}
	}{}
	\funrule{
		applyCast(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
	}{
		applyCast(v,\cOOcast{P_1}{l_2}{P_2})
	}{}
	\funrule{
		applyCast(v,\cOOcast{P}{l}{\star})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
	}{}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
	}{\sidecond{P_1 \smile P_2}}
	\funrule{
		applyCast(v,\cOOcast{P_1}{l}{P_2})
	}{
		\rOOfail{l}
	}{\sidecond{\neg P_1 \smile P_2}}
	
	\end{array}
	\]
	\caption{Definition of $applyCast$for \lazyD}
	\label{fig:applyCast-D-C}
\end{figure}

\begin{definition}[\lazyD{} CEK Machine]
  The \lazyD{} CEK machine, written \ineffCEKD{}, is the CEK machine of
  \figref{fig:machine-cekc} using the $applyCast$ for \lazyD{} defined
  in \figref{fig:applyCast-D-C}.  We write the transition relations of
  this machine as $\judgeDreduce{s}{s}$ and $\judgeDreduceTrans{s}{s}$
  and write the evaluation function as $\judgeDeval{e}{o}$.
\end{definition}

We conjecture that \ineffCEKD{} agrees with the \lazyD{} cast calculus
of \citet{siek2009exploring}.

Next we define the CEK Machine for \lazyUD{}. The only difference with
respect to \lazyD{} is in the definition of the $\mathit{applyCast}$
function, in which a cast whose source or target is the unknown type
$\star$ is always split into two casts that go through an injectiable
type, that is, a type in which all sub-components are the unknown
type, such as $\star \to \star$.


\begin{definition}[\lazyUD{} CEK Machine]
  The \lazyUD{} CEK machine, written \ineffCEKUD{}, is the CEK machine of
  \figref{fig:machine-cekc} using the $applyCast$ for \lazyUD{} defined
  in \figref{fig:apply-Cast-UD}.  We write the transition relations of
  this machine as $\judgeUDreduce{s}{s}$ and $\judgeUDreduceTrans{s}{s}$
  and write the evaluation function as $\judgeUDeval{e}{o}$.
\end{definition}


\begin{figure}
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& v \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        v \langle \cOOcast{P}{l}{I} \rangle
          \langle \cOOcast{I}{l}{\star} \rangle
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        v \langle \cOOcast{\star}{l}{I} \rangle
          \langle \cOOcast{I}{l}{P} \rangle
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& v \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
     v \langle \cOOcast{P_1}{l}{P_2} \rangle & \text{if } P_1 \smile P_2
  \end{array}
  \]

  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}

We conjecture that \ineffCEKUD{} agrees with the \lazyUD{} cast
calculus of \citet{siek2009exploring}.

% the following are temporary -JS
\clearpage
\pagebreak

\subsection{Coercions in Normal Form} 
\label{sec:coercion-calculus}

In this section we review the
coercions~\citep{henglein1994dynamic,herman2010space} and the normal
form of \citet{siek2012interpretations} to motivate the design of
hypercoercions.  We ignore sum types and product types in this
section, because \citet{siek2012interpretations} did not discuss
them. We assume a basic familiarity with coercions and direct readers
who are not familiar with them to \citet{siek2012interpretations}.

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{I}{injectable types (\lazyD)}{
		\POOfun{T}{T} \mid \POOunit}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOfun{\TOOdyn}{\TOOdyn} \mid \POOunit
	}
	\stxrule{c}{coercions}{
		\ncInj{I} \mid
		\ncProj{I}{l} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncSeq{c}{c} \mid
		\ncFun{c}{c}
	}
	\stxrule{\bar{c}}{wrapper coercions}{	
		\ncInj{I} \mid
		\ncFun{\hat{c}}{\hat{c}} \mid
		\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}
	}
%	\stxrulecont{
%		\ncProd{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncProd{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
%		\ncSum{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncSum{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid	
%	}
	\stxrule{\hat{c}}{normal coercions}{
		\bar{c} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncProj{I}{l} \mid
		\ncSeq{\ncProj{I}{l}}{\ncFail{l}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncInj{I}}
	}
	\stxrulecont{
		\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}}
	}
	\end{array}
	\]
	\caption{Syntax of coercions and normal forms}
	\label{fig:normal-coercion}
\end{figure}

\figref{fig:normal-coercion} gives the grammar for coercions, written
$c$ and also coercions in normal form, written $\hat{c}$.
%
To review, an injection $I!$ takes a value from an injectiable type
$I$ to type $\TOOdyn$. An injectable type is simply a type that can be
cast directly to (injection) and from (projection) $\TOOdyn$. The
definition of injectable type depends on blame strategy. With \lazyD,
all pre-types are injectable. With \lazyUD, only
$\POOfun{\TOOdyn}{\TOOdyn}$ is injectable.
%
A projection $I?^l$ takes a value from type $\TOOdyn$ to type $I$, or
halts the program and blames $l$ if the value is of a different type.
The coercion $\iota$ is the identity, $\bot^{l}$ is the coercion that
always fails and blames $l$, and $\ncSeq{c_1}{c_2}$ applies $c_1$ and
then $c_2$ in sequence. The function coercion $\ncFun{c_1}{c_2}$
applies $c_1$ to the argument of a function and $c_2$ to the return
value.

Coercions come with a reduction relation so it is natural to ask what
are their normal forms. The most important of the reduction rules are
the ones that handle when an injection is followed by a projection,
which for \lazyUD{} are:
\begin{align*}
  I! ; I?^l &\longmapsto \iota \\
  I_1! ; I_2?^l & \longmapsto \bot^l & \text{if } I_1 \neq I_2
\end{align*}
and the rule for pushing sequences below function coercions:
\begin{align*}
  (c_1 \to c_2) ; (c_3 \to c_4) & \longmapsto
  (c_3 ; c_1) \to (c_2 ; c_4)
\end{align*}
Of course there are also rules that remove identity coercions.

\todo[inline]{UNDER CONSTRUCTION -Jeremy}


Let $\bar{c}$ range over wrapper coercions, which represent casts in $
\vOOcast{v}{c}$.  Let $\hat{c}$ range over normal coercions. If we
inline $\bar{c}$ and re-order the cases, the definition of $\hat{c}$
becomes:
\[
\begin{array}{rclr}
\stxrule{\hat{c}}{normal coercions}{
	\ncFun{\hat{c}}{\hat{c}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
	\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
	\ncId \mid
	\ncProj{I}{l} \mid
	\ncInj{I} \mid
	\ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
	\ncFail{l} \mid
}
\end{array}
\]

Three observations on this definition leads to hypercoercion: 
\begin{enumerate}
	\item The length of normal coercion is at most three.
	\item Projections are always at the beginning when present.
	\item Injections and failures are always at the end when present.
\end{enumerate}


\section{Definition of Hypercoercions} \label{sec:hypercoercion-definition}

\begin{figure}
	Syntax
	\[
	\begin{array}{lclr}
	\stxrule{I}{injectable types (\lazyD)}{P}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\TOOdyn}{\TOOdyn} \mid
		\POOprod{\TOOdyn}{\TOOdyn} \mid
		\POOsum{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{hypercoercions}{
		\hyperCoercionI \mid{}
		\hyperCoercionC{h}{m}{t}
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{m}{middles}{
		\POOunit \mid
		\POOfun{c_1}{c_2} \mid
		\POOprod{c_1}{c_2} \mid
		\POOsum{c_1}{c_2}
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
		
	hypercoercion typing \fbox{$c : T \Longrightarrow T$}
	\begin{gather*}
	\inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
	\quad
	\inference{
		\typingHC{h}{T_1}{P_1} &
		\typingHC{m}{P_1}{P_2} &
		\typingHC{t}{P_2}{T_2}
	}{
		\typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
	}
	\end{gather*}
	
	Head typing \fbox{$\typingHC{h}{T}{P}$}
	\begin{gather*}
	\inference{}{\typingHC{\epsilon}{P}{P}}
	\quad
	\inference{}{\typingHC{?^l}{\TOOdyn}{I}}
	\end{gather*}
	
	Middle typing \fbox{$\typingHC{m}{T}{T}$}
	\begin{gather*}
	\inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
	\quad
	\inference{
		\typingHC{c_1}{T_3}{T_1} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
	}
	\\
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
	}
	\quad
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
	}
		\end{gather*}
		
		Tail typing \fbox{$\typingHC{t}{P}{T}$}
		\begin{gather*}
		\inference{}{\typingHC{\epsilon}{P}{P}} \quad
		\inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
		\inference{}{\typingHC{\bot^l}{P}{T}} \quad
		\end{gather*}
	
	\caption{Definition of hypercoercions (HC)}
	\label{fig:hypercoercion}
\end{figure}

This section presents our first contribution, the definition of
hypercoercions.  The design of hypercoercions is motivated by
observations on coercion normal forms: a normal coercion has at most
three parts; projections are always at the beginning; injections and
failures are always at the end. Hypercoercions have similar shape: a
hypercion either is $\hyperCoercionI$, the identity cast for
$\TOOdyn$, or contains three parts, where the first part is either a
projection or a no-op while last part is either an injection, a
failure, or a no-op.

\figref{fig:hypercoercion} defines the syntax of hypercoercions. Types, 
pre-types, and blame labels are as before.

Let $c$ range over hypercoercions. A hypercoercion either is the identity 
cast between the dynamic types, or includes a head, a middle, and a tail. 
Let $h$ range over heads. A head is either a no-op, or a projection.
Let $m$ range over middles. There is a one-to-one 
correspondence between middles and type constructors. 
We generalize shallow-consistency to middles $m \smile m$ in the obvious way.
Let $t$ range over tails. A tail is either a no-op, an injection, or a 
failure.

Subsection~\ref{sec:ld-hc} defines functions that construct \lazyD\ 
hypercoercions. Subsection~\ref{sec:lud-hc} defines the \lazyUD\ counterparts. 
Functions that apply hypercoercions to values are deferred to 
Section~\ref{sec:hypercoercion-correctness} because they depends on a new 
definition of values, which is part of the framework in
Section~\ref{sec:framework}.

\subsection{\lazyD{} hypercoercions}
\label{sec:ld-hc}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{\ell}{Maybe$l$}{\epsilon \mid l}
	\end{array}
	\]
	
	Composition of hypercoercions \fbox{$c \fatsemi^\ell c = c$}
	\[ 
	\begin{array}{rclclr}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{}
	
	\comprulel{
		\hyperCoercionI
	}{
		\hyperCoercionC{\epsilon}{m}{t}
	}{
		\hyperCoercionC{?^{l}}{m}{t}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{
		c
	}{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{t}
	}{
		\hyperCoercionI
	}{
		\hyperCoercionC{h}{m}{!}
	}{
		\sidecond{\forall l. t \neq \bot^{l}}
	}
	
	\comprule{
		\hyperCoercionC{h_1}{m_1}{t_1}
	}{
		\hyperCoercionC{?^l}{m_2}{t_2}
	}{
		\hyperCoercionC{h_1}{m_1}{\bot^l}
	}{
		\sidecond{
			\neg \; m_1 \smile m_2
			\; \text{and} \;
			\forall l. t \neq \bot^{l}
		}
	}

\comprulel{
\hyperCoercionC{h_1}{m_1}{t_1}
}{
\hyperCoercionC{\epsilon}{m_2}{t_2}
}{
\hyperCoercionC{h_1}{m_1}{\bot^l}
}{
\sidecond{
	\neg \; m_1 \smile m_2
	\; \text{and} \;
	\forall l. t \neq \bot^{l}
}
}
\comprule{
\hyperCoercionC{h_1}{m_1}{t_1}
}{
\hyperCoercionC{?^l}{m_2}{t_2}
}{
\hyperCoercionC{h_1}{m_1 \fatsemi^{l} m_2}{t_2}
}{
\sidecond{
	m_1 \smile m_2
	\; \text{and} \;
	\forall l. t \neq \bot^{l}
}
}
	\comprule{
		\hyperCoercionC{h_1}{m_1}{t_1}
	}{
		\hyperCoercionC{\epsilon}{m_2}{t_2}
	}{
		\hyperCoercionC{h_1}{m_1 \fatsemi^{\ell} m_2}{t_2}
	}{
		\sidecond{
			m_1 \smile m_2
			\; \text{and} \;
			\forall l. t \neq \bot^{l}
		}
	}
%
%	\comprule{
%		\hyperCoercionC{h}{m_1}{t_1}
%	}{
%		\hyperCoercionC{\epsilon}{m_2}{t_2}
%	}{
%		\hyperCoercionC{h}{m'}{t'}
%	}{
%		\sidecond{
%			m_1 \fatsemi^{\ell} (m_2, t_2) = (m', t')
%			 \; \text{and} \;
%			 \forall l. t \neq \bot^{l}
%		}
%	}
%	
%	\comprule{
%		\hyperCoercionC{h}{m_1}{t_1}
%	}{
%		\hyperCoercionC{?^{l'}}{m_2}{t_2}
%	}{
%		\hyperCoercionC{h}{m'}{t'}
%	}{
%		\sidecond{
%			m_1 \fatsemi^{l'} (m_2, t_2) = (m', t')
%			\; \text{and} \;
%			\forall l. t \neq \bot^{l} 
%		}
%	}
	\end{array}
	\]
	
	Composition of middles \fbox{$m \fatsemi^\ell m = m$}
	\[ 
	\begin{array}{rclclr}
	\comprule{\POOunit}{\POOunit}{
		\POOunit
	}{}
	\comprule{\POOfun{c_1}{c_2}}{\POOfun{c_3}{c_4}}{
		\POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4}
	}{}
	\comprule{\POOprod{c_1}{c_2}}{\POOprod{c_3}{c_4}}{
		\POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4}
	}{}
	\comprule{\POOsum{c_1}{c_2}}{\POOsum{c_3}{c_4}}{
		\POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4}
	}{}
	\end{array}
	\]
	
	\fbox{$seq(c,c) = c$}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^\epsilon c_2
	}{}
	\end{array}
	\]
	
	\fbox{$id( P ) = m$}
	\[
	\begin{array}{rclr}
	\funrule{id(\POOunit)}{\POOunit}{}
	\funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
	}{}
	\end{array}
	\]
	
	\fbox{$id( T ) = c$}
	\[
	\begin{array}{rclr}
	\funrule{id(\star)}{
		\hyperCoercionI
	}{}
	\funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
	}{}
	\end{array}
	\]
	
	\fbox{$cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	\caption{\lazyD{} Hypercoercions}
	\label{fig:HC-D}
\end{figure}

\figref{fig:HC-D} defines functions that construct \lazyD{} hypercoercions. We 
expect language implementations to call $id(T)$, which constructs an 
identity, $seq(c,c)$, which composes two hypercoercions, and $
cast(T_1,l,T_2)$, which translate a cast to a hypercoercion. Other functions 
in the figure are their helpers.

Let $\ell$ range over $\epsilon$ and labels.
$ c_1 \fatsemi^\ell c_2$ composes hypercoercion $c_1$ and hypercoercion $c_2$.
When both $c_1$ and $c_2$ are $\hyperCoercionI$, their 
composition is also $\hyperCoercionI$.
When $c_1$ is $\hyperCoercionI$ but $c_2$ is not, the head of the 
composition must be a projection. In this 
case, if the head of $c_2$ is a projection, we reuse it. Otherwise, we need a 
label to build the projection. Since the head of $c_2$ is $\epsilon$, its 
source type must be a pretype. Thus we know $\ell$ must be a label and put it 
in the projection. 
When $c_1$ ends with a failure, the composition is $c_1$ itself. In all 
remaining cases, we shall assume that $c_1$ does not end with 
a failure.
When $m_1$ and $m_2$ have different top constructors ($\neg\;m_1 \smile 
m_2$), proceeding to $m_2$ can not make sense. So we end the composition 
with a failure. To do so we need a label. When $c_2$ starts with a 
projection, we shall accuse it of casting a value to a shallowly inconsistent 
type. When $c_2$ starts with a no-op, $\ell$ must be a label. And we accuse 
it of composing shallowly inconsistent hypercoercions. The last two cases 
compose $m_1$ and $m_2$ with a helper function $m \fatsemi^\ell m$, which 
assumes its inputs have the same top constructor. The definition of $m 
\fatsemi^\ell m$ is straightforward. Going back to the last two cases of $c_1 
\fatsemi^\ell c_2$. When $c_2$ starts with a projection, we have no clue 
whether the target type of $m_1$ is the same as the source of $m_2$, 
although we know they are shallowly consistent. So we give the $l$ in the 
projection to $m \fatsemi^\ell m$. When $c_2$ starts with a no-op, we reuse 
the $\ell$.

$seq(c_1,c_2)$ requires that the target type of $c_1$ is the same as the 
source of $c_2$. $c \fatsemi^\ell c$ does the job for it.
$id(T)$ constructs an identity coercion of $T$ with the help of $id(P)$. 
Their definitions are straightforward.
$cast(T_1,l,T_2)$ constructs a coercion from a source type, a label, and a 
target type. $c \fatsemi^\ell c$ does the most job.

\begin{proposition}[\lazyD\ hypercoercion is a monoid]
	\label{thm:hc-monoid}
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}
\begin{proof}
	By induction on hypercoercion(s).
\end{proof}

\begin{proposition}[]
	For all $T$ and $l$, $cast(T,l,T) = id(T) $
\end{proposition}
\begin{proof}
	By induction on T.
\end{proof}

\subsection{\lazyUD{} hypercoercion [Jeremy]}
\label{sec:lud-hc}

\todo[inline]{Jeremy needs to add text. -JS}

Figure~\ref{fig:HC-UD}

\begin{figure}
  Composition of hypercoercions \fbox{$c \fatsemi c = c$}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
       \hyperCoercionC{p_2}{m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{\epsilon} &\fatsemi& \hyperCoercionC{\epsilon}{m_2}{i_2} &=&
       \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{i_2} &=&
  \begin{cases}
    \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{p_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{p_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
     \hyperCoercionC{p_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$id( P ) = m$}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$id( T ) = c$}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
		\hyperCoercionI
    }{}
    \funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]

  
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}


Figure~\ref{fig:HC-UD-cast}


\begin{figure}
  \fbox{$\mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$\mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$\mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$\mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxilliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\begin{proposition}[\lazyUD\ hypercoercions form a monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}


\subsection{Compact Memory Representation for Hypercoercions}


\todo[inline]{UNDER CONSTRUCTION (a couple paragraphs) -Jeremy}


% the following are temporary -JS
\clearpage
\pagebreak

\section{A framework for proving correctness of cast representations}
\label{sec:framework}

This section presents our second contribution, a framework for proving
the correctness of cast representations, especially space efficient
ones. Section~\ref{sec:hypercoercion-correctness} applies this
framework to prove the correctness of the \lazyD{} hypercoercions.

We start by defining a CEK machine \effCEK{C} that is parameterized
over the cast representation $C$
(Section~\ref{sec:framework:cek}). This machine is space efficient
provided that the cast representation performs compression.  The
interface between the machine and the cast representation is defined
by an abstract data type, named Cast ADT, that we define shortly.  We
conjecture that all cast representations defined in the literature
are instances of this ADT.

In Section~\ref{secc:framework:monoid-correct} we prove that, for any
instance $C$ of the Cast ADT, if $C$ satisfies a more refined abstract
data type for Lazy D casts, then \effCEK{C} is equivelent to
\ineffCEKD{}, that is,
\[
  \evalEqv{\effCEK{C}}{\ineffCEKD}
\]
We conjecture that all of the cast representations in the literature
for \lazyD{} (supercoercions, coercions in normal form, threesomes)
are instances of the Lazy D Cast ADT.  We are working on a similar
theorem for \lazyUD{} cast representations.

We then apply this framework to \lazyD{} hypercoercions
(Section~\ref{sec:hypercoercion-correctness}), where we show that $H$
is an instance of the Lazy D Cast ADT, and therefore
\[
  \evalEqv{\effCEK{H}}{\ineffCEKD}
\]

Before turning to the definition of the abstract data types, we first
give the definition of values and cast results used by the \effCEK{C}, as they 
are mentioned in the definition of the ADTs.

\todo[inline]{The notation $\hcvOOinj{P}{v}$ is non-standard
   and should be explained. -JS
\\---\\
What is the standard way to display it? -KC}

\begin{definition}[Values and cast results for the \effCEK{C} machine] 
\label{def:values-effCEK}
  \[
  \begin{array}{rclr}
	\stxrule{v}{values}{
		\hcvOOtt \mid
		\hcvOOfun{c}{\rho}{x}{e}{c} \mid
		\hcvOOcons{v}{c}{v}{c} \mid
		\hcvOOinl{v}{c} \mid
		\hcvOOinr{v}{c} \mid
		\hcvOOinj{P}{v}
	}
\stxrule{r}{cast results}{
	\rOOsucc{v} \mid
	\rOOfail{l}
}
  \end{array}
  \]
\end{definition}

\todo[inline]{We also need to define results $r$ for \effCEK{C} -JS
\\---\\
Fixed. -KC}

\subsection{The Cast Abstract Data Types}

The \emph{Cast Abstract Data Type}, defined below, captures the set of
operators that a cast representation $C$ must provide for it to be
used with the \effCEK{C} machine.  The first three operators enables
\effCEK{C} to construct casts so we call them \textit{cast
  constructors}. The forth and last operator enables \effCEK{C} to
apply casts to values.

\begin{definition}[Cast Abstract Data Type (Cast ADT)]
  \label{def:cast-rep}
  A cast abstract data type is a set $Cast$, which is indexed by two types, 
  with four operators:
  \begin{description}
  \item[$id(T)$] constructs an identity cast from a type
  \item[$seq(c_1,c_2)$] composes two casts
  \item[$cast(T_1,l,T_2)$] constructs a cast from $T_1$ to $T_2$
  \item[$ applyCast(v,c)$] applies a cast to a value, producing a result
  \end{description}
  We denote by $c : T_1 \Longrightarrow T_2$ to mean $c$ is in $Cast \; T_1 \; T_2$
  and we say ``$c$ is from $T_1$ to $T_2$''.
\end{definition}

Next we define the \emph{Lazy D Cast ADT}, which capture the further
requirements that are needed for the theorem that establishes
equivalence to \ineffCEKD{}. Property (1) below states that $id(T)$
acts like the identity function. Property (2) states that $seq(c,c)$
acts like a sequence of casts. Properties (3) through (11) state that
$cast(T_1,l,T_2)$ act like the Lazy D $applyCast$
(Fig.~\ref{fig:applyCast-D-C}).

\begin{definition}[Lazy D Cast ADT]
  \label{def:surely-lazyd}
  A  Cast is a Lazy D Cast if:
  \begin{enumerate}
  \item if $v : T$, then $applyCast(v,id(T)) = \mathtt{succ} \; v $
  \item if $\judgeType{v}{T_1}$,
    $ \judgeTypeFT{c_1}{T_1}{T_2}$, and
    $ \judgeTypeFT{c_2}{T_2}{T_3}$,\\
    then $applyCast(v,seq(c_1,c_2)) = 
    applyCast(v,c_1) >>= \lambda v.applyCast(v,c_2)$\\
    where 
    \[
    \begin{array}{rcl}
      \rOOsucc{v} >>= f & = & f(v) \\
      \rOOfail{l} >>= f & = & \rOOfail{l}
    \end{array}
    \]
  \item if $v : T_1$ and $\neg T_1 \smile T_2$,
    then $applyCast(v,cast(T_1, l, T_2)) = \rOOfail{l} $
  \item if $v : \star$, 
    then $applyCast(v,cast(\TOOdyn,l,\TOOdyn)) = \rOOsucc{v} $
  \item if $v : P$,
    then $applyCast(\hcvOOinj{P}{v},cast(\star,l,P')) 
    = applyCast(v,cast(P,l,P')) $
  \item if $v : P$,
    then $applyCast(v,cast(P,l,\star)) = \rOOsucc{(\hcvOOinj{P}{v})} $
  \item if $v : \POOunit$,
    then $applyCast(v,cast(\POOunit,l,\POOunit)) = \rOOsucc{v} $
  \item if $(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}) : \POOfun{T_1}{T_2}$,
    then\\
    $ 
    applyCast(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}, 
    cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4})) \\
    = 
    \rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\rho}{x}{b}{seq(c_2,cast(T_2,l,T_4))})}$
  \item if $(\hcvOOcons{v_1}{c_1}{v_2}{c_2}) : \POOprod{T_1}{T_2}$,
    then \\
    $ 
    applyCast(\hcvOOcons{v_1}{c_1}{v_2}{c_2},cast(\POOprod{T_1}{T_2},l,T_3 
    \times 
    T_4))$\\
    $ = 
    \rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
    $ 
  \item if $(\hcvOOinl{v}{c}) : \POOsum{T_1}{T_2}$,
    then \\
    $ 
    applyCast(\hcvOOinl{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
    = \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))})} $
  \item if $(\hcvOOinr{v}{c}) : \POOsum{T_1}{T_2}$,
    then \\$
    applyCast(\hcvOOinr{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
    = \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_2,l,T_4))})} $
  \end{enumerate}
\end{definition}

%% After showing their cast is an instance of Lazy D Cast, users of our
%% frameworks can plug-in this cast representation to our space-efficient
%% abstract machine in subsection~\ref{ssec:framework:cek}, and prove
%% that this machine is equivalent to
%% \ineffCEKD\ (subsection~\ref{secc:framework:all-correct}), which
%% depends on lemmas in subsection~\ref{secc:framework:monoid-correct}.

\subsection{A Space-efficient CEK machine}
\label{sec:framework:cek}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
%	\stxrule{r}{cast results}{
%		\rOOsucc{v} \mid
%		\rOOfail{l}
%	}
%	\stxrule{s}{states}{
%		\sOOinspect{e}{\rho}{\kappa} \mid{}
%		\sOOreturn{v}{\kappa} \mid{}
%		\sOOhalt{o}
%	}
	\stxrule{\kappa}{continuation}{
		\kOOcast{c}{k}
	}
	\stxrule{k}{pre-continuations}{
		\kOOmt \mid{}
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa} \mid
		\kOOinr{\kappa}
	}
	\stxrulecont{
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa} \mid
		\kOOcdr{\kappa}
	}
	\stxrulecont{
		\kOOcaseI{e}{e}{\rho}{\kappa} \mid
		\kOOcaseII{v}{e}{\rho}{\kappa} \mid
		\kOOcaseIII{v}{v}{\kappa}
	}
	\end{array}
	\]
	
	Build continuation \fbox{$wrap(k) = \kappa$}
	\[
	\begin{array}{rclc}
	\funrule{wrap(k)}{\kOOcast{id(T_1)}{k}}{
		\sidecond{k : T_1 \Longrightarrow T_2}}
	\end{array}
	\]
	
	Extend continuation \fbox{$ext(c,\kappa) = \kappa$}
	\[
	\begin{array}{rclc}
	\funrule{ext(c_1,\kOOcast{c_2}{k})}{
		\kOOcast{seq(c_1,c_2)}{k}
	}{}
	\end{array}
	\]
	
	Reduction \fbox{$\judgeSreduce{C}{s}{s}$}
	\[
	\begin{array}{rclr}
	\hiredruleS{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
	}{}
	\redruleS{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho(x)}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\hcvOOtt}{\kappa}
	}{}
	\hiredruleS{
		\sOOinspect{(\eOOlam{T_1}{T_2}{x}{e})}{\rho}{\kappa}
	}{
		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{
			wrap(\kOOconsI{e_2}{\rho}{\kappa})
		}
	}{}
	\redruleS{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{wrap(\kOOinl{\kappa})}
	}{}
	\redruleS{
		\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{wrap(\kOOinr{\kappa})}
	}{}
	\redruleS{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{wrap(\kOOappI{e_2}{\rho}{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
		\sOOinspect{e}{\rho}{wrap(\kOOcar{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
		\sOOinspect{e}{\rho}{wrap(\kOOcdr{\kappa})}}{}
	
	\redruleS{
		\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
		\sOOinspect{e_1}{\rho}{wrap(\kOOcaseI{e_2}{e_3}{\rho}{\kappa})}}{}
	\hiredruleS{
		\sOOreturn{v}{\kOOcast{c}{k}}
	}{
	\begin{cases}
	\continue{k}{v'} & \sidecond{applyCast(v,c) = \rOOsucc{v'}} 
	\\
	\sOOhalt{(\oOOblame{l})} & \sidecond{applyCast(v,c) = \rOOfail{l}}
	\end{cases}
	}{}
	\end{array}
	\]
	
	Apply continuation
	\fbox{$\continue{k}{v} = s$}
	\[
	\begin{array}{rclr}
	

\funrule{
	\continue{v_1}{\kOOconsI{e_2}{\rho}{\kappa}}}{
	\sOOinspect{e_2}{\rho}{wrap(\kOOconsII{v_1}{\kappa})}}{}

\hifunrule{
	\continue{v_2}{\kOOconsII{v_1}{\kappa}}}{
	\sOOreturn{(\hcvOOcons{v_1}{id(T_1)}{v_2}{id(T_2)})}{\kappa}}{}

\hifunrule{
	\continue{v}{\kOOinl{\kappa}}}{
	\sOOreturn{(\hcvOOinl{v}{id(T)})}{\kappa}}{}

\hifunrule{
	\continue{v}{\kOOinr{\kappa}}}{
	\sOOreturn{(\hcvOOinr{v}{id(T)})}{\kappa}}{}

\funrule{
	\continue{v_1}{\kOOappI{e_2}{\rho}{\kappa}}}{
	\sOOinspect{e_2}{\rho}{
		wrap(\kOOappII{v_1}{\kappa})
	}}{}

\hifunrule{
	\continue{v_2}{(\kOOappII{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{\kappa})}}{
\begin{cases}
\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)} \\
\sidecond{applyCast(v_2,c_1) = \rOOsucc{v'}}
\\
\sOOhalt{l} \\
\sidecond{applyCast(v_2,c_1) = \rOOfail{l}}
\end{cases}
}{}


\hifunrule{
	\continue{\hcvOOcons{v_1}{c_1}{v_2}{c_2}}{
		\kOOcar{\kappa}
	}
}{
	\sOOreturn{v_1}{ext(c_1,k)}
}{}
\hifunrule{
	\continue{\hcvOOcons{v_1}{c_1}{v_2}{c_2}}{
		\kOOcdr{\kappa}
	}
}{
	\sOOreturn{v_2}{ext(c_2,k)}
}{}

\funrule{
	\continue{v_1}{\kOOcaseI{e_2}{e_3}{\rho}{\kappa}}
}{
	\sOOinspect{e_2}{\rho}{
		wrap(\kOOcaseII{v_1}{e_3}{\rho}{\kappa})
	}
}{}

\funrule{
	\continue{v_2}{
		\kOOcaseII{v_1}{e_3}{\rho}{\kappa}
	}
}{
	\sOOinspect{e_3}{\rho}{
	wrap(\kOOcaseIII{v_1}{v_2}{\kappa})
	}
}{}

\hifunrule{
	\continue{v_3}{
		\kOOcaseIII{(\hcvOOinl{v}{c})}{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{\kappa}
%		(\mathtt{case_3}\;()\;
%		()
%		\;)
	}
}{
	\sOOreturn{v}{wrap(\kOOappII{(\hcvOOfun{seq(c,c_1)}{\rho}{x}{e}{c_2})}{\kappa})}
}{}

\hifunrule{
	\continue{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}
	{
		\kOOcaseIII{(\hcvOOinr{v}{c})}{v_2}{\kappa}
	}
}{
	\sOOreturn{v}{wrap(\kOOappII{(\hcvOOfun{seq(c,c_1)}{\rho}{x}{e}{c_2})}{\kappa})}
}{}

\funrule{
	\continue{v}{\kOOmt}}{
	\sOOhalt{observe(v)}}{}
	
	\end{array}\]
	
%	Transitive closure of reduction \fbox{$s \longrightarrow_{S(C)}^{*} s$}
%	\[\dots\]
	
%	Evaluation \fbox{$\judgeSeval{C}{e}{o}$}
%	\[
%	\inference{
%		\judgeSreduceTrans{C}{
%			\sOOinspect{e}{\emptyset}{wrap(\hckOOmt)}
%		}{
%			\sOOhalt{o}
%		}		
%	}{
%		\judgeSeval{C}{e}{o}
%	}
%	\]
	
	\caption{Space-efficient CEK machine$\mathcal{S}(C)$}
	\label{fig:machine-cekcc}
\end{figure}

\figref{fig:machine-cekcc} defines \effCEK{C}, a space-efficient CEK
machine.  This machine is similar to the \ineffCEK{} machine
(Figure~\ref{fig:machine-cekc}).  The key differences are in values
and continuations.

Let $v$ range over values. In \ineffCEK{} we have one value
constructor for all casted value.  In \effCEK{C}, however, we do not
have this generic value constructor, instead we push those casts into
the ordinary values. For instance, $(\vOOcons{v_1}{v_2})$ corresponds
to $(\hcvOOcons{v_1'}{id(T_1)}{v_2'}{id(T_2)})$. To construct values
of the dynamic type, we use $(\hcvOOinj{P}{v})$.

Cast results ($r$) and machine states ($s$) are the same as for
\ineffCEK{}.

Let $\kappa$ range over continuations and let $k$ range over
pre-continuations.  A continuation is now a pre-continuation prefixed
with a cast.  Pre-continuation are like the continuations in
\ineffCEK{}, but there is no constructor for casts.  Continuations in
\ineffCEKD{} have zero or more casts at the top.  In \effCEK{C},
however, every continuation has exactly one cast at the top.
Continuations in \ineffCEK\ that have no casts at the top correspond
to continuations in \effCEK{C}\ whose casts are identity.
Continuations in \ineffCEK\ that have many casts at the top correspond
to continuations in \effCEK{C}\ where those casts are composed by
$seq(c,c)$.

The transition relation $\judgeSreduce{C}{s}{s}$ uses functions provides by $C$ 
to represent cases and to apply casts.
%
When evaluating a cast expression, the machine extends the continuation with 
cast $cast(T_1,l,T_2)$. The function $ext(c,\kappa)$ composes $c$ with the cast 
at the top of $k$ by calling $seq$.
%
To construct a function, the machine fills the casts $id$.
%
To return a value to a continuation, the machine first applies the top cast to 
the value. If the application fails, the machine halts with the blame label 
from the failure. Otherwise, the machine handles the pre-continuation with 
$cont$.
%
When the machine constructs a pair, a left injection, or a right injection, it 
fills the casts with $id$ as well, just like how it did for functions. 
%
To apply a function, the machine applies the domain cast $c_1$ to the 
operand $v_2$, extends the continuation with the codomain cast $c_2$, and 
evaluate the function body.
%
To take out the first part of a pair, the machine returns the first value to a 
continuation extended with the first cast. Taking out the second part of a pair 
is similar.
%
%%In case splitting, if the target value is a left injection, the
%%machine moves to a state that will apply the first continuation
%%function to the value inside the left injection. The case for right
%%injection is similar.
%%
To case split a variant, the machine first look at the variant value. If the 
variant is a left injection, the machine composes the cast in the left 
injection with the domain casts of the first continuation function, then moves 
to a state that will apply the new function to the value in the left injection.
The case for right injections is similar.

Transitive closure of reduction ($\judgeSreduceTrans{C}{s}{s}$) and 
evaluation ($\judgeSeval{C}{e}{o}$) are standard. Value typing 
($\judgeType{v}{T}$) is straightforward.

\subsection{\effCEK{C} is equivalent to \ineffCEKD{}, provided $C$ is an instance of the Lazy D ADT}
\label{secc:framework:monoid-correct}

In this subsection, we prove that for all $C$, if $C$ is a Lazy D Cast
ADT, then
\[
  \evalEqv{\effCEK{C}}{\ineffCEKD}
\]
The main work of the proof is in a lemma that establishes a weak
bisimulation between \effCEK{C} and \ineffCEKD{}.  The bisimulation
goes more smoothly if we require two more properties of the cast
representation: that the casts form a monoid (the $id$ and $seq$
operators) and that the cast constructor is equivalent to the identity
operator when applied to an identical source and target type.
However, the final theorem does not require these two properties
because we can prove 1) that \effCEK{C_1} and \effCEK{C_2} are
equivalent for any two Lazy D Cast ADTs $C_1$ and $C_2$
(Proposition~\ref{thm:surely-lazyD-eqv}), and 2) there is an instance
of the Lazy D Cast ADT, named $L$, that is a monoid and satisfies the
two extra properties, and is therefore equivalent to \ineffCEKD{}
(Lemma~\ref{lem:L-correct}). So by transitivity, for any Lazy D Cast
ADT $C$ we have \evalEqv{\effCEK{C}}{\ineffCEKD}.

\subsubsection{Weak Bisimulation between \effCEK{C} and \ineffCEKD{}}

We shall prove that if a instance of Cast ADT $C$ is Lazy D, is a
monoid, and if $cast(T,l,T) = id(T)$, then there is
%% $eval_\mathcal{D} = eval_{\mathcal{S}(C)}$. We proof this lemma with
a weak bisimulation between \effCEK{C} and \ineffCEKD{}.
We define monoid as follows.

\begin{definition}[Monoid]
	A Cast ADT is a monoid if 
	for all
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c_1) = c_1$,
		\item $seq(c_1,id(T_2)) = c_1$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{definition}

%Lazy D Cast ADT confines the behavior of operators so narrowly that it 
%effectively allows us to ``run'' programs without referring to an actual 
%representation of cast.

\todo[inline]{How does the following bisimulation relation
  compare to the one used in the Blame and Coercion paper?
  Are there any guiding principles to how this bisimulation
  relation was constructed? -JS
\\---\\
The guiding principle is to keep the change in D side atomic. \\
In the blame and coercion paper,
the bisimulation relation between $ \lambda{}C $ and $ \lambda{}S $ seems to be 
related, but its (iii) rules in Figure 6 looks wired to me. -KC}

Fig.~\ref{fig:bisim-SC-D} defines the bisimulation relation.  It is
the smallest congruence relation that also includes the pairs induced
by the rules in Fig.~\ref{fig:bisim-SC-D}.
%
The relation is mutually defined on continuations, written $\kappa
\approx \kappa$, and values, written $v \approx v : T$, where $T$ is
their type.
%
If $k \approx \kappa$, adding an identity cast on top of $k$ gives a related 
continuation.
%
\todo[inline]{The use of ``wrap'' obscures this explanation.
  Consider getting rid of wrap by inlining it. -JS
\\---\\
I agree that inlining wrap and ext can improve readability of $\kappa \approx 
\kappa$, but this would make latex different from Agda, is it alright?
-KC}
%
If $\kappa_1 \approx \kappa_2$, extending $\kappa_1$ and $\kappa_2$ with the 
same cast gives related results.
%
If two values of type $P$ are related, injecting them to $\TOOdyn$ gives 
related values.
%
% The following is part of being a congruence. -JS
%Unit values are of course related. 
%
To relate to a non-casted function in \ineffCEKD, the function in \effCEK{C} 
must use identities as its casts.
%
If functions are related, we can apply the same cast on both side.
%
Rules for products and sums are similar.

\begin{figure}
	$\text{\effCEK{C}} \approx \text{\ineffCEKD}$
%	\[\dots\]
	
	\fbox{$\kappa \approx \kappa$}
	\begin{gather*}
	\inference{
		k \approx \kappa
	}{
		wrap(k) \approx \kappa
	}
	\quad
	\inference{
		\kappa_1 \approx \kappa_2
	}{
		ext(cast(T_1,l,T_2),\kappa_1) \approx 
		\kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa_2}
	}
\\
	\end{gather*}
\\	
	\fbox{$v \approx v : T$}
	\begin{gather*}
	\inference{
		v_1 \approx v_2 : P
	}{
		\hcvOOinj{P}{v_1} \approx \vOOcast{v_2}{\cOOcast{P}{l}{\TOOdyn}}
		: \TOOdyn
	}
\\ \\
	%% \inference{}{
	%% 	\hcvOOtt \approx \vOOtt : \POOunit
	%% }
	%% \quad
	\inference{}{
		\hcvOOtt \approx \vOOcast{\vOOtt}{\cOOcast{\POOunit}{l}{\POOunit}}
		: \POOunit
	}
	\\ \\
	\inference{
		\rho_1 \approx \rho_2 &
		dom(\rho_1) = dom(\rho_2) = \Gamma \\
		\Gamma , x : T_1 \vdash e : T_2
	}{
		\hcvOOfun{id(T_1)}{\rho_1}{x}{e}{id(T_2)}
		\approx
		\vOOfun{\rho_2}{x}{e}
		: \POOfun{T_1}{T_2}
	}
\\ \\
\inference{
\hcvOOfun{c_1}{\rho}{x}{e}{c_2} \approx v_2 : \POOfun{T_1}{T_2} \\
%		\judgeType{\hcvOOfun{c_1}{\rho}{x}{e}{c_2}}{\POOfun{T_1}{T_2}} \\
c_1' = seq(cast(T_3,l,T_1),c_1) \\
c_2' = seq(c_2,cast(T_2,l,T_4))
}{
\hcvOOfun{c_1'}{\rho}{x}{e}{c_2'}
\approx
\vOOcast{v}{\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}}
: \POOfun{T_3}{T_4}
}
\\ \\
	\inference{
		v_1 \approx v_2 : T_1 &
		v_3 \approx v_4 : T_2 &
	}{
		\hcvOOcons{v_1}{id(T_1)}{v_3}{id(T_2)}
		\approx
		\vOOcons{v_2}{v_3}
		: \POOprod{T_1}{T_2}
	}
\\ \\
	\inference{
		\hcvOOcons{v_1}{c_1}{v_3}{c_2} \approx v_2 : \POOsum{T_1}{T_2} \\
		c_1' = seq(c_1,cast(T_1,l,T_3)) \\
		c_2' = seq(c_2,cast(T_2,l,T_4))
	}{
		\hcvOOcons{v_1}{c_1'}{v_3}{c_2'} \approx
		\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{\POOprod{T_3}{T_4}}}
		: \POOprod{T_3}{T_4}
	}
\\ \\
	\inference{
		v_1 \approx v_2 : T_1
	}{
		\hcvOOinl{v_1}{id(T_1)} \approx \vOOinl{v_2}
		: \POOsum{T_1}{T_2}
	}
	\quad
	\inference{
		\hcvOOinl{v_1}{c} \approx v_2
		: \POOsum{T_1}{T_2} &
		c' = seq(c,cast(T_1,l,T_3))
	}{
		\hcvOOinl{v_1}{c'} \approx
		\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
		: \POOsum{T_3}{T_4}	
	}
	\\
	\inference{
	v_1 \approx v_2 : T_2
	}{
	\hcvOOinr{v_1}{id(T_2)} \approx \vOOinr{v_2}
	: \POOsum{T_1}{T_2}
	}
	\quad
	\inference{
	\hcvOOinr{v_1}{c} \approx v_2
	: \POOsum{T_1}{T_2} &
	c' = seq(c,cast(T_2,l,T_4))
	}{
	\hcvOOinr{v_1}{c'} \approx
	\vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
	: \POOsum{T_3}{T_4}
	}
	\end{gather*}
	\caption{Bisimulation between \effCEK{C} and \ineffCEKD}
	\label{fig:bisim-SC-D}
\end{figure}

\todo[inline]{Give the motivation for the following lemma. Where
  does it get used? As in, which case of which other lemma or theorem? -JS
\\---\\
Partially fixed. Will say in which cases after finishing the bisim proof. -KC}

We use the following lemma in our bisimulation proof.

\begin{lemma}[SoAndSo]
	\label{thm:lem-apply-cast-SD}
	Assume $C$ implements Lazy D Cast ADT
	and $v_1$ is a value in \effCEK{C}
	and $v_2$ is a value in \ineffCEKD\
	and $v_1 \approx v_2 : T_1$,
	\[
	applyCast_{\text{\effCEK{C}}}(v,cast(T_1,l,T_2)) 
	\approx 
	applyCast_{\text{\ineffCEKD}}(v,\cOOcast{T_1}{l}{T_2})
	\]
\end{lemma}
\begin{proof}
	Case splitting whether $T_1$ is shallowly consistent with $T_2$.
	If yes, case splitting how they are shallowly consistent.
	Then apply properties (3) - (11) of Lazy D Cast when applicable.
\end{proof}

Before proving the weak bisimulation between \effCEK{C} and \ineffCEKD, we 
introduce one more definition.

\begin{definition}[$s \approx^{*} s$]
Given any two states $s_1$ and $s_2$, we write $s_1 \approx^{*} s_2$
if and only if there exists a state $s_2' \in \text{\ineffCEKD}$ such
that
\[
s_1 \approx s_2'
\;\text{and}\;
\judgeDreduceTrans{s_2}{s_2'}
\]
\end{definition}

\todo[inline]{Explain that this is an unusual formulation of a weak
  bisimulation.  We promise it will all be OK regarding how it is used
  in the correctness proof for S(C). -JS}


\begin{lemma}[Weak Bisimulation between \effCEK{C} and \ineffCEKD]
	\label{thm:surely-monoidic-reduce}
	Assume $C$ implements Lazy D Cast ADT
	and $C$ is a monoid
	and $cast(T,l,T)=id(T)$,
	$ s_{1} \in \text{\effCEK{C}}$,
	$ s_{2} \in \text{\ineffCEKD}$,
	$ s_{1} \approx s_{2}$,
\begin{enumerate}
	\item If $s_1 = \sOOhalt{o}$ then $s_2 = \sOOhalt{o}$
	\item If $s_2 = \sOOhalt{o}$ then $s_1 = \sOOhalt{o}$
	\item If $\judgeSreduce{C}{s_1}{s_3}$ 
		then $\judgeDreduce{s_2}{s_4}$ for some $s_4$
	\item If $\judgeDreduce{s_2}{s_4}$
		then $\judgeSreduce{C}{s_1}{s_3}$ for some $s_3$
	\item If $\judgeSreduce{C}{s_1}{s_3}$ 
		and  $\judgeDreduce{s_2}{s_4}$ 
		then $s_3 \approx^{*} s_4$
\end{enumerate}
	Or diagrammatically, 
	\[\begin{array}{clclc}
	s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
	\rotatebox[origin=c]{90}{$\approx$} 
	& & & \;\;\;\rotatebox[origin=c]{-20}{$\approx$} \\
	s_{2} & 
	\longrightarrow_{\text{\ineffCEKD}} & s_2' &
	\longrightarrow^{*}_{\text{\ineffCEKD}} & s_2'' \\
	\end{array}\]
\end{lemma}
\begin{proof}
	Part (1) and (2) follow from the definition of $s \approx s$.
	Part (3) and (4) are true because we have transition rules for every 
	non-halting state.
	Part (5) is more interesting. Our goal is to prove that one reduction step 
	in 	\effCEK{C} corresponds to one or more steps in \ineffCEKD.	
	Consider
	\[
	\sOOreturn{\hcvOOcons{v_{11}}{c_{11}}{v_{12}}{c_{12}}}{
		wrap(\kOOcar{\kappa})
	}
	\approx
	\sOOreturn{v_2}{\kOOcar{\kappa}}
	\]

	By looking at the definition of $v \approx v$, we know
	\[ c_{11} = seq(\dots seq(id(T_1),cast(T_1,l,T_3)) \dots) \]
	\[ c_{12} = seq(\dots seq(id(T_2),cast(T_2,l,T_4)) \dots) \] 
	\[ v_2 = \vOOcast{(\vOOcons{v_{21}}{v_{22}})}{
		\cOOcast{\POOprod{T_1}{T_2}}{l_1}{\POOprod{T_3}{T_4}}} \dots
	\]
	Thus we have the following reduction in \effCEK{C}. The equation 
	reasoning employs the fact that $C$ is a monoid.
	\[
	\begin{array}{ll}
&
\sOOreturn{\hcvOOcons{v_{11}}{c_{11}}{v_{12}}{c_{12}}}{wrap(\kOOcar{\kappa})}
\\
\longmapsto_\text{\effCEK{C}} &
\sOOreturn{v_{11}}{ext(c_{11},\kappa)}
\\
= &
\sOOreturn{v_{11}}{ext(seq(\dots seq(id(T_1),cast(T_1,l,T_3))\dots),\kappa)}
\\
= &
\sOOreturn{v_{11}}{ext(cast(T_1,l,T_3),\dots,\kappa)}
	\end{array}
	\]

And we have the following reduction in \ineffCEKD, where the last state is 
related to the last state in the above sequence.

\[
\begin{array}{ll}
& \sOOreturn{
	\vOOcast{(\vOOcons{v_{21}}{v_{22}})}{		
	\cOOcast{\POOprod{T_1}{T_2}}{l_1}{\POOprod{T_3}{T_4}}} \dots
}{\kOOcar{\kappa}}
\\
\longmapsto_{\mathcal{D}}^{*} &
\sOOreturn{(\vOOcons{v_{21}}{v_{22}})}{
	\kOOcar{
	\kOOcast{\cOOcast{T_1}{l}{T_3}}{\dots\kappa}
}}
\\
\longmapsto_{\mathcal{D}} &
\sOOreturn{v_{21}}{
	\kOOcast{\cOOcast{T_1}{l}{T_3}}{\dots\kappa}
}
\end{array}
\]

Other cases are similar. Of course we need the lemma about $applyCast$ 
(\ref{thm:lem-apply-cast-SD}) when cast applications happen in both machines. 
And in case spliting, we shall use $cast(T,l,T)=id(T)$ to relate the 
continuation functions.
\end{proof}

\todo[inline]{Should I invest time on restating the bisimulation lemma in the 
standard format? -KC}

\begin{corollary}[Correctness of \effCEK{C}]
  \label{thm:surely-monoidic-eval}
  Suppose $C$ is an instance of the Cast ADT
  and the \lazyD{} ADT, $C$ is a monoid,
  and $cast(T,l,T)=id(T)$.
  If $\judgetype{\emptyset}{e}{T}$ and $o : T$, then
  \[
    \text{\evalEqv{\effCEK{C}}{\ineffCEKD}}
  \]
\end{corollary}
\begin{proof}
  Proving that the left-hand side implies the right-hand side is
  trivial.  To prove $\judgeDeval{e}{o}$ implies
  $\judgeSeval{C}{e}{o}$, we first take one step in \effCEK{C}, and
  catch it up in \ineffCEKD\ by taking one or more steps in
  \ineffCEKD. As we just took a positive number of steps, we are
  closer to the halting state.
  \todo[inline]{I might want to revise this proof. -KC}
\end{proof}

%% \subsection{\lazyD\ Cast ADT Respect \ineffCEKD}
%% \label{secc:framework:all-correct}

%% In this subsection, we prove that for all $C$, if $C$ is a Lazy D Cast ADT, 
%% then \evalEqv{\ineffCEKD}{\effCEK{C}}. We first 
%% prove that all $S(C)$ where $C$ is a Lazy D Cast ADT are equivalent, then 
%% connect this theorem to Lemma~\ref{thm:surely-monoidic-eval}.

\subsubsection{\effCEK{C_1} and \effCEK{C_2} are equivalence if $C_1$ and $C_2$ are Lazy D}

We prove the equivalence among two \effCEK{C} machines with a strong
bisimulation. The bisimulation relation is the smallest congruence relation 
that also includes the pairs induced by the rules below.
\todo[inline]{By ``derived from the definitions'' do you mean
 that it is a congruence? -JS
\\---\\
Exactly, fixed. -KC}

\begin{gather*}
\inference{
}{
	cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
	id_1(T) \approx id_2(T)
}
\quad
\inference{
	c_1 \approx c_2 &
	c_3 \approx c_4
}{
	seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\begin{lemma}[Strong Bisimulation among $\mathcal{S}(\cdot)$]
	\label{thm:CEKS-bisim}
	Assume $C_1$ and $C_2$ implements Lazy D Cast ADT
	$s_{1} \in \text{\effCEK{C_1}}$,
	$s_{2} \in \text{\effCEK{C_2}}$,
	$s_{1} \approx s_{2}$,
	\begin{enumerate}
		\item If $s_1 = \sOOhalt{o}$ then $s_2 = \sOOhalt{o}$
		\item If $s_2 = \sOOhalt{o}$ then $s_1 = \sOOhalt{o}$
		\item If $\judgeSreduce{C_1}{s_1}{s_3}$ 
		then $\judgeSreduce{C_2}{s_2}{s_4}$ and $s_3 \approx s_4$ for some $s_4$
		\item If $\judgeSreduce{C_2}{s_2}{s_4}$ 
		then $\judgeSreduce{C_1}{s_1}{s_3}$ and $s_3 \approx s_4$ for some $s_3$
	\end{enumerate}
%	
	Or diagrammatically, 
	\[\begin{array}{clc}
	s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_3\\
	\rotatebox[origin=c]{90}{$\approx$} 
	& & \rotatebox[origin=c]{90}{$\approx$} \\
	s_{2} & 
	\longrightarrow_{\text{\ineffCEKD}} & s_4 \\
	\end{array}\]
\end{lemma}
\begin{proof} By casing on $s_{1} \approx s_{2}$.
%
  \todo[inline]{The above sentence is not normal proof jargon.  Are
    you doing a proof by cases on $s_{1}
    \longrightarrow_{\text{\effCEK{C}}} s_1'$? -JS
\\---\\
By casing on the bisimulation relation. -KC}
%
  The key ideas of this proof are undoing sequencing with the property
  (2) of Lazy D Cast ADT, and handling all possibly uses of
  $cast(T,l,T)$ with property (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of two \lazyD{} Cast ADTs]
  \label{thm:surely-lazyD-eqv}
  Assume $C_1$ and $C_2$ implements Lazy D Cast ADT,
  \[
  eval_{\mathcal{S}(C_1)} = eval_{\mathcal{S}(C_2)}.
  \]
\end{proposition}
\begin{proof}
	Without lost of generality, assume $\judgeSreduce{C_1}{e}{o}$, prove 
	$\judgeSreduce{C_2}{e}{o}$.\\
	By the definition of $eval_{\mathcal{S}(C)}$, we know 
	\[
	\judgeSreduceTrans{C_2}{load_{\mathcal{S}(C_1)}(e)}{\sOOhalt{o}}
	\]
	By induction on this reduction sequence and Lemma~\ref{thm:CEKS-bisim}, we 
	have 
	\[\judgeSreduceTrans{C_2}{load_{\mathcal{S}(C_2)}(e)}{\sOOhalt{o}}\]
	that is, $\judgeSreduce{C_2}{e}{o}$
\todo[inline]{Induction on what? -JS
\\---\\
Fixed. -KC
\\---\\
Need to define load. -KC}
\end{proof}

\subsubsection{The $L$ instance of the Lazy D Cast ADT}

\todo[inline]{KC, please add the definition of $L$ -JS}

\begin{proposition}[$L$ properties]\ 
  \begin{enumerate}
  \item $L$ is an instance of the Lazy D ADT
  \item $L$ is a monoid
  \item $cast(T,l,T) = id(T)$
  \end{enumerate}
\end{proposition}

\begin{lemma}[$L$ is correct wrt. \ineffCEKD]
  \label{lem:L-correct}
  \[
  \text{\evalEqv{\effCEK{L}}{\ineffCEKD}}
  \]
\end{lemma}

\subsubsection{Correctness of \effCEK{C}}

\begin{theorem}[\effCEK{C} is correct wrt. \ineffCEKD{}]
  \label{thm:surely-lazyD-correct}
  Suppose $C$ is a \lazyD{} Cast ADT.  If
  $\judgetype{\emptyset}{e}{T}$ and $o : T$, then
  \[
  \text{\evalEqv{\effCEK{C}}{\ineffCEKD}}
  \]
\end{theorem}
\begin{proof}
	If we have a Lazy D Cast ADT and it is a monoid, this 
	proof is immediately from Lemma~\ref{thm:surely-monoidic-eval} and 
	Proposition~\ref{thm:surely-lazyD-eqv}. One such representation is to 
	represent casts as a list of triples of type, label, and type, where 
	$id(T)$ is the empty list and $seq(c,c)$ is the list append. Another such 
	representation is the \lazyD\ hypercoercion!
\end{proof}


\section{Correctness Proof of \lazyD{} hypercoercions}
\label{sec:hypercoercion-correctness}

In this section we prove \lazyD\ hypercoercion is 
correct. First we define $applyCast(v,c)$ to make it an instance of Cast ADT, 
then prove that it is also Lazy D, and finally apply 
Theorem~\ref{thm:surely-lazyD-correct} to finish the proof.

\figref{hc-applyCast} defines $applyCast(v,c)$ for \lazyD\ hypercoercion. 
Applying the identity cast for the 
dynamic type succeeds immediately. When applying a compound cast, we firstly 
apply the middle, then apply the tail. We denote by $r \; >>= \; f$ to mean 
that if $r$ is $\rOOsucc{v}$, the result is $f(v)$, otherwise the result 
is the failure.
$ applyMiddle(v,\ell,m)$ and $applyTail(v,t)$ are straightforward.
In the definition of $applyMiddle(v,\ell,m)$, we generalize 
shallow-consistency to compare middles and values ($v \smile m$) in the 
natural way.

\begin{figure}
	\fbox{$applyCast(v,c) = r$}
	\[
	\begin{array}{rclr}
	\funrule{applyCast(v,\hyperCoercionI,)}{\rOOsucc{v}}{}
	\funrule{applyCast(\hcvOOinj{P}{v},\hyperCoercionC{?^l}{m}{t})}{
		applyMiddle(v,l,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\funrule{applyCast(v,\hyperCoercionC{\epsilon}{m}{t})}{
		applyMiddle(v,\epsilon,m) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\end{array}
	\]
	
	\fbox{$applyMiddle(v,\ell,m) = r$}
	\[
	\begin{array}{rclr}
	\funrule{applyMiddle(\hcvOOtt,\ell,\POOunit)}{\rOOsucc{\hcvOOtt}}{}
	\funrule{applyMiddle(\hcvOOfun{c_1}{\rho}{x}{e}{c_2}\ell,\POOfun{c_3}{c_4})}{
		\rOOsucc{(\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\rho}{x}{e}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOcons{v_1}{c_1}{v_2}{c_2},\ell,\POOprod{c_3}{c_4})}{
		\rOOsucc{(\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 
		\fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(\hcvOOinl{v}{c_1},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)})}
	}{}
	\funrule{applyMiddle(\hcvOOinr{v}{c_2},\ell,\POOsum{c_3}{c_4})}{
		\rOOsucc{(\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)})}
	}{}
	\funrule{applyMiddle(v,l,m)}{
		\rOOfail{l}
	}{
		\sidecond{\neg v \smile m}
	}
	\end{array}
	\]
	
	\fbox{$applyTail(v,t) = r$}
	\[
	\begin{array}{rclr}
	\funrule{applyTail(v,\bot^l)}{\rOOfail{l}}{}
	\funrule{applyTail(v,\epsilon)}{\rOOsucc{v}}{}
	\funrule{applyTail(v,!)}{\rOOsucc{(\hcvOOinj{P}{v})}}{}
	\end{array}
	\]
	\caption{\lazyD\ hypercoercion's $applyCast$}
	\label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} hypercoercion is a \lazyD Cast ADT]
	\label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof} See the supplementary material. \end{proof}

\begin{theorem}[\lazyD{} hypercoercion Respect \ineffCEKD]
  If $\judgetype{\emptyset}{e}{T}$ and $o : T$
  \[
  \text{\evalEqv{\effCEK{H}}{\ineffCEKD}}
  \]
\end{theorem}
\begin{proof}
	Immediately from Theorem~\ref{thm:surely-lazyD-correct} and 
	Lemma~\ref{thm:hc-surely-lazyD}.
	Alternatively, from Lemma~\ref{thm:surely-monoidic-eval},
	Lemma~\ref{thm:hc-surely-lazyD}, and 
	Proposition~\ref{thm:hc-monoid}.
\end{proof}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile,all}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots


\end{document}
