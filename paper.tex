%% For double-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{$\mathtt{Lazy UD}$}
\newcommand{\lazyD}{$\mathtt{Lazy D}$}
\newcommand{\eager}{$\mathtt{Eager}$}
\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}
\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{#1 \; #2}
\newcommand{\eOOcons}[2]{\mathtt{cons} \; #1 \; #2}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{\langle \cOOcast{#2}{#3}{#4} \rangle #1}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\oOOinj}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
%\newcommand{\cOOcast}[3]{#3 \overset{#2}{\Leftarrow} #1}
\newcommand{\cOOcast}[3]{#3 \Leftarrow^{#2} #1}
\newcommand{\vOOcast}[2]{\langle#2\rangle#1}
\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}
\newcommand{\kOOmt}[0]{\mathtt{stop}}
\newcommand{\kOOconsI}[3]{\mathtt{cons_1} \; #1 \; #2 \; #3}
\newcommand{\kOOconsII}[2]{\mathtt{cons_2} \; #1 \; #2}
\newcommand{\kOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\kOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\kOOappI}[3]{
	\mathtt{app_1} \; #1 \; #2 \; #3
}
\newcommand{\kOOappII}[2]{
	\mathtt{app_2} \; #1 \; #2}
\newcommand{\kOOcar}[1]{
	\mathtt{fst} \; #1}
\newcommand{\kOOcdr}[1]{
	\mathtt{snd} \; #1}
\newcommand{\kOOcaseI}[4]{
	\mathtt{case_1} \; #1 \; #2 \; #3 \; #4}
\newcommand{\kOOcaseII}[4]{
	\mathtt{case_2} \; #1 \; #2 \; #3 \; #4}
\newcommand{\kOOcaseIII}[3]{
	\mathtt{case_3} \; #1 \; #2 \; #3}
\newcommand{\kOOcast}[2]{
	\langle #1 \rangle #2}
\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{inj} \; #2}
\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D cast calculus on space-inefficient CEK
\newcommand{\judgeCreduce}[2]{#1 \longrightarrow_{\mathcal{C}} #2}
\newcommand{\judgeCreduceTrans}[2]{#1 \longrightarrow_{\mathcal{C}}^{*} #2}
\newcommand{\judgeCeval}[2]{#1 \Downarrow_{\mathcal{C}} #2}
\newcommand{\redrule}[3]{#1 & \longrightarrow_\mathcal{C} & #2 & #3\\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longrightarrow_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longrightarrow_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{#2 \Downarrow_{\mathcal{S}(#1)} #3}
\newcommand{\redruleS}[3]{#1 & \longrightarrow_{\mathcal{S}(C)} & #2 & #3\\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hypercoercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvDS}[3]{#2 \approx_{\mathcal{DS}} #3}
% to-dos
\newcommand{\todoKC}[1]{\todo[inline]{KC needs to #1}}
\newcommand{\todoKCFixed}[0]{\todo[inline]{Fixed. -KC}}
% abbrev
\newcommand{\castCalculus}[0]{$\lambda_{\rightarrow}^{\langle\cdot\rangle}$}

\begin{document}

%% Title information
\title{Blame and Coercion: Together Again for the Second Time}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
\todoKC{rewrite this abstract based on the comparision table.}
  Gradual Typing is great. Implementing gradually typed with blame
  tracking and space efficiency is tricky. There exist two technique
  to do this: coercion and threesome. Coercion is easy to understand,
  and easy enough to implement, but difficult to reason about
  formally. Threesome is hard to understand, easy to implement, and
  easy to reason about formally. We propose hypercoercion, which is
  easy to understand, as easy to implement as coercion, and easy to
  reason about formally.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\listoftodos{}


\section{Introduction}

\todo[inline]{I see lots of mistakes regarding when to make words
  plural (whether they should have an ``s'' at the end). Please review
  the rules of English regarding plurals. The rules are tricky...
  some words don't have a plural form, like ``blame''. -JS
  \\---\\
  Will fix grammar after fixing all other problems -KC}
\todo[inline]{The first paragraph of the introduction should summarize
  the entire introduction, and in some sense, the entire paper. -JS}

Around 2006, many work on integrating dynamic typing and static typing emerge, 
notably gradual types \citep{siek2006gradual} and hybrid types 
\citep{flanagan2006hybrid}. 
Later \citet{wadler2009well} introduces Blame Calculus, an intermediate 
language for gradual types and hybrid types. 
Blame Calculus throws a blame label when a runtime type-check fails.
Labels provide useful debugging information, therefore are necessary for 
practical use of gradually typed languages.

Implementing gradually typed languages naively on top of blame calculus, 
however, suffices sever space leak.
For example, translation to Blame Calculus can wrap some expressions with code 
that performs runtime type-checking (casts), including expressions at 
tail positions. Thus, mutually tail-recursive functions in source language can 
consume unbounded space at runtime. There are more examples of space leaking in 
\citet{herman2010space}.

In 2007, \citet{herman2010space} proposes a solution to this problem by 
representing casts with coercion \citep{henglein1994dynamic}, 
which can be composed and normalized. Every coercion looks like a list of 
trees. For normal coercion, the length of the list is bounded by a small 
constant. And the depths of trees do not grow during composition and
normalization. These two facts implies that coercion is a space-efficient cast 
representation. This coercion, however, does not support blame 
tracking. 

After that, many efforts have been made to combine blame tracking and 
space efficiency. 

\citet{siek2009exploring} present another intermediate langauge for gradually 
typed language, cast calculus \castCalculus\ and achieve both blame-tracking 
and space-efficiency for this language by decorating \citet{herman2010space}'s 
coercions with labels. \castCalculus\ is simply typed lambda calculus extended 
with the dynamic type and cast expressions. The labels in \castCalculus{}, 
unlike their counterparts in the Blame Calculus, have no polarity. 
They also propose that there are four blame strategies for \castCalculus{}:
$ \{Lazy, Eager\} \times \{D, UD\} $. Eager strategies detect more potential 
type errors, but blame more programs. $ D $ and $ UD $ assign blame labels 
differently. They claim that their \lazyUD\ cast calculus is the same as the 
Blame Calculus, modulo label polarity, and prove that their their \lazyUD\ 
coercion calculus simulates their \lazyUD{} cast calculus. It is unknown, 
however, whether the simulation in the other direction also works.
\todo[inline]{Is it important to this paper whether there is a
simulation in the other direction? -JS
\\ --- \\
I guessed to say coercion is correct the other direction is 
necessary. -KC}

\citet{siek2010threesomes} proposes another approach to combine blame 
tracking and space efficiency. Their solution represents casts with threesomes, 
a novel cast representation. Threesome is proved space-efficient as well.
They prove that their calculus bisimulates the \lazyUD{} coercion 
calculus in \citet{siek2009exploring} and the Blame Calculus in 
\citet{wadler2009well}.

\citet{siek2012interpretations} present a revised coercion calculi.
They simplify the coercion calculi by only 
working with normal coercions (i.e. coercions in normal form). 
They conjecture that their revised coercion calculi bisimulate the 
corresponding cast calculi.

\citet{garcia2013calculating} develops
threesome for other blame strategies. After studying in depth the connection 
between coercion and threesome,
he claims that normal coercion with labels is easy to understand but hard to 
implement and hard to reason about, and that 
threesome with labels, however, is easy to implement and easy to reason about 
but hard to understand. 
His claim is mostly affirmed by the group of people who develop threesome 
(\citet{siek2015blame}).
His threesome calculi are equivalent to the coercion calculi of
\citet{siek2009exploring} because the former ones are derived from the latter 
ones.

\citet{siek2015blame} revisit the coercion-based approach. They revise
the \lazyUD{} coercion in \citet{siek2012interpretations} and prove
that their revised coercion calculus bisimulates the \lazyUD{} Blame
Calculus \citet{wadler2009well}.

Last year, \citet{kuhlenschmidt2018efficient} present Grift, a compiler for a 
gradually typed language of the same name. 
This implementation is based on the \lazyD{} coercion in 
\citet{siek2012interpretations}.
Their result suggests that normal coercion is easy enough to implement in a 
compiler. 

So far, it seems that normal coercion is the best way to combine 
space-efficiency and blame-tracking: normal coercion is claimed easy to 
understand \citep{garcia2013calculating}\citep{siek2015blame} and is shown 
easy enough to implement in a compiler \citep{kuhlenschmidt2018efficient}.
Normal coercion is still not satisfactory, however, in at least two aspects.
Firstly, as we mentioned above, it is hard to reason about normal coercion. The 
major difficulty is from its non-structurally recursive composition.
For instance, the developers of Grift report it is tricky to convince
their proof assistants that the composition terminates.

Secondly, the definition of normal coercion lies unnecessarily on top 
of coercion: all coercions are normal when they are initially constructed, and 
\citet{siek2012interpretations} have shown an function that 
composes and produces normal coercions.
%
\todo[inline]{Many researchers would view this as a positive thing,
  not a negative. For example, the notion of normal forms comes up
  over and over again in mathematics and logic. -JS
\\ --- \\
I guess having a notion of normal forms is more convenient when a 
notion of normalization is convenient. But we don't even need a notion of 
normalization for cast representations. -KC
\\ --- \\
FWIW, I agree with you. But the point is that the argument is not
likely to be convincing to the reader, so we're probably better off
not wasting space on it. -JS
}

Perhaps unsurprisingly, threesome has a structurally recursive compose and a 
self-standing definition. Together with \citet{garcia2013calculating}'s 
work, they suggest that there might be a cast representation whose definition 
is self-standing, and whose composition is structurally recursive. 
supercoercion introduced in \citet{garcia2013calculating} could be a promising 
candidate. It is believed even more complicated than threesome 
\citep{siek2015blame}. In fact, it uses 10 constructors to deal with an 
elementary type system with only base types and 
function types. And four constructors are directly related to function types. 
Thus, supercoercion might not scale very well to more sophisticated type 
systems. 

We present hypercoercion, a cast representation whose composition is 
structurally recursive, and whose definition is self-standing. What's more, it 
should be at 
least as easy to implement and understand as normal coercions, because there is 
a clear connection between them, as we will show in Section 
\ref{sec:hypercoercion}.
Our hypercoercion considers sum types and product types, which are not 
considered in all proofs above. Adding each of them requires us to add only one 
new constructor to a component of hypercoercion. This suggests that 
hypercoercion might scale better than supercoercion.

We prove formally that the \lazyD{} (resp. \lazyUD{}) hypercoercion calculus 
bisimulates the \lazyD{} (resp. \lazyUD{}) cast calculus. This is 
the first bisimulation proof for the \lazyD{} cast calculus as far as we know.
We care more about lazy strategies because recently, \citet{new2019gradual} 
show that \eager{} strategies are incompatible with $\eta$-equivalence of 
functions, which suggest that these strategies are not very ideal. 
\todo[inline]{Explain why we care about \lazyD{} and \lazyUD{}. -JS
  \\ --- \\ Explained, not sure if it suffice. -KC
  \\ --- \\
  That's good that you explained why lazy instead of eager.
  (Also, you should add that we are interested in lazy because
  that's what Grift does.)\\
  But you haven't explained why we are interested in both D and UD. -JS
}

The structure of this paper is as follows. 
Section \ref{sec:blame-calculus} reviews the state-of-art of $Lazy$ cast 
calculi. 
Section \ref{sec:coercion-calculus} reviews the state-of-art of $Lazy$ Coercion 
Calculi. 
In section \ref{sec:hypercoercion} we present hypercoercion.
Section \ref{sec:conclude} concludes.
\todo[inline]{Lots of missing sections. -JS}

\section{Background} \label{sec:blame-calculus}

In this section, we review lazy cast calculi (\ref{sec:cast-calculi}) and
normal coercion (\ref{sec:coercion-calculus}). 

\subsection{Cast Calculi}
\label{sec:cast-calculi}
\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P}{pre-types}{
		\POOunit \mid
		\POOfun{T_1}{T_2} \mid
		\POOprod{T_1}{T_2} \mid
		\POOsum{T_1}{T_2}
	}
	\stxrule{e}{terms}{
		\eOOvar{x} \mid{}
		\eOOsole{} \mid{}
		\eOOlam{T_1}{T_2}{x}{e} \mid
		\eOOapp{e_1}{e_2} \mid
		\eOOcons{e_1}{e_2} \mid
		\eOOcar{e} \mid
		\eOOcdr{e}
	}
	\stxrulecont{
		\eOOinl{e} \mid
		\eOOinr{e} \mid
		\eOOcase{e_1}{e_2}{e_3} \mid
		\eOOcast{e}{T_1}{l}{T_2} \mid
		\eOOblame{l}
	}
	\stxrule{v}{values}{
		\vOOtt{} \mid
		\vOOfun{\rho}{x}{e} \mid
		\vOOcons{v_1}{v_2} \mid
		\vOOinl{v} \mid
		\vOOinr{v} \mid		
		\vOOcast{v}{c}
	}
	\stxrule{c}{casts}{
		\cOOcast{T_1}{l}{T_2}
	}
	\stxrule{I}{injectable types (\lazyD)}{
		P
	}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\star}{\star} \mid
		\star \times \star \mid
		\star + \star
	}
	\stxrule{o}{observations}{
		\oOOinj \mid
		\oOOsole \mid
		\oOOfun \mid
		\oOOcons \mid
		\oOOinl \mid
		\oOOinr \mid
		\oOOblame{l}
	}
	\end{array}
	\]
	
	Consistency
	\fbox{$ T_1 \sim T_2 $}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	Shallow-consistency
	\fbox{$ T_1 \smile T_2 $}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
	} \quad
	\inference{}{
		T_{11} \times T_{12} \smile T_{21} \times T_{22}
	} \quad
	\inference{}{
	T_{11} \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	Term typing
	\fbox{$ \judgetype{\Gamma}{e}{T} $}
	\begin{gather*}
		\inference{
			\Gamma \vdash e : T_1 & T_1 \sim T_2
		}{
			\judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\eOOblame{l}}{T}
		}
	\end{gather*}
	
	Value typing \fbox{$ v : T $}
	\begin{gather*}
	\dots \quad
	\inference{
		v : I
	}{
		\vOOcast{v}{\cOOcast{I}{l}{\TOOdyn}} : \TOOdyn
	}
	\quad
	\inference{
		v : P_1 &
		P_1 \smile P_2
	}{
		\vOOcast{v}{\cOOcast{P_1}{l}{P_2}} : P_2
	}
	\end{gather*}

	\caption{Syntax and static semantics of the cast calculi.}
	\label{fig:blame-static}
\end{figure}

\figref{fig:blame-static} defines the syntax of cast calculi and its
static semantics. We extend the syntax in \citet{siek2009exploring} with sum 
types and product types. Besides, we annotate function codomain explicitly 
because we need to compute identity hypercoercion for the codomain when 
evaluating cast calculus with hypercoercions.
\todo[inline]{Which previous definitions are you refering to?  What
  are the little changes? -JS
\\ --- \\ Fixed -KC}
\todo[inline]{The term typing rule for casts is broken. -JS
\\ --- \\ Fixed -KC}
\todo[inline]{Why do you annotate the codomain of lambda abstractions
	explicitly? -JS
	\\---\\
	Because I apply $ id(\cdot) $ to the codomain in the HC CEK. -KC
        \\---\\
        The answer you put in the text is too vague. -JS
        \\---\\
        Fixed. -KC}
Let $ T $ range over types. A type is either the dynamic type $ \star $
(a.k.a. $ \mathtt{Dyn} $, $ \mathbb{?} $, or $ \mathtt{Unknown} $), 
or a pre-type. 
Let $ P $ range over pre-types. Every pre-type is a type with a type 
constructor at the top. For simplicity, we only have one base type, $ \POOunit 
$. 
Other pre-types are functions, products, and sums.

$ T_1 \sim T_2 $ reads ``$ T_1 $ and $ T_2 $ are consistent''.
The intuition of $ T_1 \sim T $ is that $ T_1 $ and $ T_2 $ have no conflict 
type information. Two types are consistent if one of them is $ \star $, or they 
have the same top-most type constructor and the corresponding sub-parts are 
consistent. Consistency is reflexive and symmetric, but not transitive.

$ T_1 \smile T_2 $ reads ``$ T_1 $ and $ T_2 $ are shallowly-consistent''. Two 
types are shallowly consistent if one of them is $ \star $, or they have the 
same type constructor at the top. Shallow-inconsistency is the root of all 
blame in lazy cast strategies -- casting a value to a shallowly inconsistent 
type leads to a blame. Shallow-consistency is reflexive, symmetric, but 
not transitive.

Let $ e $ range over terms. Most terms are standard. We annotate the codomain 
of lambda abstractions explicitly because we need it when evaluating cast 
calculus with hypercoercion. We have two additional terms: cast expressions and 
blame expressions. Cast expressions insert runtime type checks. And blame 
expressions raise an error. The typing rules for the additional terms are
straightforward.

Let $ v $ range over values. A value is either the unit, a function (a 
closure), a pair, a left injection, a right injection, or a 
casted value. As shown 
by the value typing rules, if the target type of a casted value is the dynamic 
type, the underlying value must be of an injectable type. The definition of 
injectable types depends on blame strategies: for the \lazyD\ strategy, every 
pre-type is injectable; for the \lazyUD\ strategy, a pre-types is injectable if 
and only if all its sub-parts are the dynamic type. If the target type of a 
casted value is a pre-type, the type of the underlying value must have the same 
type constructor.

Let $ c $ range over casts. A cast is a triple of a type, a label, and a type.

Let $ o $ range over observations. They are what would be observed if a 
program terminates. Observations include all value constructors and blame.
The function converting values to observations ($ observe(v) = o $) is defined 
in the natural way.

\begin{figure}
	%	Continuation typing \fbox{$ \kappa : T_1 \Longrightarrow T_2 $}
	%	\begin{gather*}
	%	\dots \quad
	%	\inference{
	%		c : T_1 \Longrightarrow T_2 &
	%		\kappa : T_2 \Longrightarrow T_3
	%	}{
	%		\langle c \rangle \kappa : T_1 \Longrightarrow T_3
	%	}
	%	\end{gather*}
	
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	
	\stxrule{\kappa}{continuations}{
		\kOOmt \mid
		\kOOconsI{e}{\rho}{\kappa} \mid
		\kOOconsII{v}{\kappa} \mid
		\kOOinl{\kappa} \mid
		\kOOinr{\kappa}
	}
	\stxrulecont{
		\kOOappI{e}{\rho}{\kappa} \mid
		\kOOappII{v}{\kappa} \mid
		\kOOcar{\kappa} \mid
		\kOOcdr{\kappa} \mid
		\kOOcaseI{e_1}{e_2}{\rho}{\kappa}
	}
	\stxrulecont{	
		\kOOcaseII{v}{e}{\rho}{\kappa} \mid
		\kOOcaseIII{v_1}{v_2}{\kappa} \mid
		\kOOcast{c}{\kappa}
	}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeCreduce{s}{s} $}
	\[
	\begin{array}{rclr}
	\redrule{
		\sOOinspect{\eOOvar{x}}{\rho}{\kappa}
	}{	
		\sOOreturn{\rho[x]}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOsole}{\rho}{\kappa}
	}{
		\sOOreturn{\vOOtt}{\kappa}
	}{}
	\redrule{
		\sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\rho}{\kappa}
	}{
		\sOOreturn{(\vOOfun{\rho}{x}{e})}{\kappa}
	}{}
	\redrule{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{E}{}
	}{}
	\redrule{
		\sOOinspect{(\eOOinl{e})}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{(\kOOinl{\kappa})}
	}{}
	\redrule{
	\sOOinspect{(\eOOinr{e})}{\rho}{\kappa}
	}{
	\sOOinspect{e}{\rho}{(\kOOinr{\kappa})}
	}{}
	\redrule{
		\sOOinspect{(\eOOapp{e_1}{e_2})}{\rho}{\kappa}
	}{
\sOOinspect{e_1}{\rho}{(\kOOappI{E}{e_2}{\kappa})}}{}
\redrule{
\sOOinspect{(\eOOcar{e})}{\rho}{\kappa}}{
\sOOinspect{e}{\rho}{(\kOOcar{\kappa})}}{}
\redrule{
	\sOOinspect{(\eOOcdr{e})}{\rho}{\kappa}}{
	\sOOinspect{e}{\rho}{(\kOOcdr{\kappa})}}{}
\redrule{
\sOOinspect{(\eOOcase{e_1}{e_2}{e_3})}{\rho}{\kappa}}{
\sOOinspect{e_1}{\rho}{(\kOOcaseI{E}{e_2}{e_3}{\kappa})}}{}
	\redrule{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{\langle\cOOcast{T_1}{l}{T_2}\rangle\kappa}
	}{}

\redrule{
\sOOreturn{v_1}{(\kOOconsI{\rho}{e_2}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOconsII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOconsII{v_1}{\kappa})}}{
\sOOreturn{(\vOOcons{v_1}{v_2})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinl{\kappa})}}{
\sOOreturn{(\vOOinl{v})}{\kappa}}{}

\redrule{
\sOOreturn{v}{(\kOOinr{\kappa})}}{
\sOOreturn{(\vOOinr{v})}{\kappa}}{}

\redrule{
\sOOreturn{v_1}{(\kOOappI{\rho}{e_2}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOappII{v_1}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOappII{(\vOOfun{\rho}{x}{e})}{\kappa})}}{
\sOOinspect{e}{\rho[x:=v_2]}{\kappa}}{}
	\redrule{
		\sOOreturn{v_1}{(\mathtt{app_2} \; \vOOcast{v_2}{
				\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
			} \; \kappa)}
	}{
		\sOOreturn{v_1}{
			\langle\cOOcast{T_3}{l}{T_1}\rangle
			(\mathtt{app_2} \; v_2 \; 
			\langle\cOOcast{T_2}{l}{T_4}\rangle \kappa)}
	}{}
	\redrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{fst} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{fst} \;
			\langle \cOOcast{T_1}{l}{T_3} \rangle \kappa
			)}
	}{}
	
	\redrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{snd} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{snd} \;
			\langle \cOOcast{T_2}{l}{T_4} \rangle \kappa
			)}
	}{}

\redrule{
\sOOreturn{v_1}{(\kOOcaseI{\rho}{e_2}{e_3}{\kappa})}}{
\sOOinspect{e_2}{\rho}{(\kOOcaseII{E}{v_1}{e_3}{\kappa})}}{}

\redrule{
\sOOreturn{v_2}{(\kOOcaseII{\rho}{v_1}{e_3}{\kappa})}}{
\sOOinspect{e_3}{\rho}{
	(\kOOcaseIII{v_1}{v_2}{\kappa})
}}{}	
		\redrule{
		\sOOreturn{v_3}{(
			\mathtt{case_3} \;
			v_1 \; v_2 \;
			\kappa
			)}
	}{case(v_1,
		\mathtt{app_2} \; v_2 \; \kappa,
		\mathtt{app_2} \; v_3 \; \kappa
		)}{}
	
	\redrule{
		\sOOreturn{v}{(
			\mathtt{cast} \; c \; \kappa
			)}
	}{
		\sOOreturn{u}{\kappa}
		\\ &
	}{
		\sidecond{applyCast(c,v) = \rOOsucc{u}}
	}
	
	\redrule{
		\sOOreturn{v}{(
			\mathtt{cast} \; c \; \kappa
			)}
	}{
		\sOOhalt{(\oOOblame{l})}
		\\ &
	}{
		\sidecond{applyCast(c,v) = \rOOfail{l}}
	}
\redrule{
\sOOreturn{v}{\kOOmt}}{
\sOOhalt{observe(v)}}{}
	\end{array}
	\]	
	
	\fbox{$case(v, \kappa, \kappa) = s$}
	\[
	\begin{array}{rclr}
	\funrule{case(\vOOinl{v},\kappa_1,\kappa_2)}{
		\sOOreturn{v}{\kappa_1}
	}{}
	\funrule{case(\vOOinr{v},\kappa_1,\kappa_2)}{
		\sOOreturn{v}{\kappa_2}
	}{}
	\funrule{case(\vOOcast{v}{\cOOcast{\POOsum{T_{11}}{T_{12}}}{l}{\POOsum{T_{21}}{T_{22}}}},\kappa_1,\kappa_2)}{
		case(v,
		\langle \cOOcast{T_{11}}{l}{T_{21}} \rangle \kappa_1,
		\langle \cOOcast{T_{12}}{l}{T_{22}} \rangle \kappa_2)
	}{}
	\end{array}
	\]
		
	%	Transitive closure of reduction \fbox{$ s \longrightarrow_{D,B}^{*} s 
	%$}\\
	
	Evaluation \fbox{$\judgeCeval{e}{o}$}
	\[
	\inference{
		\sOOinspect{e}{\emptyset}{cont(\hckOOmt)} \longrightarrow_{B}^{*} 
		\sOOhalt{o}
	}{
		\judgeCeval{e}{o}
	}
	\]
	
	\caption{Dynamic semantics of the cast calculi as a CEK machine ($ 
	\mathcal{C} $)}
	\label{machine-cekc}
\end{figure}

Fig.~\ref{machine-cekc} defines the dynamic semantics of cast calculi as a 
CEK machine \citep{felleisen1986control}. CEK machines include continuation as 
part of their states. They evaluate expressions with two interleaving 
processes: 
(1) dive into an expression and extend the continuation;
(2) return a value to the current continuation.
\todo[inline]{Briefly present the main ideas regarding how a CEK
	machine works. (2-3 sentences) -JS
\\---\\Fixed -KC}

Most existing proofs about cast calculi defines the dynamic semantics with 
reduction semantics. We use a CEK machine instead because the first author is 
more familiar with CEK machines, and that he believes CEK machines are more 
convenient because space-efficiency is about compressing continuations.
\todo[inline]{Explain why you are using a CEK machine instead of
	reduction semantics. -JS
        \\---\\Fixed -KC
        \\---\\
        Change ``one of us'' to ``first author''. -JS
 		\\---\\Fixed -KC
}


\todo[inline]{Please fill in the missing reduction rules. -JS
\\---\\ Fixed -KC}
\todo[inline]{Change the order of parameters for applyCast to take
	the value first and the cast second. -JS
	\\---\\
	Could you tell me why taking the value first is better?
	I am always taking the target of induction first. -KC
	\\---\\
    It's better because it matches the postfix syntax we are using for
    casts. Currently line 2 of applyCast for D is difficult to read,
    compare it with line 4 of applyCast for UD. -JS
    \\---\\
    Does it mean changing the syntax for casts to a prefix syntax would work as 
    well? 
    If yes, I prefer this way, because of the reason in my first response 
    and that function applications (apply) also takes arguments in this order.
    I have fixed it with my idea so that we can see if it works. This change is 
    easy to undo.
    -KC
    }

Let $ r $ range over cast results. A cast result is either a success, which 
brings back a value, or a failure, which brings a blame label.

Let $ s $ range over machine states. A state is either looking at an 
expression to decide what to do next, returning a value to a continuation, or 
halting with an observation.

Let $ \kappa $ range over continuations. $ \mathtt{stop} $ is the top 
continuation. The remaining continuations correspond to expressions. For 
example, $ (\mathtt{cons_1} \; e \; \rho \; \kappa) $ is the continuation where 
we are waiting for the value of the first argument to a $ \mathtt{cons} $. And 
the last continuation, $ \langle c \rangle \kappa $ is to cast the value before 
returning to $ \kappa $.

The reduction relation $ \judgeCreduce{s}{s} $ depends on $ applyCast $, a 
function depending on blame strategies. We will give the definitions of $ 
applyCast $ shortly.
To evaluate a cast 
expression, the machine move the 
cast to the continuation and evaluate the inner expression. To apply a casted 
function, the machine firstly cast $ v_1 $, the operand, then apply the casted 
operand to $ v_2 $, the un-casted function, and finally cast the result of the 
function application. To take out the first (resp. second) part of a casted 
pair, the machine firstly take out the first (resp. second) part of $ v $, the 
un-casted pair, and cast the result. To case-split a sum, the machine looks 
deep inside the value to find out whether it is a left injection or a right 
one.
\todo[inline]{Change the rules for case to be small step, i.e.,
	the case function should not be recursive. -JS}
Along the way, the machine accumulates the pending casts onto the 
continuations. To cast a value, the machine try to apply the cast to the value. 
If the cast succeeds, the machine returns the result to the next continuation. 
If the cast fails, the machine halts with the blame label.

The reflexive transitive closure of reduction ($ \judgeCreduceTrans{s}{s} $) 
and evaluation ($ \judgeCeval{e}{o} $) are standard.

\subsection{The \lazyD{} cast calculus}
\todo[inline]{I want to merge this and the following subsetion to the 
subsection above. -KC}

\begin{figure}
	
	\fbox{$applyCast(c,v) = r$}
	\[
	\begin{array}{rclr}
	\funrule{
		applyCast(\cOOcast{\star}{l}{\star},v)
	}{
		\rOOsucc{v}
	}{}
	\funrule{
		applyCast(\cOOcast{\star}{l}{P_2},\vOOcast{v}{\cOOcast{P_1}{l'}{\star}})
	}{
		applyCast(\cOOcast{P_1}{l}{P_2},v)
	}{}
	\funrule{
		applyCast(\cOOcast{P}{l}{\star},v)
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
	}{}
	\funrule{
		applyCast(\cOOcast{P_1}{l}{P_2},v)
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
	}{\sidecond{P_1 \smile P_2}}
	\funrule{
		applyCast(\cOOcast{P_1}{l}{P_2},v)
	}{
		\rOOfail{l}
	}{\sidecond{\neg P_1 \smile P_2}}
	
	\end{array}
	\]
	\caption{Definition of $ applyCast $ for \lazyD}
	\label{fig:applyCast-D-C}
\end{figure}

\figref{fig:applyCast-D-C} defines the $ applyCast $ for \lazyD. 
We conjecture that with this $ applyCast $, the CEK machine in 
\figref{machine-cekc} would agree with the \lazyD{} cast calculus in 
\citet{siek2009exploring}. We denote this \lazyD{} machine by $ 
\mathcal{C}_{\mathtt{D}} $.

\subsection{The \lazyUD{} cast calculus [Jeremy]}

The dynamic semantics of the \lazyUD{} cast calculus, which we define here as a
CEK machine, is similar to that of the \lazyD{} cast calculus
(Fig. \ref{machine-cekc}). The only difference is in the definition of
the $\mathit{applyCast}$ function, in which a cast whose source or
target is the unknown type $\star$ is always split into two casts that
go through an injectiable type, that is, a type in which all
sub-components are the unknown type, such as $\star \to \star$. The
definition of $\mathit{applyCast}$ for the \lazyUD{} cast calculus is given in
Fig.~\ref{fig:apply-Cast-UD}.

\begin{figure}
%
%  Syntax
%  \[
%  \begin{array}{rclr}
%    \stxrule{v}{values}{
%      \cdots \mid 
%      \vOOcast{v}{ \cOOcast{I}{l}{\star} } \mid
%      \vOOcast{v}{ \cOOcast{P}{l}{P} }
%    }
%  \end{array}
%  \]
%  
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& v \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        v \langle \cOOcast{P}{l}{I} \rangle
          \langle \cOOcast{I}{l}{\star} \rangle
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        v \langle \cOOcast{\star}{l}{I} \rangle
          \langle \cOOcast{I}{l}{P} \rangle
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& v \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
     v \langle \cOOcast{P_1}{l}{P_2} \rangle & \text{if } P_1 \smile P_2
  \end{array}
  \]


  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}


% the following are temporary -JS
\clearpage
\pagebreak

\subsection{Coercions in Normal Form} 
\label{sec:coercion-calculus}

In this section we review the normal coercions \citep{siek2012interpretations} 
to motivate the design of hypercoercion. 
We ignore sum types and product types in this 
section, because they were not in the paper. We assume a basic 
familiarity with coercion, and direct readers who do not know it to 
\citet{siek2012interpretations}.
%We 
%will highlight the similarity of normal coercion and hypercoercion, and hope 
%this would convince you that hypercoercion should be as difficult to implement 
%as normal coercions.
%\todo[inline]{I don't think we should try to convince the reader that
%  hypercoercions are easier to implement. We don't have real evidence
%  for that.}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{I}{injectable types (\lazyD)}{
		\POOfun{T}{T}}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOfun{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{coercions}{
		\ncInj{I} \mid
		\ncProj{I}{l} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncSeq{c}{c} \mid
		\ncFun{c}{c}
	}
	\stxrule{\bar{c}}{wrapper coercions}{	
		\ncInj{I} \mid
		\ncFun{\hat{c}}{\hat{c}} \mid
		\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}
	}
%	\stxrulecont{
%		\ncProd{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncProd{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
%		\ncSum{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncSum{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid	
%	}
	\stxrule{\hat{c}}{normal coercions}{
		\bar{c} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncProj{I}{l} \mid
		\ncSeq{\ncProj{I}{l}}{\ncFail{l}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncInj{I}}
	}
	\stxrulecont{
		\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}}
	}
	\end{array}
	\]
	\caption{Syntax of Normal Coercion (NC)}
	\label{fig:normal-coercion}
\end{figure}

\todo[inline]{Give a summary statement about the shape of the normal form. 
-JS
\\---\\The three-part shape is not obvious before the transformation at 
the end of the next paragraph. So the summary is given after that. -KC}

\figref{fig:normal-coercion} defines the normal coercion.
Types, pre-types, and blame labels are as before.
Let $ I $ range over injectable types. An injectable type is a type that can 
be cast directly to (injection) and from (projection) $ \TOOdyn $. The 
definition of injectable type depends on blame strategy. With \lazyD, all 
pre-types are injectable. With \lazyUD, only $ \POOfun{\TOOdyn}{\TOOdyn} $ 
is injectable. 
Let $ c $ range over coercions, a coercion is either injection, projection, 
identity, failure, sequencing, or function coercion.
Let $ \bar{c} $ range over wrapper coercions, which represent casts in $ 
\vOOcast{v}{c} $.
Let $ \hat{c} $ range over normal coercions. If we inline $ \bar{c} $ and 
re-order the cases, the definition of $ \hat{c} $ becomes:
\[
\begin{array}{rclr}
\stxrule{\hat{c}}{normal coercions}{
	\ncFun{\hat{c}}{\hat{c}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
	\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
	\ncId \mid
	\ncProj{I}{l} \mid
	\ncInj{I} \mid
	\ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
	\ncFail{l} \mid
}
\end{array}
\]

Three observations on this definition leads to hypercoercion: 
\begin{enumerate}
	\item The length of normal coercion is at most three.
	\item Projections are always at the beginning when present.
	\item Injections and failures are always at the end when present.
\end{enumerate}


\section{hypercoercion} \label{sec:hypercoercion}

\begin{figure}
	Syntax
	\[
	\begin{array}{lclr}
	\stxrule{I}{injectable types (\lazyD)}{P}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\TOOdyn}{\TOOdyn} \mid
		\POOprod{\TOOdyn}{\TOOdyn} \mid
		\POOsum{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{hypercoercions}{
		\hyperCoercionI \mid{}
		\hyperCoercionC{h}{m}{t}
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{m}{middles}{
		\POOunit \mid
		\POOfun{c_1}{c_2} \mid
		\POOprod{c_1}{c_2} \mid
		\POOsum{c_1}{c_2}
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
		
	hypercoercion typing \fbox{$ c : T \Longrightarrow T $}
	\begin{gather*}
	\inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
	\quad
	\inference{
		\typingHC{h}{T_1}{P_1} &
		\typingHC{m}{P_1}{P_2} &
		\typingHC{t}{P_2}{T_2}
	}{
		\typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
	}
	\end{gather*}
	
	Head typing \fbox{$ \typingHC{h}{T}{P} $}
	\begin{gather*}
	\inference{}{\typingHC{\epsilon}{P}{P}}
	\quad
	\inference{}{\typingHC{?^l}{\TOOdyn}{I}}
	\end{gather*}
	
	Middle typing \fbox{$ \typingHC{m}{T}{T} $}
	\begin{gather*}
	\inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
	\quad
	\inference{
		\typingHC{c_1}{T_3}{T_1} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
	}
	\\
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
	}
	\quad
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
	}
		\end{gather*}
		
		Tail typing \fbox{$ \typingHC{t}{P}{T} $}
		\begin{gather*}
		\inference{}{\typingHC{\epsilon}{P}{P}} \quad
		\inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
		\inference{}{\typingHC{\bot^l}{P}{T}} \quad
		\end{gather*}
	
	\caption{Definition of hypercoercion (HC)}
	\label{fig:hypercoercion}
\end{figure}

\todo[inline]{What is the main idea behind the organization of
 hypercoercions?}

This section presents our first contribution, hypercoercion (HC). 
\figref{fig:hypercoercion} defines the syntax of HC.
Types, pre-types, and blame labels are as before.

Let $ c $ range over hypercoercions. A hypercoercion is either 
an identity cast between the dynamic types, or a complex including a head, a 
middle, and a tail. 
Let $ h $ range over heads. A head is either a no-op, or a projection.
Let $ m $ range over middles. There is a one-to-one 
correspondence between middles and type constructors. 
We generalize shallow-consistency to middles $ m \smile m $ in the natural way.
Let $ t $ range over tails. A tail is either a no-op, an injection, or a 
failure. 
Let $ \ell $ range over no-op and labels. It is useful when we introduce 
composition of hypercoercions.

\subsection{\lazyD{} hypercoercion}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{\ell}{Maybe $ l $}{\epsilon \mid l}
	\end{array}
	\]
	
	Composition of hypercoercions \fbox{$ c \fatsemi^\ell c = c $}
	\[ 
	\begin{array}{rclclr}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{\epsilon}{m}{t}
	}{
		\hyperCoercionC{?^{l}}{m}{t}
	}{\sidecond{\ell = l}}
	
	\comprule{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{
		c
	}{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{t}
	}{
		\hyperCoercionI
	}{
		\hyperCoercionC{h}{m}{!}
	}{
		\sidecond{\forall l. t \neq \bot^{l}}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{\epsilon}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			m_1 \fatsemi^{\ell} (m_2, t_2) = (m', t')
			 \; \text{and} \;
			 \forall l. t \neq \bot^{l}
		}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{?^{l'}}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			m_1 \fatsemi^{l'} (m_2, t_2) = (m', t')
			\; \text{and} \;
			\forall l. t \neq \bot^{l} 
		}
	}
	\end{array}
	\]
	
	Composition of middles \fbox{$ m \fatsemi^\ell (m,t) = (m,t) $}
	\[ 
	\begin{array}{rclclr}
	\comprule{\POOunit}{(\POOunit,t)}{
		(\POOunit,t)
	}{}
	\comprule{\POOfun{c_1}{c_2}}{(\POOfun{c_3}{c_4},t)}{
		(\POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOprod{c_1}{c_2}}{(\POOprod{c_3}{c_4},t)}{
		(\POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOsum{c_1}{c_2}}{(\POOsum{c_3}{c_4},t)}{
		(\POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{m_1}{(m_2,t)}{
		(m_1,\bot^l)
	}{
		\sidecond{
			\ell = l \; \text{and} \;
			\neg m_1 \smile m_2 
		}
	}
	\end{array}
	\]
	
	\fbox{$ seq(c,c) = c $}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^\epsilon c_2
	}{}
	\end{array}
	\]
	
	\fbox{$ id( P ) = m $}
	\[
	\begin{array}{rclr}
	\funrule{id(\POOunit)}{\POOunit}{}
	\funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
	}{}
	\end{array}
	\]
	
	\fbox{$ id( T ) = c $}
	\[
	\begin{array}{rclr}
	\funrule{id(\star)}{
		\hyperCoercionI
	}{}
	\funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
	}{}
	\end{array}
	\]
	
	\fbox{$ cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	\caption{\lazyD{} hypercoercion}
	\label{fig:HC-D}
\end{figure}

\figref{fig:HC-D} defines the constructors of \lazyD{} HC.

\todoKC{check consistency before using middle composition.}
$ c_1 \fatsemi^\ell c_2 = c' $ composes two hypercoercions. The target of $ 
c_1 $ and the source of $ c_2 $ might be different, in which case $ \ell $ must 
be a label.
$ m_1 \fatsemi^\ell (m_2,t) = (m',t') $ composes a middle with a 
pair of a middle and a tail. Similarly, the target of $ m_1 $ and the source of 
$ m_2 $ might be different, in which case $ \ell $ must be a label.
$ seq(c_1,c_2) $ composes two coercions where the target type of $ c_1 $ is 
equal to the source type of $ T_2 $.
$ id(T) $ constructs an identity coercion of $ T $ with the help of $ id(P) $.
$ cast(T_1,l,T_2) $ constructs a coercion from a source type, a label, and a 
target type. 

\begin{proposition}[\lazyD\ hypercoercion is a monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}

The correctness proof of \lazyD\ HC is deferred to \secref{sec:LDHC-correct} 
because it relies on the space-efficient CEK abstract machine in 
\secref{sec:CEKS}.

\subsection{\lazyUD{} hypercoercion [Jeremy]}


Figure~\ref{fig:HC-UD}

\begin{figure}
  Composition of hypercoercions \fbox{$ c \fatsemi c = c $}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
       \hyperCoercionC{p_2}{m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{\epsilon} &\fatsemi& \hyperCoercionC{\epsilon}{m_2}{i_2} &=&
       \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{i_2} &=&
  \begin{cases}
    \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{p_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{p_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
     \hyperCoercionC{p_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$ id( P ) = m $}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$ id( T ) = c $}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
		\hyperCoercionI
    }{}
    \funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]

  
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}


Figure~\ref{fig:HC-UD-cast}


\begin{figure}
  \fbox{$ \mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$ \mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$ \mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$ \mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$ cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxilliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\begin{proposition}[\lazyUD\ hypercoercions form a monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}


\section{Space-efficient CEK Abstract Machine}
\label{sec:CEKS}

This section presents our second contribution, a space-efficient CEK abstract 
machine. This machine is parameterized over \emph{cast representation}. 

\begin{definition}[Cast Representation]
	A cast representation is a set indexed by two types and has four interface 
	functions:
	\begin{description}
		\item[$ id(T) $] constructs an identity cast
		\item[$ seq(c_1,c_2) $] composes two casts
		\item[$ cast(T_1,l,T_2) $] constructs a cast from $ T_1 $ to $ T_2 $
		\item[$ applyCast(c,v) $] applies a cast onto a value
	\end{description}
\end{definition}

\begin{definition}[Monoidic Cast Representation]
	A cast representation is monoidic if 
	for all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{definition}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	
	\stxrule{v}{values}{
		\hcvOOtt \mid
		\hcvOOfun{c}{\rho}{x}{e}{c} \mid
		\hcvOOcons{v}{c}{v}{c}
	}
	\stxrulecont{
		\hcvOOinl{v}{c} \mid
		\hcvOOinr{v}{c} \mid
		\hcvOOinj{P}{v}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuation}{
		\langle c \rangle k
	}
	\stxrule{k}{pre-continuations}{
		\hckOOmt \mid{}
		\mathtt{cons_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{cons_2} \; v \; \kappa \mid{}
		\mathtt{inl} \; \kappa \mid{}
		\mathtt{inr} \; \kappa
	}
	\stxrulecont{
		\mathtt{app_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{app_2} \; v \; \kappa \mid{}
		\mathtt{fst} \; \kappa \mid{}
		\mathtt{snd} \; \kappa
	}
	\stxrulecont{
		\mathtt{case_1} \; e \; e \; \rho \; \kappa \mid
		\mathtt{case_2} \; v \; e \; \rho \; \kappa \mid{}
		\mathtt{case_3} \; v \; v \; \rho \; \kappa
	}
	\end{array}
	\]
	
	Build continuation \fbox{$ cont(k) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{cont(k)}{\langle id(T_1) \rangle k}{
		\sidecond{k : T_1 \Longrightarrow T_2}}
	\end{array}
	\]
	
	Extend continuation \fbox{$ ext(c,\kappa) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{ext(c_1,\langle c_2 \rangle k)}{\langle seq(c_1,c_2) \rangle k}{}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeSreduce{C}{s}{s} $}
	\[
	\begin{array}{rclr}
	& \vdots \\
	\redruleS{
		\sOOinspect{(\eOOlam{T_1}{T_2}{x}{e})}{\rho}{\kappa}
	}{
		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
	}{}
	\redruleS{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{cont(\hckOOconsI{e_2}{\rho}{\kappa})}
	}{}
	\redruleS{
		\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
	}{
		\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)}
	}{
		\\ & &
		\sidecond{applyCast(c_1,v) = \rOOsucc{v'}}
	}
	\redruleS{
		\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
	}{
		\sOOhalt{(\oOOblame{l})}
	}{
		\\ & &
		\sidecond{applyCast(c_1,v) = \rOOfail{l}}
	}
	\end{array}
	\]
	
%	Transitive closure of reduction \fbox{$ s \longrightarrow_{S(C)}^{*} s $}
%	\[\dots\]
	
	Evaluation \fbox{$ \judgeSeval{C}{e}{o} $}
	\[
	\inference{
		\judgeSreduceTrans{C}{
			\sOOinspect{e}{\emptyset}{cont(\hckOOmt)}
		}{
			\sOOhalt{o}
		}		
	}{
		\judgeSeval{C}{e}{o}
	}
	\]
	
	\caption{Space-efficient CEK machine $ \mathcal{S}(C) $}
	\label{machine-cekcc}
\end{figure}

\figref{machine-cekcc} defines the machine. 
Let $ v $ range over value. A value is either the unit value, function, pair, 
left injection of sum, right injection of sum, and injection to $ \TOOdyn $.
Cast results ($ r $) and machine states ($ s $) are as before. 
Let $ \kappa $ range over continuations and let $ k $ range over 
pre-continuations. 
A continuation is now a pair where the first part is a cast and the second 
part is a pre-continuation. 
Pre-continuation are like the continuations before.

We list a fraction of reduction rules due to space limitation.
When values are constructed, their hypercoercion parts are filled with outputs 
of $ id $. For instance, when a function value is constructed, its first part 
and last part are initialized to $ id(T_1) $ and $ id(T_2) $ respectively.
When evaluating a cast expression, the current continuation is extended with a 
hypercoercion constructed by $ cast $. $ ext $ composes the new hypercoercion 
with the hypercoercion on the top of the continuation.
When evaluating a compound expression, the machine firstly construct the new 
pre-continuation, then turn it to a continuation by adding an identity 
hypercoercion at the top. For instance, when evaluating a \texttt{cons} 
expression, the machine firstly construct $ \hckOOconsI{e_2}{\rho}{\kappa} $, 
the new pre-continuation, then call $ cont $, which adds an identity cast to 
form a continuation. 
When a function call happens, the machine firstly cast the operand. If the 
casting succeeds, the machine then evaluate the body in the extended 
environment and the extended continuation. If the casting fails, the machine 
then halts with the blame label.

Transitive closure of reduction ($ \judgeSreduceTrans{C}{s}{s} $) and 
evaluation are standard. Value typing ($ \judgeType{v}{T} $) is straightforward.


\section{Correctness Proof of \lazyD{} hypercoercions}

\todo[inline]{Give a high-level summary of the proof.
  The summary should be enough so that the reader knows a bit
  about why you introduce the various definitions below. -JS}

\subsection{\lazyD\ Cast Representations}

In this section we describe a subset of cast representations, where all 
elements implement the \lazyD{} blame strategy. We will show in 
Subsection~\ref{sec:LDHC-correct} that the \lazyD\ HC is in this subset.

\begin{definition}[Surely \lazyD\ Cast Representation]
	A cast representation is surely \lazyD\ if
	\begin{enumerate}
		\item If $ v : T $, then $ applyCast(id(T), v) = \mathtt{succ} \; v $
		\item If $ \judgeType{v}{T_1} $,
				 $ \judgeTypeFT{c_1}{T_1}{T_2} $, and
				 $ \judgeTypeFT{c_2}{T_2}{T_3} $,\\
		then $ applyCast(seq(c_1,c_2),v) = 
			   applyCast(c_1,v) >>= \lambda v.applyCast(c_2,v) $ \\
		where 
		\[
		\begin{array}{rcl}
			\rOOsucc{v} >>= f & = & f(v) \\
			\rOOfail{l} >>= f & = & \rOOfail{l}
		\end{array}
		\]
		\item If $ v : T_1 $ and $ \neg T_1 \smile T_2 $,
		then $ applyCast(cast(T_1, l, T_2),v) = \rOOfail{l} $
		\item If $ v : \star $, 
		then $ applyCast(cast(\TOOdyn,l,\TOOdyn),v) = \rOOsucc{v} $
		\item If $ v : P $,
		then $ applyCast(cast(\star,l,Q),\hcvOOinj{P}{v}) 
		= applyCast(cast(P,l,Q),v) $
		\item If $ v : P $,
		then $ applyCast(cast(P,l,\star),v) = \rOOsucc{(\hcvOOinj{P}{v})} $
		\item If $ v : \POOunit $,
		then $ applyCast(cast(\POOunit,l,\POOunit),v) = \rOOsucc{v} $
		\item
		$ 
		applyCast(cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4}) ,
		\hcvOOfun{c_1}{\rho}{x}{b}{c_2}) \\
		= 
		\rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\rho}{x}{b}{seq(c_2,cast(T_2,l,T_4))})}$
		
		\item $ applyCast(cast(\POOprod{T_1}{T_2},l,T_3 \times 
		T_4),\hcvOOcons{v_1}{c_1}{v_2}{c_2}) $ \\
		$ = 
		\rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
		$ 
		\item $ 
		applyCast(cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}),\hcvOOinl{v}{c})
		= \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_2))})} $
		\item $ 
		applyCast(cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}),\hcvOOinr{v}{c})
		= \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_3,l,T_4))})} $
	\end{enumerate}
\end{definition}

\subsection{All Surely \lazyD{} and Monoidic Cast Representations Respect 
$\mathcal{D}$}

\todo[inline]{``monoidic'' is not a word. -JS}

We use bisimulation to proof equivalence between the two machines.
\todo[inline]{Which two machines? -JS}
The bisimulation relation of states ($\eqvDS{C}{s}{s}$) is mostly derived from 
the definitions of $ \mathcal{D} $. Exceptions include the relations from 
continuations to pre-continuations, between continuations, and between values. 
We omit subscripts when there is no ambiguity.

\todoKC{write down the exceptional bisimilarity relations}


\begin{lemma}[Weak Bisimulation between $ \mathcal{S}(\cdot) $ and $ 
	\mathcal{D} $]
	\label{thm:surely-monoidic-reduce}
	For all cast representations $ C $, 
	if $ C $ is surely \lazyD{} and monoidic,
	$ s_1 \in \mathcal{D} $,
	$ s_2 \in \mathcal{S}(C) $, and
	$ s_1 \approx s_2 $, 
	\begin{enumerate}
		\item If $ \judgeCreduce{s_1}{s_3} $,
		then
		there exist $ s_5 \in \mathcal{D} $, $ s_4 \in \mathcal{S}(C) $,
		such that \begin{itemize}
			\item $ s_5 \approx s_4 $, and
			\item $ \judgeSreduce{C}{s_2}{s_4} $,
			\item $ \judgeCreduceTrans{s_3}{s_5} $
		\end{itemize}
		\item If $ \judgeSreduce{C}{s_2}{s_4} $,
		then
		there exist $ s_3 \in \mathcal{D} $,
		such that \begin{itemize}
			\item $ s_3 \approx s_4 $
			\item $ \judgeCreduceTrans{s_1}{s_3} $
		\end{itemize}
	\end{enumerate}
\end{lemma}
\begin{proof}
	See the supplementary material.
\end{proof}

\begin{lemma}[Surely \lazyD\ and Monoidic Cast Representations Respect 
	$ \mathcal{D} $]
	\label{thm:surely-monoidic-eval}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is surely 
	\lazyD{} and monoidic,
	\[
	\judgeCeval{e}{o} \; \text{if and only if} \; 
	\judgeSeval{C}{e}{o}
	\]
\end{lemma}
\begin{proof}
  Immediately from Lemma~\ref{thm:surely-monoidic-reduce}.
  \todo[inline]{I'm guessing that you prove this lemma by induction,
    using Lemma~\ref{thm:surely-monoidic-reduce}.
    Proofs by induction are not ``immediate''. -JS}
\end{proof}

\subsection{\lazyD\ Hyper-coercion Respect $ \mathcal{D} $}
\label{sec:LDHC-correct}

\figref{hc-applyCast} defines $ applyCast $, the last interface function.
We generalize shallow-consistency to middles and values ($ m \smile v $) in the 
natural way.
Applying the identity cast for the 
dynamic type succeeds immediately. When applying a compound cast, we firstly 
apply the middle, then apply the tail. We denote by $ r \; >>= \; f $ to mean 
that if $ r $ is $ \rOOsucc{v} $, the result is $ f(v) $, otherwise the result 
is the failure.
$ applyMiddle(\ell,m,v) $ and $ applyTail(t,v) $ are straightforward.

\begin{figure}
	\fbox{$ applyCast(c,v) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyCast(\hyperCoercionI,\;v)}{\rOOsucc{v}}{}
	\funrule{applyCast(\hyperCoercionC{?^l}{m}{t},\;\hcvOOinj{P}{v})}{
		applyMiddle(l,m,v) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\funrule{applyCast(\hyperCoercionC{\epsilon}{m}{t},\;v)}{
		applyMiddle(\epsilon,m,v) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\end{array}
	\]
	
	\fbox{$ applyMiddle(\ell,m,v) = v $}
	\[
	\begin{array}{rclr}
	\funrule{applyMiddle(\ell,\POOunit,\hcvOOtt)}{\hcvOOtt}{}
	\funrule{applyMiddle(\ell,\POOfun{c_3}{c_4},\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{
		\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\rho}{x}{e}{(c_2 \fatsemi^\ell c_4)}
	}{}
	\funrule{applyMiddle(\ell,\POOprod{c_3}{c_4},\hcvOOcons{v_1}{c_1}{v_2}{c_2})}{
		\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 \fatsemi^\ell c_4)}
	}{}
	\funrule{applyMiddle(\ell,\POOsum{c_3}{c_4},\hcvOOinl{v}{c_1})}{
		\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)}
	}{}
	\funrule{applyMiddle(\ell,\POOsum{c_3}{c_4},\hcvOOinr{v}{c_2})}{
		\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)}
	}{}
	\funrule{applyMiddle(\ell,m,v)}{
		\rOOfail{l}
	}{
		\sidecond{\ell = l \; \text{and} \; \neg m \smile v}
	}
	\end{array}
	\]
	
	\fbox{$ applyTail(t,v) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyTail(\bot^l,v)}{\rOOfail{l}}{}
	\funrule{applyTail(\epsilon,v)}{\rOOsucc{v}}{}
	\funrule{applyTail(!,v)}{\rOOsucc{(\hcvOOinj{P}{v})}}{v : P}
	\end{array}
	\]
	\caption{\lazyD\ hypercoercion's $ applyCast $}
	\label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} hypercoercion is Surely \lazyD]
	\label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof}
	See the supplementary material.
\end{proof}

\begin{theorem}[\lazyD{} hypercoercion Respect $ \mathcal{D} $]
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ 
	\[
	\judgeCeval{e}{o} \; \text{if and only if} \; 
	\judgeSeval{H}{e}{o}
	\]
\end{theorem}
\begin{proof}
	Immediately from Lemma~\ref{thm:surely-monoidic-eval},
	Lemma~\ref{thm:hc-surely-lazyD}, and 
	Proposition~\ref{thm:hc-monoid}.
\end{proof}

\subsection{Extra Theorems}

In these section we show some extra theorems that might be useful in proving 
the correctness of other cast representations.

With the properties of surely \lazyD{} cast representation, it is 
straightforward to proof that 
all machines instantiated with these cast representations bisimulate each 
other. 
The bisimulation relation of states ($\eqvS{C}{C}{s}{s}$) is 
derived from the definition of states.
\todo[inline]{The term ``bisimilarity'' has a different technical meaning from
	``bisimulation relation''. I don't think you are using it properly
	in the above sentence. -JS
\\---\\
Fixed.
I learn that $ s_1 \sim s_1 $ reads ``$ s_1 $ is bisimilar to $ s_2 $'' from 
wikipedia. (https://en.wikipedia.org/wiki/Bisimulation).
-KC}
We omit subscripts when there is no 
ambiguity. \begin{gather*}
\inference{
	\rho_1 \approx \rho_2 &
	\kappa_1 \approx \kappa_2
}{
	\sOOinspect{e}{\rho_1}{\kappa_1} \approx \sOOinspect{e}{\rho_2}{\kappa_2}
}
\quad
\inference{
	\kappa_1 \approx \kappa_2 &
	v_1 \approx v_2
}{
	\sOOreturn{v_1}{\kappa_1} \approx \sOOreturn{v_2}{\kappa_2}
}
\quad
\inference{
}{
	\sOOhalt{o} \approx \sOOhalt{o}
}
\end{gather*}

The relations between continuations, pre-continuations, enviroments, values, 
cast results are also derived from their definitions. But the relation for 
casts is special: \begin{gather*}
\inference{
}{
	cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
	id_1(T) \approx id_2(T)
}
\quad
\inference{
	c_1 \approx c_2 &
	c_3 \approx c_4
}{
	seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\begin{lemma}[Strong Bi-simulation among $ \mathcal{S}(\cdot) $]
	\label{thm:CEKS-bisim}
	If 
	$ C_1 $ and $ C_2 $ are surely \lazyD,
	$ s_1, s_2 \in S(C_1) $ and $ s_3 \in S(C_2) $,
	$ s_1 \approx s_3 $,
	$ \judgeSreduce{C_1}{s_1}{s_2} $,
	then there exists an $ s_4 $ such that
	\begin{itemize}
	\item $ s_2 \approx s_4 $ and
	\item $ s_3 \longrightarrow_{S(C_2)} s_4 $
	\end{itemize}
\end{lemma}
\begin{proof}
	The key ideas of this proof are undoing sequencing with the property (2) of 
	surely \lazyD{} cast representation, and handling all possibly uses of $ 
	cast(T,l,T) $ with property (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of Surely \lazyD{} Cast Representations]
	\label{thm:surely-lazyD-eqv}
	If $ \judgetype{\emptyset}{e}{T} $, $ o : T $, and $ C_1 $ and $ C_2 $ 
	are surely \lazyD\ cast representations,
	\[
	e \Downarrow_{S(C_1)} o \; \text{if and only if} \; 
	e \Downarrow_{S(C_2)} o
	\]
\end{proposition}
\begin{proof}
	Immediately from Lemma~\ref{thm:CEKS-bisim}.
\end{proof}

\begin{theorem}[Surely \lazyD\ Cast Representations Respect 
	$ \mathcal{D} $]
	\label{thm:surely-lazyD-correct}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is surely 
	\lazyD{}
	\[
	\judgeCeval{e}{o} \; \text{if and only if} \; 
	\judgeSeval{C}{e}{o}
	\]
\end{theorem}
\begin{proof}
	Immediately from Lemma~\ref{thm:surely-monoidic-eval} and 
	Proposition~\ref{thm:surely-lazyD-eqv}.
\end{proof}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots


\end{document}
