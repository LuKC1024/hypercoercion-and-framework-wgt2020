%% For double-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxrule}[3]{#1 & ::= & #3 & \text{#2}\\}
\newcommand{\stxrulecont}[1]{& | & #1 & \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{$\mathtt{Lazy UD}$}
\newcommand{\lazyD}{$\mathtt{Lazy D}$}
\newcommand{\eager}{$\mathtt{Eager}$}
\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}
\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{#1 \; #2}
\newcommand{\eOOcons}[2]{\mathtt{cons} \; #1 \; #2}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
\newcommand{\eOOinl}[1]{\mathtt{inl} \; #1}
\newcommand{\eOOinr}[1]{\mathtt{inr} \; #1}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{#1 \langle \cOOcast{#2}{#3}{#4} \rangle}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\oOOinj}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\cOOcast}[3]{#1 \overset{#2}{\Rightarrow} #3}
\newcommand{\vOOcast}[2]{#1\langle#2\rangle}
\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}
\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{inj} \; #2}
\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D blame calculus on space-inefficient CEK
\newcommand{\judgeDBreduce}[2]{#1 \longrightarrow_{\mathcal{D}} #2}
\newcommand{\judgeDBreduceTrans}[2]{#1 \longrightarrow_{\mathcal{D}}^{*} #2}
\newcommand{\judgeDBeval}[2]{#1 \Downarrow_{\mathcal{D}} #2}
\newcommand{\redrule}[3]{#1 & \longrightarrow_\mathcal{D} & #2 & #3\\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longrightarrow_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longrightarrow_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{#2 \Downarrow_{\mathcal{S}(#1)} #3}
\newcommand{\redruleS}[3]{#1 & \longrightarrow_{\mathcal{S}(C)} & #2 & #3\\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hyper-coercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvDS}[3]{#2 \approx_{\mathcal{DS}} #3}

\begin{document}

%% Title information
\title{Blame and Coercion: Together Again for the Second Time}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  \todo[inline]{Rewrite this abstract based on the comparision table. -Jeremy}
  Gradual Typing is great. Implementing gradually typed with blame
  tracking and space efficiency is tricky. There exist two technique
  to do this: coercion and threesome. Coercion is easy to understand,
  and easy enough to implement, but difficult to reason about
  formally. Threesome is hard to understand, easy to implement, and
  easy to reason about formally. We propose hyper-coercion, which is
  easy to understand, as easy to implement as coercion, and easy to
  reason about formally.
  \todo[inline]{Spell it ``hypercoercion'' without the hyphen. -Jeremy}
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\listoftodos{}


\section{Introduction}

Around 2006, many work on integrating dynamic typing and static typing emerge, 
notably gradual types \cite{siek2006gradual} and hybrid types 
\cite{flanagan2006hybrid}. 
Later \citet{wadler2009well} introduces Blame Calculus, an intermediate 
language for gradual types and hybrid types. 
Blame Calculus throws a blame label when a runtime type-check fails.
Labels provide useful debugging information, therefore are necessary for 
practical use of gradually typed languages.

Implementing gradually typed languages naively on top of blame calculus, 
however, suffices sever space leak.
For example, translation to Blame Calculus can wrap some expressions with code 
that performs runtime type-checking (casts), including those expressions at 
tail position. Thus, mutually tail-recursive functions in source language can 
consume unbounded space at runtime. There are more examples of space leaking in 
\citet{herman2010space}.

In 2007, \citet{herman2010space} proposes a solution to this problem by 
representing casts with coercion \cite{henglein1994dynamic}, 
which can be composed and normalized. Every coercion looks like a list of 
trees. For normal coercion, the length of the list is bounded by a small 
constant. And the depths of trees do not grow during composition and
normalization. These two facts implies that coercion is a space-efficient cast 
representation. This coercion, however, does not support blame 
tracking. 

After that, many efforts have been made to combine blame tracking and 
space efficiency. 

%\subsection{coercion-based approach and blame strategies}

\citet{siek2009exploring} decorate \citet{herman2010space}'s coercions with 
labels to restore 
blame-tracking. They also propose that there are four blame 
strategies for their coercion:
$ \{Lazy, Eager\} \times \{D, UD\} $. 
Eager strategies detect more potential type errors, 
but blame more programs.
$ D $ and $ UD $ assign blame labels differently.
They prove partially that their \lazyUD{} coercion is correct by showing 
that it simulates the Blame Calculus in \cite{wadler2009well}. It is unknown, 
however, whether the simulation also works in the other direction.

\citet{siek2010threesomes} proposes another approach to combine blame 
tracking and space efficiency. Their solution represents casts with threesomes, 
a novel cast representation.
They show that their calculus bisimulates the \lazyUD{} coercion 
calculus in \citet{siek2009exploring} and the Blame Calculus in 
\citet{wadler2009well}. They also prove that threesome is space-efficient as 
well.

\citet{siek2012interpretations} present the first \lazyD{} Blame Calculus and 
revised coercion calculi.
They simplify the coercion calculi by only 
working with normal coercions (i.e. coercions in normal form). 
They conjecture that their revised coercion calculi bi-simulate the 
corresponding Blame Calculi.

Following \citet{siek2010threesomes}, \citet{garcia2013calculating} develops
threesome for other blame strategies. After studying in depth the relation 
between coercion and threesome,
he claims that normal coercion with labels is easy to understand but hard to 
implement and hard to reason about, and that 
threesome with labels, however, is easy to implement and easy to reason about 
but hard to understand. 
His claim is mostly affirmed by the group of people who develop threesome 
(\citet{siek2015blame}).
His threesome calculi are equivalent to the coercion calculi in 
\citet{siek2009exploring} because the former ones are derived from the latter 
ones.

\citet{siek2015blame} revisit the coercion-based approach. They revise the 
\lazyUD{} coercion in \citet{siek2012interpretations} and prove that 
their revised coercion calculus bi-simulates the \lazyUD{} Blame Calculus.

Last year, \citet{kuhlenschmidt2018efficient} present Grift, a compiler for a 
gradually typed language of the same name. 
This implementation is based on the \lazyD{} coercion in 
\citet{siek2012interpretations}.
Their result suggests that normal coercion is easy enough to implement in a 
compiler. 

Recently, \citet{new2019gradual} show that \eager{} strategies are 
incompatible with $\eta$-equivalence of functions, which suggest that these 
strategies are not very ideal. 

So far, it seems that normal coercion is the best way to combine 
space-efficiency and blame-tracking: normal coercion is claimed easy to 
understand \cite{garcia2013calculating}\cite{siek2015blame} and is shown 
easy enough to implement in a compiler \cite{kuhlenschmidt2018efficient}.
Normal coercion is still not satisfactory, however, in at least two aspects.
Firstly, as we mentioned above, it is hard to reason about normal coercion. The 
major difficulty is from its non-structurally recursive composition.
For instance, many developers of Grift report it is tricky to convince
their proof assistants that the composition terminates. 
Secondly, the definition of normal coercion lies unnecessarily on top 
of coercion: all coercions are normal when they are initially constructed, and 
\citet{siek2012interpretations} have shown an function that 
composes and produces normal coercions.

Perhaps unsurprisingly, threesome has a structurally recursive compose and a 
self-standing definition. Together with \citet{garcia2013calculating}'s 
work, they suggest that there might be a cast representation whose definition 
is self-standing, and whose composition is structurally recursive. 
Super-coercion introduced in \citet{garcia2013calculating} could be a promising 
candidate. It is believed even more complicated than threesome 
\cite{siek2015blame}. In fact, it uses 10 constructors to deal with an 
elementary type system with only base types and 
function types. And four constructors are directly related to function types. 
Thus, super-coercion might not scale very well to more sophisticated type 
systems. 

We present hyper-coercion, a cast representation whose composition is 
structurally recursive, and whose definition is self-standing. What's more, it 
should be at 
least as easy to implement and understand as normal coercions, because there is 
a clear connection between them, as we will show in Section 
\ref{sec:hyper-coercion}.
Our hyper-coercion considers sum types and product types, which are not 
considered in all proofs above. Adding each of them requires us to add only one 
new constructor to a component of hyper-coercion. This suggests that 
hyper-coercion might scale better than super-coercion.

We prove formally that the \lazyD{} (resp. \lazyUD{}) hyper-coercion calculus 
bi-simulates the \lazyD{} (resp. \lazyUD{}) Blame Calculus. This is 
the first bi-simulation proof for the \lazyD{} Blame Calculus as far as we know.

The structure of this paper is as follows. 
Section \ref{sec:blame-calculus} reviews the state-of-art of $Lazy$ Blame 
Calculi. 
Section \ref{sec:coercion-calculus} reviews the state-of-art of $Lazy$ Coercion 
Calculi. 
In section \ref{sec:hyper-coercion} we present Hyper-coercion.
Section \ref{sec:conclude} concludes.

\section{Background: Blame Calculus} \label{sec:blame-calculus}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	\stxrule{T}{types}{
		\star \mid{}
		P
	}
	\stxrule{P}{pre-types}{
		\POOunit \mid
		\POOfun{T_1}{T_2} \mid
		\POOprod{T_1}{T_2} \mid
		\POOsum{T_1}{T_2}
	}
	\stxrule{e}{terms}{
		\eOOvar{x} \mid{}
		\eOOsole{} \mid{}
		\eOOlam{T_1}{T_2}{x}{e} \mid
		\eOOapp{e_1}{e_2}
	}
	\stxrulecont{
		\eOOcons{e_1}{e_2} \mid
		\eOOcar{e} \mid
		\eOOcdr{e}
	}
	\stxrulecont{
		\eOOinl{e} \mid
		\eOOinr{e} \mid
		\eOOcase{e_1}{e_2}{e_3}
	}
	\stxrulecont{
		\eOOcast{e}{T_1}{l}{T_2} \mid
		\eOOblame{l}
	}
	\stxrule{o}{observations}{
		\oOOinj \mid
		\oOOsole \mid
		\oOOfun \mid
		\oOOcons \mid
		\oOOinl \mid
		\oOOinr \mid
		\oOOblame{l}
	}
	\end{array}
	\]
	
	Consistency
	\fbox{$ T_1 \sim T_2 $}
	\begin{gather*}
	\inference{}{
		\star \sim \star
	} \quad
	\inference{}{
		\star \sim P
	} \quad
	\inference{}{
		P \sim \star
	} \\
	\inference{}{
		\iota \sim \iota
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \times T_1 \sim S_2 \times T_2
	} \quad
	\inference{
		S_1 \sim S_2 &
		T_1 \sim T_2
	}{
		S_1 \plus T_1 \sim S_2 \plus T_2
	}
	\end{gather*}
	
	Shallow-consistency
	\fbox{$ T_1 \smile T_2 $}
	\begin{gather*}
	\inference{}{
		\star \smile \star
	} \quad
	\inference{}{
		\star \smile P
	} \quad
	\inference{}{
		P \smile \star
	} \\
	\inference{}{
		\iota \smile \iota
	} \quad
	\inference{}{
		T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
	} \quad
	\inference{}{
		T_{11} \times T_{12} \smile T_{21} \times T_{22}
	} \quad
	\inference{}{
	T_{11} \plus T_1 \smile S_2 \plus T_2
	}
	\end{gather*}
	
	Term typing
	\fbox{$ \judgetype{\Gamma}{e}{T} $}
	\begin{gather*}
		\inference{
			S \sim T & \Gamma \vdash e : S 
		}{
			\judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
		} \quad
		\inference{
		}{
			\judgetype{\Gamma}{\eOOblame{l}}{T}
		}
	\end{gather*}
	
	\caption{Blame Calculus and its static semantics}
	\label{fig:blame-static}
\end{figure}

\figref{fig:blame-static} defines the syntax of blame calculus and its static 
semantics. It is little changed from previous definitions.
\todo[inline]{Which previous definitions are you refering to?
  What are the little changes? -Jeremy}
\todo[inline]{The term typing rule for casts is broken. -Jeremy}
The dynamic semantics of Blame Calculi depend on blame strategies, so we defer 
them to sub-sections.

Blame Calculus is based on Simply Typed Lambda Calculus with sum types and 
product types ($ \mathtt{STLC+} $). 
Let $ S,T $ range over types. A type is either the dynamic type $ \star $
(a.k.a. $ \mathtt{Dyn} $, $ \mathbb{?} $, or $ \mathtt{Unknown} $), 
or a pre-type. 
Let $ P,Q $ range over pre-types. Every pre-type is a type with a type 
constructor at the top. For simplicity, we only have one base type, $ \POOunit 
$. 
Other pre-types are functions, products, and sums.

%$ S \sim T $ reads ``$ S $ and $ T $ are consistent''.
%Two types are consistent if one of them is $ \star $, or they have the same 
%top-most type constructor and the corresponding sub-parts are consistent. 
%The intuition of $ S \sim T $ is that $ S $ and $ T $ have no conflict type 
%information. Consistency is reflexive and symmetric, but not transitive.

%One might be tempted to conclude that inconsistency is the root of all runtime 
%type errors (blames). In the setting of gradual typing, however, runtime 
%type-checking is usually gradual as well. 
$ S \smile T $ reads ``$ S $ and $ T $ are shallowly-consistent''. Two types 
are shallowly consistent if one of them is $ \star $, or they have the same 
top-most type constructor. Shallow-inconsistency is the root of all blames in 
all lazy strategies -- casting a value to a shallowly inconsistent type leads 
to a blame. Shallow-consistency is reflexive, symmetric, but 
not transitive.

Let $ e $ ranges over terms, including all terms from $ \mathtt{STLC+} $ and, 
in addition, casts and blames. Unlike $ \mathtt{STLC+} $, we annotate the 
co-domain of lambda abstractions explicitly. 
The end of the figure shows the typing rules for the additional terms.

Let $ o $ ranges over observations. They are what would be observed if a 
program terminates. Observations include all constructors and blames.

Now let's move to the dynamic semantics. 

\subsection{\lazyD{} Blame Calculus}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	
	\stxrule{v}{values}{
		\vOOfun{\rho}{x}{b} \mid
		\vOOtt{} \mid
		\vOOcons{v_1}{v_2} \mid
		\vOOinl{v} \mid
		\vOOinr{v} \mid		
		\vOOcast{v}{c}
	}
	\stxrule{c}{casts}{
		\cOOcast{T_1}{l}{T_2}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
		
	\stxrule{\kappa}{continuations}{
		\mathtt{stop} \mid{}
		\mathtt{cons_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{cons_2} \; v \; \kappa \mid{}
		\mathtt{inl} \; \kappa \mid{}
		\mathtt{inr} \; \kappa
	}
	\stxrulecont{
		\mathtt{app_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{app_2} \; v \; \kappa \mid{}
		\mathtt{car} \; \kappa \mid{}
		\mathtt{cdr} \; \kappa \mid
		\mathtt{case_1} \; e_1 \; e_2 \; \rho \; \kappa
	}
	\stxrulecont{	
		\mathtt{case_2} \; v   \; e   \; \rho \; \kappa \mid{}
		\mathtt{case_3} \; v_1 \; v_2 \; \rho \; \kappa \mid
		\langle c \rangle \kappa
	}
	\end{array}
	\]
	
	Value typing \fbox{$ v : T $}
	\begin{gather*}
	\dots \quad
	\inference{
		v : P &
		c : P \Longrightarrow T &
		P \smile T
	}{
		\vOOcast{v}{\cOOcast{P}{l}{T}} : T
	}
	\end{gather*}
	
%	Continuation typing \fbox{$ \kappa : T_1 \Longrightarrow T_2 $}
%	\begin{gather*}
%	\dots \quad
%	\inference{
%		c : T_1 \Longrightarrow T_2 &
%		\kappa : T_2 \Longrightarrow T_3
%	}{
%		\langle c \rangle \kappa : T_1 \Longrightarrow T_3
%	}
%	\end{gather*}
	
	Reduction \fbox{$ \judgeDBreduce{s}{s} $}
	\[
	\begin{array}{rclr}
	
	& \dots  \\
	\redrule{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{\langle\cOOcast{T_1}{l}{T_2}\rangle\kappa}
	}{}
	\redrule{
		\sOOreturn{v_1}{(\mathtt{app_2} \; \vOOcast{v_2}{
				\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
			} \; \kappa)}
	}{
		\sOOreturn{v_1}{
		\langle\cOOcast{T_3}{l}{T_1}\rangle
		(\mathtt{app_2} \; v_2 \; 
		\langle\cOOcast{T_2}{l}{T_4}\rangle \kappa)}
	}{}
	
%	\redrule{
%		\sOOreturn{v}{(
%			\mathtt{app_2} \;
%			(\vOOfun{\rho}{x}{e}) \;
%			\kappa
%		)}
%	}{\sOOinspect{e}{\rho{}[x := v]}{\kappa}}{}

	\redrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
			}{(\mathtt{car} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{car} \;
			\langle \cOOcast{T_1}{l}{T_3} \rangle \kappa
			)}
	}{}

	\redrule{
		\sOOreturn{
			\vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
					\POOprod{T_3}{T_4}}}
		}{(\mathtt{cdr} \; \kappa)}
	}{
		\sOOreturn{v}{(
			\mathtt{cdr} \;
			\langle \cOOcast{T_2}{l}{T_4} \rangle \kappa
			)}
	}{}

	\redrule{
		\sOOreturn{v_3}{(
			\mathtt{case_3} \;
			v_1 \; v_2 \;
			\kappa
		)}
	}{case(v_1,
	\mathtt{app_2} \; v_2 \; \kappa,
	\mathtt{app_2} \; v_3 \; \kappa
	)}{}

	\redrule{
		\sOOreturn{v}{(
			\mathtt{cast} \; c \; \kappa
		)}
	}{
		\sOOreturn{u}{\kappa}
		\\ &
	}{
		\sidecond{applyCast(c,v) = \rOOsucc{u}}
	}

	\redrule{
		\sOOreturn{v}{(
			\mathtt{cast} \; c \; \kappa
			)}
	}{
		\sOOhalt{(\oOOblame{l})}
		\\ &
	}{
		\sidecond{applyCast(c,v) = \rOOfail{l}}
	}
	\end{array}
	\]	
	
	\fbox{$case(v, \kappa, \kappa) = s$}
	\[
	\begin{array}{rclr}
	\funrule{case(\vOOinl{v},\kappa_1,\kappa_2)}{
		\sOOreturn{v}{\kappa_1}
	}{}
	\funrule{case(\vOOinr{v},\kappa_1,\kappa_2)}{
		\sOOreturn{v}{\kappa_2}
	}{}
	\funrule{case(\vOOcast{v}{\cOOcast{\POOsum{T_{11}}{T_{12}}}{l}{\POOsum{T_{21}}{T_{22}}}},\kappa_1,\kappa_2)}{
		case(v,
		\langle \cOOcast{T_{11}}{l}{T_{21}} \rangle \kappa_1,
		\langle \cOOcast{T_{12}}{l}{T_{22}} \rangle \kappa_2)
	}{}
	\end{array}
	\]
	
	\fbox{$applyCast(c,v) = r$}
	\[
	\begin{array}{rclr}
	\funrule{
		applyCast(\cOOcast{\star}{l}{\star},v)
	}{
		\rOOsucc{v}
	}{}
	\funrule{
		applyCast(\cOOcast{\star}{l}{P_2},\vOOcast{v}{\cOOcast{P_1}{l'}{\star}})
	}{
		applyCast(\cOOcast{P_1}{l}{P_2},v)
	}{}
	\funrule{
		applyCast(\cOOcast{P}{l}{\star},v)
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
	}{}
	\funrule{
		applyCast(\cOOcast{P_1}{l}{P_2},v)
	}{
		\rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
	}{\sidecond{P_1 \smile P_2}}
	\funrule{
		applyCast(\cOOcast{P_1}{l}{P_2},v)
	}{
		\rOOfail{l}
	}{\sidecond{\neg P_1 \smile P_2}}
	
	\end{array}
	\]
	
%	Transitive closure of reduction \fbox{$ s \longrightarrow_{D,B}^{*} s $}\\
	
	Evaluation \fbox{$\judgeDBeval{e}{o}$}
	\[
	\inference{
		\sOOinspect{e}{\emptyset}{cont(\hckOOmt)} \longrightarrow_{B}^{*} 
		\sOOhalt{o}
	}{
		\judgeDBeval{e}{o}
	}
	\]
	
	\caption{CEK abstract machine ($ \mathcal{D} $) for the \lazyD{} Blame 
	Calculus}
	\label{machine-cekc}
\end{figure}

Fig.~\ref{machine-cekc} defines the dynamic semantics of the \lazyD{} Blame 
Calculus in the style of CEK machines (\citet{felleisen1986control}).
\todo[inline]{The figure is too tall. You may need to pull some things
  out of the figure, such as the value typing. -Jeremy}
\todo[inline]{Please fill in the missing reduction rules. -Jeremy}
\todo[inline]{Explain why you are using a CEK machine instead of
  reduction semantics. -Jeremy}
\todo[inline]{Change the order of parameters for applyCast to take
  the value first and the cast second. -Jeremy}
\todo[inline]{The definition of values is too loose for a cast.
  You need to restrict the casts to just the inert ones. -Jeremy }
We conjecture that this CEK machines agree with the \lazyD{} blame calculus in 
\citet{siek2012interpretations}.
We will show in \hyperref{sec:hyper-coercion} that this abstract machine is 
equivalent to an abstract machine that represents casts with hyper-coercions.

Let $ c $ ranges over casts. A cast is a triple of a type, a label, and a type.
Let $ v $ ranges over values. A value is either a function, the 
element of unit, a pair, a left injection, a right injection, or a casted value.
The cast around a casted value is not arbitrary, as shown by value typing: the 
source type must be a pre-type, and the source and the target must be 
shallow-consistent.
Let $ r $ ranges over cast results. A cast result is either a success, which 
brings a value, or a failure, which brings a blame label.
Let $ s $ ranges over machine states. A state is either looking at an 
expression to decide what to do next, returning a value to a continuation, or 
halting with an observation.
Let $ \kappa $ ranges over continuations. $ \mathtt{mt} $ is the top 
continuation. The remaining continuations correspond to expressions. For 
example, $ (\mathtt{cons_1} \; e \; \rho \; \kappa) $ is the continuation where 
we are waiting for the value of the first argument to a $ \mathtt{cons} $. And 
the last continuation, $ \langle c \rangle \kappa $ is to cast the value before 
returning to $ \kappa $.

In the reduction rules, to evaluate a cast expression, the machine move the 
cast to the continuation and evaluate the inner expression. To apply a casted 
function, the machine firstly cast $ v_1 $, the operand, then apply the casted 
operand to $ v_2 $, the un-casted function, and finally cast the result of the 
function application. To take out the first (resp. second) part of a casted 
pair, the machine firstly take out the first (resp. second) part of $ v $, the 
un-casted pair, and cast the result. To case-split a sum, the machine looks 
deep inside the value to find out whether it is a left injection or a right 
one. Along the way, the machine accumulate the pending casts onto the 
continuations. To cast a value, the machine try to apply the cast to the value. 
If the cast succeeds, the machine returns the result to the next continuation. 
If the cast fails, the machine halts with the blame label.

Transitive closure of reduction ($ \judgeDBreduceTrans{s}{s} $) and evaluation 
are 
standard.

\subsection{\lazyUD{} Blame Calculus [Jeremy]}


UNDER CONSTRUCTION

Fig.~\ref{fig:apply-Cast-UD}

\begin{figure}

  Syntax
  \[
  \begin{array}{rclr}
    \stxrule{v}{values}{
      \cdots \mid 
      \vOOcast{v}{ \cOOcast{I}{l}{\star} } \mid
      \vOOcast{v}{ \cOOcast{P}{l}{P} }
    }
  \end{array}
  \]
  
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& v \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        v \langle \cOOcast{P}{l}{I} \rangle
          \langle \cOOcast{I}{l}{\star} \rangle
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        v \langle \cOOcast{\star}{l}{I} \rangle
          \langle \cOOcast{I}{l}{P} \rangle
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& v \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
     v \langle \cOOcast{P_1}{l}{P_2} \rangle & \text{if } P_1 \smile P_2
  \end{array}
  \]


  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}


% the following are temporary -Jeremy
\clearpage
\pagebreak

\section{Background: Normal Coercion} \label{sec:coercion-calculus}

In this section we review the normal coercion (NC) in 
\citet{siek2012interpretations}. We ignore sum types and product types in this 
section, because they were not presented in the paper. We assume a basic 
familiarity with coercion, and direct readers who do not know it to 
\citet{siek2012interpretations}.

As the name suggests, 
hyper-coercion is largely inspired by coercion, especially its subst NC. We 
will highlight the similarity of normal coercion and hyper-coercion, and hope 
this would convince you that hyper-coercion should be as difficult to implement 
as NC.

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{I}{injectable types (\lazyD)}{
		\POOfun{T}{T}}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOfun{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{coercions}{
		\ncInj{I} \mid
		\ncProj{I}{l} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncSeq{c}{c} \mid
		\ncFun{c}{c}
	}
	\stxrule{\bar{c}}{wrapper coercions}{	
		\ncInj{I} \mid
		\ncFun{\hat{c}}{\hat{c}} \mid
		\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}
	}
%	\stxrulecont{
%		\ncProd{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncProd{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
%		\ncSum{\hat{c}}{\hat{c}} \mid
%		\ncSeq{\ncSum{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid	
%	}
	\stxrule{\hat{c}}{normal coercions}{
		\bar{c} \mid
		\ncId \mid
		\ncFail{l} \mid
		\ncProj{I}{l} \mid
		\ncSeq{\ncProj{I}{l}}{\ncFail{l}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncInj{I}}
	}
	\stxrulecont{
		\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
		\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}}
	}
	\end{array}
	\]
	\caption{Syntax of Normal Coercion (NC)}
	\label{fig:normal-coercion}
\end{figure}

\figref{fig:normal-coercion} defines the normal coercion. 
Types, pre-types, and blame labels are as before.
Let $ I $ ranges over injectable types. An injectable type is a type that can 
be cast directly to (injection) and from (projection) $ \TOOdyn $. The 
definition of injectable type depends on blame strategy. With \lazyD, all 
pre-types are injectable. With \lazyUD, only $ \POOfun{\TOOdyn}{\TOOdyn} $ 
is injectable. 
Let $ c $ ranges over coercions, a coercion is either injection, projection, 
identity, failure, sequencing, or function coercion.
Let $ \bar{c} $ ranges over wrapper coercions, which represent casts in $ 
\vOOcast{v}{c} $.
Let $ \hat{c} $ ranges over normal coercions. If we inline $ \bar{c} $ and 
re-arrange cases a little bit, the definition becomes:
\[
\begin{array}{rclr}
\stxrule{\hat{c}}{normal coercions}{
	\ncFun{\hat{c}}{\hat{c}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
	\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
	\ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
	\ncId \mid
	\ncProj{I}{l} \mid
	\ncInj{I} \mid
	\ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
	\ncFail{l} \mid
}
\end{array}
\]

Three observations on this definition leads to hyper-coercion: 
\begin{enumerate}
	\item The length of normal coercion is at most three.
	\item Projections are always at the beginning when presented.
	\item Injections and failures are always at the end when presented.
\end{enumerate}


\section{Hyper-coercion} \label{sec:hyper-coercion}

\begin{figure}
	Syntax
	\[
	\begin{array}{lclr}
	\stxrule{I}{injectable types (\lazyD)}{P}
	\stxrule{I}{injectable types (\lazyUD)}{
		\POOunit \mid
		\POOfun{\TOOdyn}{\TOOdyn} \mid
		\POOprod{\TOOdyn}{\TOOdyn} \mid
		\POOsum{\TOOdyn}{\TOOdyn}
	}
	\stxrule{c}{hyper-coercions}{
		\hyperCoercionI \mid{}
		\hyperCoercionC{h}{m}{t}
	}
	\stxrule{h}{heads}{
		\epsilon \mid{}
		?^l
	}
	\stxrule{m}{middles}{
		\POOunit \mid
		\POOfun{c_1}{c_2} \mid
		\POOprod{c_1}{c_2} \mid
		\POOsum{c_1}{c_2}
	}
	\stxrule{t}{tails}{
		\epsilon \mid{}
		! \mid{}
		\bot^l
	}
	\end{array}
	\]
		
	Hyper-coercion typing \fbox{$ c : T \Longrightarrow T $}
	\begin{gather*}
	\inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
	\quad
	\inference{
		\typingHC{h}{T_1}{P_1} &
		\typingHC{m}{P_1}{P_2} &
		\typingHC{t}{P_2}{T_2}
	}{
		\typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
	}
	\end{gather*}
	
	Head typing \fbox{$ \typingHC{h}{T}{P} $}
	\begin{gather*}
	\inference{}{\typingHC{\epsilon}{P}{P}}
	\quad
	\inference{}{\typingHC{?^l}{\TOOdyn}{I}}
	\end{gather*}
	
	Middle typing \fbox{$ \typingHC{m}{T}{T} $}
	\begin{gather*}
	\inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
	\quad
	\inference{
		\typingHC{c_1}{T_3}{T_1} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
	}
	\\
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
	}
	\quad
	\inference{
		\typingHC{c_1}{T_1}{T_3} &
		\typingHC{c_2}{T_2}{T_4}
	}{
		\typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
	}
		\end{gather*}
		
		Tail typing \fbox{$ \typingHC{t}{P}{T} $}
		\begin{gather*}
		\inference{}{\typingHC{\epsilon}{P}{P}} \quad
		\inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
		\inference{}{\typingHC{\bot^l}{P}{T}} \quad
		\end{gather*}
	
	\caption{Definition of Hyper-coercion (HC)}
	\label{fig:hyper-coercion}
\end{figure}

This section presents our first contribution, hyper-coercion (HC). 
\figref{fig:hyper-coercion} defines the syntax of HC.
Types, pre-types, and blame labels are as before.

Let $ c $ ranges over hyper-coercions. A hyper-coercion is either 
an identity cast between the dynamic types, or a complex including a head, a 
middle, and a tail. 
Let $ h $ ranges over heads. A head is either a no-op, or a projection.
Let $ m $ ranges over middles. There is a one-to-one 
correspondence between middles and type constructors. 
We generalize shallow-consistency to middles $ m \smile m $ in the natural way.
Let $ t $ ranges over tails. A tail is either a no-op, an injection, or a 
failure. 
Let $ \ell $ ranges over no-op and labels. It is useful when we introduce 
composition of hyper-coercions.

\subsection{\lazyD{} Hyper-coercion}

\begin{figure}
	\[
	\begin{array}{rclr}
	\stxrule{\ell}{Maybe $ l $}{\epsilon \mid l}
	\end{array}
	\]
	
	Composition of hyper-coercions \fbox{$ c \fatsemi^\ell c = c $}
	\[ 
	\begin{array}{rclclr}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{
		\hyperCoercionI
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{
		\hyperCoercionC{?^{l'}}{m}{t}
	}{}
	
	\comprule{
		\hyperCoercionI
	}{
		\hyperCoercionC{\epsilon}{m}{t}
	}{
		\hyperCoercionC{?^{l}}{m}{t}
	}{\sidecond{\ell = l}}
	
	\comprule{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{
		c
	}{
		\hyperCoercionC{h}{m}{\bot^{l'}}
	}{}
	
	\comprule{
		\hyperCoercionC{h}{m}{t}
	}{
		\hyperCoercionI
	}{
		\hyperCoercionC{h}{m}{!}
	}{
		\sidecond{\forall l. t \neq \bot^{l}}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{\epsilon}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			t_1 \neq \bot^{\centerdot} \; \text{and} \;
			m_1 \fatsemi^{\ell} (m_2, t_2) = (m', t')
		}
	}
	
	\comprule{
		\hyperCoercionC{h}{m_1}{t_1}
	}{
		\hyperCoercionC{?^{l'}}{m_2}{t_2}
	}{
		\hyperCoercionC{h}{m'}{t'}
	}{
		\sidecond{
			t_1 \neq \bot^{\centerdot} \; \text{and} \;
			m_1 \fatsemi^{l'} (m_2, t_2) = (m', t')
		}
	}
	\end{array}
	\]
	
	Composition of middles \fbox{$ m \fatsemi^\ell (m,t) = (m,t) $}
	\[ 
	\begin{array}{rclclr}
	\comprule{\POOunit}{(\POOunit,t)}{
		(\POOunit,t)
	}{}
	\comprule{\POOfun{c_1}{c_2}}{(\POOfun{c_3}{c_4},t)}{
		(\POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOprod{c_1}{c_2}}{(\POOprod{c_3}{c_4},t)}{
		(\POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{\POOsum{c_1}{c_2}}{(\POOsum{c_3}{c_4},t)}{
		(\POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4},t)
	}{}
	\comprule{m_1}{(m_2,t)}{
		(m_1,\bot^l)
	}{
		\sidecond{
			\ell = l \; \text{and} \;
			\neg m_1 \smile m_2 
		}
	}
	\end{array}
	\]
	
	\fbox{$ seq(c,c) = c $}
	\[
	\begin{array}{rclr}
	\funrule{seq(c_1,c_2)}{
		c_1 \fatsemi^\epsilon c_2
	}{}
	\end{array}
	\]
	
	\fbox{$ id( P ) = m $}
	\[
	\begin{array}{rclr}
	\funrule{id(\POOunit)}{\POOunit}{}
	\funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
	}{}
	\funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
	}{}
	\end{array}
	\]
	
	\fbox{$ id( T ) = c $}
	\[
	\begin{array}{rclr}
	\funrule{id(\star)}{
		\hyperCoercionI
	}{}
	\funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
	}{}
	\end{array}
	\]
	
	\fbox{$ cast(T,l,T) = c$}
	\[
	\begin{array}{rclr}
	\funrule{cast(T_1,l,T_2)}{
		id(T_1) \fatsemi^l id(T_2)
	}{}
	\end{array}
	\]
	\caption{\lazyD{} Hyper-coercion}
	\label{fig:HC-D}
\end{figure}

\lazyD{} HC constructors are in \figref{fig:HC-D}.

$ c_1 \fatsemi^\ell c_2 = c' $ composes two hyper-coercions. The target of $ 
c_1 $ and the source of $ c_2 $ might be different, in which case $ \ell $ must 
be a label.
$ m_1 \fatsemi^\ell (m_2,t) = (m',t') $ composes a middle with a 
pair of a middle and a tail. Similarly, the target of $ m_1 $ and the source of 
$ m_2 $ might be different, in which case $ \ell $ must be a label.
$ seq(c_1,c_2) $ composes two coercions where the target type of $ c_1 $ is 
equal to the source type of $ T_2 $.
$ id(T) $ constructs an identity coercion of $ T $ with the help of $ id(P) $.
$ cast(T_1,l,T_2) $ constructs a coercion from a source type, a label, and a 
target type. 

\begin{proposition}[\lazyD\ Hyper-coercions is a Monoid]
	For all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{proposition}

The correctness proof of \lazyD\ HC is deferred to \secref{sec:LDHC-correct} 
because it relies on the space-efficient CEK abstract machine in 
\secref{sec:CEKS}.

\subsection{\lazyUD{} Hyper-coercion [Jeremy]}


Figure~\ref{fig:HC-UD}

\begin{figure}
  Composition of hypercoercions \fbox{$ c \fatsemi c = c $}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
       \hyperCoercionC{p_2}{m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{\epsilon} &\fatsemi& \hyperCoercionC{\epsilon}{m_2}{i_2} &=&
       \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} \\
  \hyperCoercionC{p_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{i_2} &=&
  \begin{cases}
    \hyperCoercionC{p_1}{m_1 \fatsemi m_2}{i_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{p_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{p_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{p_2}{m_2}{i_2} &=&
     \hyperCoercionC{p_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$ id( P ) = m $}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
		\POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
		\POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
		\POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$ id( T ) = c $}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
		\hyperCoercionI
    }{}
    \funrule{id(P)}{
		\hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]

  
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}


Figure~\ref{fig:HC-UD-cast}


\begin{figure}
  \fbox{$ \mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$ \mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$ \mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$ \mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$ cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxilliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\section{Space-efficient CEK Abstract Machine}
\label{sec:CEKS}

This section presents our second contribution, a space-efficient CEK abstract 
machine. This machine is parameterized over \emph{cast representation} (CR). 

\begin{definition}[Cast Representation]
	A cast representation is a set indexed by two types and has four interface 
	functions:
	\begin{description}
		\item[$ id(T) $] constructs an identity cast
		\item[$ seq(c_1,c_2) $] composes two casts
		\item[$ cast(T_1,l,T_2) $] constructs a cast from $ T_1 $ to $ T_2 $
		\item[$ applyCast(c,v) $] applies a cast onto a value
	\end{description}
\end{definition}

\begin{definition}[Monoidic Cast Representation]
	A cast representation is monoidic if 
	for all $c : T_1 \Longrightarrow T_2$,
	$c_1 : T_1 \Longrightarrow T_2$,
	$c_2 : T_2 \Longrightarrow T_3$, and
	$c_3 : T_3 \Longrightarrow T_4$,
	\begin{enumerate}
		\item $seq(id(T_1),c) = c$,
		\item $seq(c,id(T_2)) = c$, and
		\item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
	\end{enumerate}
\end{definition}

\begin{figure}
	Syntax
	\[
	\begin{array}{rclr}
	
	\stxrule{v}{values}{
		\hcvOOtt \mid
		\hcvOOfun{c_1}{\rho}{x}{b}{c_2} \mid
		\hcvOOcons{v_1}{c_1}{v_2}{c_2}
	}
	\stxrulecont{
		\hcvOOinl{v}{c} \mid
		\hcvOOinr{v}{c} \mid
		\hcvOOinj{P}{v}
	}
	\stxrule{r}{cast results}{
		\rOOsucc{v} \mid
		\rOOfail{l}
	}
	\stxrule{s}{states}{
		\sOOinspect{e}{\rho}{\kappa} \mid{}
		\sOOreturn{v}{\kappa} \mid{}
		\sOOhalt{o}
	}
	\stxrule{\kappa}{continuation}{
		(c,k)
	}
	\stxrule{k}{pre-continuations}{
		\hckOOmt \mid{}
		\mathtt{cons_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{cons_2} \; v \; \kappa \mid{}
		\mathtt{inl} \; \kappa \mid{}
		\mathtt{inr} \; \kappa
	}
	\stxrulecont{
		\mathtt{app_1} \; e \; \rho \; \kappa \mid{}
		\mathtt{app_2} \; v \; \kappa \mid{}
		\mathtt{car} \; \kappa \mid{}
		\mathtt{cdr} \; \kappa
	}
	\stxrulecont{
		\mathtt{case_1} \; e_1 \; e_2 \; \rho \; \kappa \mid
		\mathtt{case_2} \; v   \; e   \; \rho \; \kappa \mid{}
		\mathtt{case_3} \; v_1 \; v_2 \; \rho \; \kappa
	}
	\end{array}
	\]
	
	Build continuation \fbox{$ cont(k) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{cont(k)}{(id(T_1),k)}{
		\sidecond{k : T_1 \Longrightarrow T_2}}
	\end{array}
	\]
	
	Extend continuation \fbox{$ ext(c,\kappa) = \kappa $}
	\[
	\begin{array}{rclc}
	\funrule{ext(c_1,(c_2,k))}{(seq(c_1,c_2),k)}{}
	\end{array}
	\]
	
	Reduction \fbox{$ \judgeSreduce{C}{s}{s} $}
	\[
	\begin{array}{rclr}
	& \vdots \\
	\redruleS{
		\sOOinspect{(\eOOlam{T_1}{T_2}{x}{e})}{\rho}{\kappa}
	}{
		\sOOreturn{(\hcvOOfun{id(T_1)}{\rho}{x}{e}{id(T_2)})}{\kappa}
	}{}
	\redruleS{
		\sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\rho}{\kappa}
	}{
		\sOOinspect{e}{\rho}{ext(cast(T_1,l,T_2),\kappa)}
	}{}
	\redruleS{
		\sOOinspect{(\eOOcons{e_1}{e_2})}{\rho}{\kappa}
	}{
		\sOOinspect{e_1}{\rho}{cont(\hckOOconsI{e_2}{\rho}{\kappa})}
	}{}
	\redruleS{
		\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
	}{
		\sOOinspect{e}{\rho[x:=v']}{ext(c_2,\kappa)}
	}{
		\\ & &
		\sidecond{applyCast(c_1,v) = \rOOsucc{v'}}
	}
	\redruleS{
		\sOOreturn{(\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{(c,\hckOOappII{v}{\kappa})}
	}{
		\sOOhalt{(\oOOblame{l})}
	}{
		\\ & &
		\sidecond{applyCast(c_1,v) = \rOOfail{l}}
	}
	\end{array}
	\]
	
%	Transitive closure of reduction \fbox{$ s \longrightarrow_{S(C)}^{*} s $}
%	\[\dots\]
	
	Evaluation \fbox{$ \judgeSeval{C}{e}{o} $}
	\[
	\inference{
		\judgeSreduceTrans{C}{
			\sOOinspect{e}{\emptyset}{cont(\hckOOmt)}
		}{
			\sOOhalt{o}
		}		
	}{
		\judgeSeval{C}{e}{o}
	}
	\]
	
	\caption{Space-efficient CEK machine $ \mathcal{S}(C) $}
	\label{machine-cekcc}
\end{figure}

\figref{machine-cekcc} defines the machine. 
Let $ v $ ranges over value. A value is either the unit value, function, pair, 
left injection of sum, right injection of sum, and injection to $ \TOOdyn $.
Cast results ($ r $) and machine states ($ s $) are as before. 
Let $ \kappa $ ranges over continuations and let $ k $ ranges over 
pre-continuations. 
A continuation is now a pair where the first part is a cast and the second 
part is a pre-continuation. 
Pre-continuation are like the continuations before.

We list a fraction of reduction rules due to space limitation.
When values are constructed, their hyper-coercion parts are filled with outputs 
of $ id $. For instance, when a function value is constructed, its first part 
and last part are initialized to $ id(T_1) $ and $ id(T_2) $ respectively.
When evaluating a cast expression, the current continuation is extended with a 
hyper-coercion constructed by $ cast $. $ ext $ composes the new hyper-coercion 
with the hyper-coercion on the top of the continuation.
When evaluating a compound expression, the machine firstly construct the new 
pre-continuation, then turn it to a continuation by adding an identity 
hyper-coercion at the top. For instance, when evaluating a \texttt{cons} 
expression, the machine firstly construct $ \hckOOconsI{e_2}{\rho}{\kappa} $, 
the new pre-continuation, then call $ cont $, which adds an identity cast to 
form a continuation. 
When a function call happens, the machine firstly cast the operand. If the 
casting succeeds, the machine then evaluate the body in the extended 
environment and the extended continuation. If the casting fails, the machine 
then halts with the blame label.

Transitive closure of reduction ($ \judgeSreduceTrans{C}{s}{s} $) and 
evaluation are standard. Value typing ($ \judgeType{v}{T} $) is straightforward.


\section{Correctness Proof of \lazyD{} Hyper-coercions}

\subsection{\lazyD\ Cast Representations}

In this section we describe a subset of SR, where all 
elements implement the \lazyD{} blame strategy. We will show in 
Subsection~\ref{sec:LDHC-correct} that the \lazyD\ HC is in this subset.

\begin{definition}[Surely \lazyD\ Cast Representation]
	A cast representation is surely \lazyD\ if
	\begin{enumerate}
		\item If $ v : T $, then $ applyCast(id(T), v) = \mathtt{succ} \; v $
		\item If $ \judgeType{v}{T_1} $,
				 $ \judgeTypeFT{c_1}{T_1}{T_2} $, and
				 $ \judgeTypeFT{c_2}{T_2}{T_3} $,\\
		then $ applyCast(seq(c_1,c_2),v) = 
			   applyCast(c_1,v) >>= \lambda v.applyCast(c_2,v) $ \\
		where 
		\[
		\begin{array}{rcl}
			\rOOsucc{v} >>= f & = & f(v) \\
			\rOOfail{l} >>= f & = & \rOOfail{l}
		\end{array}
		\]
		\item If $ v : T_1 $ and $ \neg T_1 \smile T_2 $,
		then $ applyCast(cast(T_1, l, T_2),v) = \rOOfail{l} $
		\item If $ v : \star $, 
		then $ applyCast(cast(\TOOdyn,l,\TOOdyn),v) = \rOOsucc{v} $
		\item If $ v : P $,
		then $ applyCast(cast(\star,l,Q),\hcvOOinj{P}{v}) 
		= applyCast(cast(P,l,Q),v) $
		\item If $ v : P $,
		then $ applyCast(cast(P,l,\star),v) = \rOOsucc{(\hcvOOinj{P}{v})} $
		\item If $ v : \POOunit $,
		then $ applyCast(cast(\POOunit,l,\POOunit),v) = \rOOsucc{v} $
		\item
		$ 
		applyCast(cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4}) ,
		\hcvOOfun{c_1}{\rho}{x}{b}{c_2}) \\
		= 
		\rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\rho}{x}{b}{seq(c_2,cast(T_2,l,T_4))})}$
		
		\item $ applyCast(cast(\POOprod{T_1}{T_2},l,T_3 \times 
		T_4),\hcvOOcons{v_1}{c_1}{v_2}{c_2}) $ \\
		$ = 
		\rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
		$ 
		\item $ 
		applyCast(cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}),\hcvOOinl{v}{c})
		= \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_2))})} $
		\item $ 
		applyCast(cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}),\hcvOOinr{v}{c})
		= \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_3,l,T_4))})} $
	\end{enumerate}
\end{definition}

\subsection{Relating All Surely \lazyD{} Cast Representations}

With the properties of surely \lazyD{} CR, it is straightforward to proof that 
all machines instantiated with these CRs bi-simulate each other. 
The state bisimilarity ($\eqvS{C}{C}{s}{s}$) is 
derived from the definition of states. We omit subscripts when there is no 
ambiguity. \begin{gather*}
\inference{
	\rho_1 \approx \rho_2 &
	\kappa_1 \approx \kappa_2
}{
	\sOOinspect{e}{\rho_1}{\kappa_1} \approx \sOOinspect{e}{\rho_2}{\kappa_2}
}
\quad
\inference{
	\kappa_1 \approx \kappa_2 &
	v_1 \approx v_2
}{
	\sOOreturn{v_1}{\kappa_1} \approx \sOOreturn{v_2}{\kappa_2}
}
\quad
\inference{
}{
	\sOOhalt{o} \approx \sOOhalt{o}
}
\end{gather*}

The relations between continuations, pre-continuations, enviroments, values, 
cast results are also derived from their definitions. But the relation for 
casts is special: \begin{gather*}
\inference{
}{
	cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
	id_1(T) \approx id_2(T)
}
\quad
\inference{
	c_1 \approx c_2 &
	c_3 \approx c_4
}{
	seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\begin{proposition}[Strong Bi-simulation among $ \mathcal{S}(\cdot) $]
	\label{thm:CEKS-bisim}
	If 
	$ C_1 $ and $ C_2 $ are surely \lazyD,
	$ s_1, s_2 \in S(C_1) $ and $ s_3 \in S(C_2) $,
	$ s_1 \approx s_3 $,
	$ \judgeSreduce{C_1}{s_1}{s_2} $,
	then there exists an $ s_4 $ such that
	\begin{itemize}
	\item $ s_2 \approx s_4 $ and
	\item $ s_3 \longrightarrow_{S(C_2)} s_4 $
	\end{itemize}
\end{proposition}
\begin{proof}
	The key ideas of this proof are undoing sequencing with the property (2) of 
	surely \lazyD{} CR, and handling all possibly uses of $ 
	cast(T,l,T) $ with property (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of Surely \lazyD{} Cast Representations]
	\label{thm:surely-lazyD-eqv}
	If $ \judgetype{\emptyset}{e}{T} $, $ o : T $, and $ C_1 $ and $ C_2 $ 
	are surely \lazyD cast representations,
	\[
	e \Downarrow_{S(C_1)} o \; \text{if and only if} \; 
	e \Downarrow_{S(C_2)} o
	\]
\end{proposition}
\begin{proof}
	Immediately from Proposition~\ref{thm:CEKS-bisim}.
\end{proof}

\subsection{Relating All Surely \lazyD{} Cast Representations to $\mathcal{D}$}

So far, we have related all surely \lazyD{} CRs, i.e. they are equivalent to 
each other. But this does not mean they respect the semantics of the \lazyD{} 
Blame Calculus. We solve prove this part in this subsection.

The state bisimilarity here ($\eqvDS{C}{s}{s}$) is mostly derived from the 
definitions of $ \mathcal{D} $. Exceptions include the bisimilarity relations 
between continuations, between values, and from continuations to 
pre-continuations. 

\todo[inline]{bisimilarity}

\begin{lemma}[Weak Bi-simulation between $ \mathcal{S}(\cdot) $ and $ 
\mathcal{D} $]
\label{thm:surely-monoidic-reduce}
For all cast representations $ C $, 
if $ C $ is surely \lazyD{} and monoidic,
$ s_1 \in \mathcal{D} $,
$ s_2 \in \mathcal{S}(C) $, and
$ s_1 \approx s_2 $, 
\begin{enumerate}
	\item If $ \judgeDBreduce{s_1}{s_3} $,
	then
	there exist $ s_5 \in \mathcal{D} $, $ s_4 \in \mathcal{S}(C) $,
	such that \begin{itemize}
		\item $ s_5 \approx s_4 $, and
		\item $ \judgeSreduce{C}{s_2}{s_4} $,
		\item $ \judgeDBreduceTrans{s_3}{s_5} $
	\end{itemize}
	\item If $ \judgeSreduce{C}{s_2}{s_4} $,
	then
	there exist $ s_3 \in \mathcal{D} $,
	such that \begin{itemize}
		\item $ s_3 \approx s_4 $
		\item $ \judgeDBreduceTrans{s_1}{s_3} $
	\end{itemize}
\end{enumerate}
\end{lemma}
\begin{proof}
	See the supplementary material.
\end{proof}

\begin{lemma}[Surely \lazyD\ and Monoidic Cast Representations Respect 
$ \mathcal{D} $]
	\label{thm:surely-monoidic-eval}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is surely 
	\lazyD{} and monoidic,
	\[
	\judgeDBeval{e}{o} \; \text{if and only if} \; 
	\judgeSeval{C}{e}{o}
	\]
\end{lemma}
\begin{proof}
	Immediately from Lemma~\ref{thm:surely-monoidic-reduce}.
\end{proof}

\begin{theorem}[Surely \lazyD\ Cast Representations Respect 
	$ \mathcal{D} $]
	\label{thm:surely-lazyD-correct}
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ and $ C $ is surely 
	\lazyD{}
\[
\judgeDBeval{e}{o} \; \text{if and only if} \; 
\judgeSeval{C}{e}{o}
\]
\end{theorem}
\begin{proof}
	Immediately from Lemma~\ref{thm:surely-monoidic-eval} and 
	Proposition~\ref{thm:surely-lazyD-eqv}.
\end{proof}

\subsection{\lazyD\ Hyper-coercion Respect $ \mathcal{D} $}
\label{sec:LDHC-correct}

To show that \lazyD\ HC is correct, we first show it is surely \lazyD, then 
uses the Theorem~\ref{thm:surely-lazyD-correct} to prove its correctness.

\figref{hc-applyCast} defines $ applyCast $, the last interface function.
We generalize shallow-consistency to middles and values ($ m \smile v $) in the 
natural way.
Applying the identity cast for the 
dynamic type succeeds immediately. When applying a compound cast, we firstly 
apply the middle, then apply the tail. We denote by $ r \; >>= \; f $ to mean 
that if $ r $ is $ \rOOsucc{v} $, the result is $ f(v) $, otherwise the result 
is the failure.
$ applyMiddle(\ell,m,v) $ and $ applyTail(t,v) $ are straightforward.

\begin{figure}
	\fbox{$ applyCast(c,v) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyCast(\hyperCoercionI,\;v)}{\rOOsucc{v}}{}
	\funrule{applyCast(\hyperCoercionC{?^l}{m}{t},\;\hcvOOinj{P}{v})}{
		applyMiddle(l,m,v) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\funrule{applyCast(\hyperCoercionC{\epsilon}{m}{t},\;v)}{
		applyMiddle(\epsilon,m,v) \; >>= \; \lambda v. applyTail(t,v)
	}{}
	\end{array}
	\]
	
	\fbox{$ applyMiddle(\ell,m,v) = v $}
	\[
	\begin{array}{rclr}
	\funrule{applyMiddle(\ell,\POOunit,\hcvOOtt)}{\hcvOOtt}{}
	\funrule{applyMiddle(\ell,\POOfun{c_3}{c_4},\hcvOOfun{c_1}{\rho}{x}{e}{c_2})}{
		\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\rho}{x}{e}{(c_2 \fatsemi^\ell c_4)}
	}{}
	\funrule{applyMiddle(\ell,\POOprod{c_3}{c_4},\hcvOOcons{v_1}{c_1}{v_2}{c_2})}{
		\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 \fatsemi^\ell c_4)}
	}{}
	\funrule{applyMiddle(\ell,\POOsum{c_3}{c_4},\hcvOOinl{v}{c_1})}{
		\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)}
	}{}
	\funrule{applyMiddle(\ell,\POOsum{c_3}{c_4},\hcvOOinr{v}{c_2})}{
		\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)}
	}{}
	\funrule{applyMiddle(\ell,m,v)}{
		\rOOfail{l}
	}{
		\sidecond{\ell = l \; \text{and} \; \neg m \smile v}
	}
	\end{array}
	\]
	
	\fbox{$ applyTail(t,v) = r $}
	\[
	\begin{array}{rclr}
	\funrule{applyTail(\bot^l,v)}{\rOOfail{l}}{}
	\funrule{applyTail(\epsilon,v)}{\rOOsucc{v}}{}
	\funrule{applyTail(!,v)}{\rOOsucc{(\hcvOOinj{P}{v})}}{v : P}
	\end{array}
	\]
	\caption{\lazyD\ Hyper-coercion's $ applyCast $}
	\label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} Hyper-coercion is Surely \lazyD]
	\label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof}
	See the supplementary material.
\end{proof}

\begin{theorem}[\lazyD{} Hyper-coercion Respect $ \mathcal{D} $]
	If $ \judgetype{\emptyset}{e}{T} $ and $ o : T $ 
	\[
	\judgeDBeval{e}{o} \; \text{if and only if} \; 
	\judgeSeval{H}{e}{o}
	\]
\end{theorem}
\begin{proof}
	Immediately from Lemma~\ref{thm:hc-surely-lazyD} and 
	Theorem~\ref{thm:surely-lazyD-correct}.
\end{proof}

\section{Conclusion} \label{sec:conclude}

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots


\end{document}
