%% For double-blind review submission, w/o CCS and ACM Reference (max 

%%submission space)
\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max 
%%submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2020}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
\usepackage{stmaryrd}
\usepackage{todonotes}
\usepackage{amsthm}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{semantic}
\usepackage{hyperref}

%\newtheorem{theorem}{Theorem}[]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{proposition}{Proposition}[]
%\newtheorem{definition}{Definition}

\newcommand{\mbind}{\ensuremath{\;\underline{\gg}\;}}

\newcommand{\GTLC}{\texttt{GTLC+}}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\stxinrule}[3]{\text{#2} & #1 & \in & #3\\}
\newcommand{\stxrule}[3]{\text{#2} & #1 & ::= & #3\\}
\newcommand{\stxrulecont}[1]{& & | & #1 \\}
\newcommand{\funrule}[3]{#1 &=& #2 & #3\\}
\newcommand{\hifunrule}[3]{\highlight{#1} &\highlight{=}& \highlight{#2} & 
\highlight{#3}\\}
\newcommand{\comprule}[4]{#1 & \fatsemi^\ell & #2 & = & #3 & #4 \\}
\newcommand{\comprulel}[4]{#1 & \fatsemi^l & #2 & = & #3 & #4 \\}
\newcommand{\plus}[0]{+}
\newcommand{\judgetype}[3]{#1 \vdash #2 : #3}
\newcommand{\judgeType}[2]{#1 : #2}
\newcommand{\judgeTypeFT}[3]{#1 : #2 \Longrightarrow #3} % FT = From To
\newcommand{\lazyUD}{Lazy\;UD}
\newcommand{\lazyD}{Lazy\;D}

\newcommand{\sOOinspect}[3]{\langle#1,#2,#3\rangle}
\newcommand{\sOOreturn}[2]{\langle#1,#2\rangle}
\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}

%\newcommand{\sOOinspect}[3]{\mathtt{Eval} \; #1 \; #2 \; #3}
%\newcommand{\sOOreturn}[2]{\mathtt{Cont} \; #2 \; #1}
%\newcommand{\sOOhalt}[1]{\mathtt{Halt} \; #1}

\newcommand{\TOOdyn}[0]{\star}
\newcommand{\TOOpre}[1]{#1}
\newcommand{\POOunit}[0]{\mathtt{Unit}}
\newcommand{\POOfun}[2]{#1 \shortrightarrow #2}
\newcommand{\POOprod}[2]{#1 \times #2}
\newcommand{\POOsum}[2]{#1 \plus #2}
\newcommand{\eOOvar}[1]{#1}
\newcommand{\eOOsole}[0]{\mathtt{unit}}
\newcommand{\eOOlam}[4]{\lambda^{#1\rightarrow{}#2}#3.#4}
\newcommand{\eOOapp}[2]{(#1 \; #2)}
\newcommand{\eOOcons}[4]{\mathtt{cons}^{\POOprod{#1}{#2}} \; #3 \; #4}
\newcommand{\eOOcar}[1]{\mathtt{fst} \; #1}
\newcommand{\eOOcdr}[1]{\mathtt{snd} \; #1}
\newcommand{\eOOinl}[3]{\mathtt{inl}^{\POOsum{#1}{#2}} \; #3}
\newcommand{\eOOinr}[3]{\mathtt{inr}^{\POOsum{#1}{#2}} \; #3}
\newcommand{\eOOcase}[3]{\mathtt{case} \; #1 \; #2 \; #3}
\newcommand{\eOOcast}[4]{#1 \langle \cOOcast{#2}{#3}{#4} \rangle}
\newcommand{\eOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\cOOcast}[3]{#1 \Rightarrow^{#2} #3}
\newcommand{\oOOdyn}{\mathtt{dyn}}
\newcommand{\oOOsole}{\mathtt{unit}}
\newcommand{\oOOfun}{\mathtt{fun}}
\newcommand{\oOOcons}{\mathtt{cons}}
\newcommand{\oOOinl}{\mathtt{inl}}
\newcommand{\oOOinr}{\mathtt{inr}}
\newcommand{\oOOblame}[1]{\mathtt{blame} \; #1}
\newcommand{\vOOcast}[2]{#1\langle#2\rangle}
%\newcommand{\vOOfun}[3]{\mathtt{fun} \; #1 \; #2 \; #3}
% Jeremy prefers the following
\newcommand{\vOOfun}[3]{\langle \lambda  #2. #3, #1 \rangle}
\newcommand{\vOOtt}[0]{\mathtt{unit}}
\newcommand{\vOOcons}[2]{\mathtt{cons}\;#1\;#2}
\newcommand{\vOOinl}[1]{\mathtt{inl}\;#1}
\newcommand{\vOOinr}[1]{\mathtt{inr}\;#1}
\newcommand{\rOOsucc}[1]{\mathtt{succ}\;#1}
\newcommand{\rOOfail}[1]{\mathtt{fail}\;#1}

\newcommand{\kOOmt}[0]{\mathtt{stop}}
\newcommand{\kOOconsI}[5]{
	[\mathtt{cons}^{\POOprod{#1}{#2}} \; \square \; \langle#3,#4\rangle ]#5}
\newcommand{\kOOconsII}[4]{
	[\mathtt{cons}^{\POOprod{#1}{#2}} \; #3 \; \square]#4}
\newcommand{\kOOinl}[3]{[\mathtt{inl}^{\POOsum{#1}{#2}}\; \square]#3}
\newcommand{\kOOinr}[3]{[\mathtt{inr}^{\POOsum{#1}{#2}}\; \square]#3}
\newcommand{\kOOappI}[3]{
  [\square \; \langle#1,#2\rangle]#3
}
\newcommand{\kOOappII}[2]{
  [#1 \; \square]#2}
\newcommand{\kOOcar}[1]{[\mathtt{fst} \; \square]#1}
\newcommand{\kOOcdr}[1]{[\mathtt{snd} \; \square]#1}
\newcommand{\kOOcaseI}[4]{
  [\mathtt{case} \; \square \; \langle#1,#3\rangle \; \langle#2,#3\rangle ]#4}
\newcommand{\kOOcaseII}[4]{
  [\mathtt{case} \; #1 \; \square \; \langle#2,#3\rangle ]#4}
\newcommand{\kOOcaseIII}[3]{
  [\mathtt{case} \; #1 \; #2 \; \square]#3}
\newcommand{\kOOcast}[2]{
  [\square \langle #1 \rangle]#2}
\newcommand{\typingHC}[3]{#1 : #2 \Longrightarrow #3}
\newcommand{\hcvOOinj}[2]{\mathtt{Dyn}_{#1}(#2)}
%\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #1 \; #2 \; #3 \; #4 \; #5}
%\newcommand{\hcvOOfun}[5]{\mathtt{fun} \; #2 \; #1 \; #3 \; #4 \; #5}
% Jeremy prefers the following version:
\newcommand{\hcvOOfun}[5]{\langle \lambda #3.\, #4 , #1 , #5, #2 \rangle}
\newcommand{\hcvOOtt}[0]{\mathtt{unit}}
%\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\;#2\;#3\;#4}
\newcommand{\hcvOOcons}[4]{\mathtt{cons}\;#1\langle#2\rangle\;#3\langle#4\rangle}
%\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\;#2}
%\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\;#2}
\newcommand{\hcvOOinl}[2]{\mathtt{inl}\;#1\langle#2\rangle}
\newcommand{\hcvOOinr}[2]{\mathtt{inr}\;#1\langle#2\rangle}
\newcommand{\hckOOmt}[0]{\mathtt{stop}}
\newcommand{\hckOOconsI}[3]{\mathtt{cons_1}\;#1\;#2\;#3}
\newcommand{\hckOOappII}[2]{\mathtt{app_2}\;#1\;#2}
\newcommand{\sidecond}[1]{\text{if}\;#1}
% Lazy D cast calculus on space-inefficient CEK
\newcommand{\judgeCreduce}[2]{#1 \longmapsto_{\mathcal{X}} #2}
\newcommand{\judgeCreduceTrans}[2]{#1 \longmapsto_{\mathcal{X}}^{*} #2}
\newcommand{\judgeCeval}[2]{eval_{\mathcal{X}}(#1) = #2}
\newcommand{\redrule}[3]{#1 & \longmapsto_\mathcal{X} & #2 & #3\\}
\newcommand{\hiredrule}[3]{\highlight{#1} & \highlight{\longmapsto_\mathcal{X}} 
& \highlight{#2} & \highlight{#3} \\}
% blame calculus on space-efficient CEK
\newcommand{\judgeSreduce}[3]{#2 \longmapsto_{\mathcal{S}(#1)} #3}
\newcommand{\judgeSreduceTrans}[3]{#2 \longmapsto_{\mathcal{S}(#1)}^{*} #3}
\newcommand{\judgeSeval}[3]{eval_{\mathcal{S}(#1)}(#2) = #3}
\newcommand{\redruleS}[3]{#1 & \longmapsto_{\mathcal{S}(C)} & #2 & #3\\}
\newcommand{\hiredruleS}[3]{\highlight{#1} & 
\highlight{\longmapsto_{\mathcal{S}(C)}} & \highlight{#2} & \highlight{#3} \\}
% Normal Coercion
\newcommand{\ncProj}[2]{#1?^{#2}}
\newcommand{\ncInj}[1]{#1!}
\newcommand{\ncId}[0]{\iota}
\newcommand{\ncSeq}[2]{#1;#2}
\newcommand{\ncFail}[1]{\bot^{#1}}
\newcommand{\ncFun}[2]{\POOfun{#1}{#2}}
\newcommand{\ncProd}[2]{\POOprod{#1}{#2}}
\newcommand{\ncSum}[2]{\POOsum{#1}{#2}}
% Hypercoercion
\newcommand{\hyperCoercionI}[0]{\mathtt{id\star}}
\newcommand{\hyperCoercionC}[3]{#1 \overset{#2}{\curvearrowright} #3}
% machine state simulations
\newcommand{\eqvS}[4]{#3 \approx_{\mathcal{S}\mathcal{S}} #4}
\newcommand{\eqvSD}[3]{#2 \approx_{\mathcal{SD}} #3}
% to-dos
\newcommand{\todoKC}[1]{\todo[inline]{KC needs to #1}}
\newcommand{\todoKCFixed}[0]{\todo[inline]{Fixed. -KC}}
% abbrev
\newcommand{\castCalculus}[0]{$\lambda_{\rightarrow}^{\langle\cdot\rangle}$}
% names
\newcommand{\ineffCEK}{\ensuremath{\mathcal{X}}}
\newcommand{\ineffCEKD}{\ensuremath{\mathcal{D}}}
\newcommand{\ineffCEKUD}{\ensuremath{\mathcal{UD}}}
\newcommand{\judgeDreduce}[2]{#1 \longmapsto_{\mathcal{D}} #2}
\newcommand{\judgeDreduceTrans}[2]{#1 \longmapsto_{\mathcal{D}}^{*} #2}
\newcommand{\judgeDreducePlus}[2]{#1 \longmapsto_{\mathcal{D}}^{+} #2}
\newcommand{\judgeDeval}[2]{eval_{\mathcal{D}}(#1) = #2}
\newcommand{\judgeUDreduce}[2]{#1 \longmapsto_{\mathcal{UD}} #2}
\newcommand{\judgeUDreduceTrans}[2]{#1 \longmapsto_{\mathcal{UD}}^{*} #2}
\newcommand{\judgeUDeval}[2]{eval_{\mathcal{UD}}(#1) = #2}
\newcommand{\effCEK}[1]{\ensuremath{\mathcal{S}(#1)}}
\newcommand{\evalEqv}[2]{
	\ensuremath{
		eval_{\text{#1}}(e) = o
		\;\text{if and only if}\;
		eval_{\text{#2}}(e) = o}
}
\newcommand{\continue}[2]{cont(#2,#1)}
\newcommand{\highlight}[1]{{\color{red} #1}}

% LCast
\newcommand{\lsOOcast}[3]{\cOOcast{#1}{#2}{#3}}
\newcommand{\lcOOnull}[0]{[]}
\newcommand{\lcOOcons}[2]{#1 \; :: \; #2}

% URLs
\newcommand{\urlLazyDProof}{
	\url{https://github.com/LuKC1024/hypercoercion-and-framework-wgt2020/tree/master/Proof}
}

\begin{document}

%% Title information
\title{Hypercoercions and a Framework for \\ Equivalence of Cast Calculi}

%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Kuang-Chen Lu}

\affiliation{
  \department{Computer Science Department}              
  %% \department is recommended
  \institution{Indiana University}
  %% \institution is required
  \country{United States}
  %% \country is recommended
}
\email{kl13@iu.edu}          %% \email is recommended


\author{Jeremy G. Siek}
\email{jsiek@indiana.edu}         %% \email is recommended

%\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%  \position{Position2a}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  \streetaddress{Street2a Address2a}
  %% \city{City2a}
  %% \state{State2a}
  %% \postcode{Post-Code2a}
  \country{United States}                   %% \country is recommended
}

\author{Andre Kuhlenschmidt}
\email{akuhlens@iu.edu}         %% \email is recommended
\affiliation{
  %\position{Position2b}
  \department{Computer Science Department}             %% \department is recommended
  \institution{Indiana University}           %% \institution is required
  %\streetaddress{Street3b Address2b}
  %\city{City2b}
  %\state{State2b}
  %\postcode{Post-Code2b}
  \country{United States}                   %% \country is recommended
}



%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  Designing a space-efficient cast representation that is good for
  both mechanized metatheory and implementation is
  challenging. Existing solutions (i.e. coercions, threesomes, and 
  supercoercions) are good for one or the other. This
  paper presents a new cast representation, named hypercoercions, that
  is good for both. On the way to proving the correctness of
  hypercoercions, this paper also makes progress on a general
  framework for proving the correctness of cast representations.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming 
languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming 
languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Gradual Typing, Blame, Coercion}
%% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}

Around 2006, several groups of researchers proposed ways to integrate
dynamic typing and static typing, notably gradual typing
\citep{siek2006gradual}, hybrid typing \citep{knowles2010hybrid},
migratory typing \citep{Tobin-Hochstadt:2006fk}, and multi-language
interoperability \citep{Gray:2005ij,Matthews:2007zr}. Researchers
usually define the semantics of gradually typed languages by
translation to an intermediate language with casts, such as the blame
calculus \citep{wadler2009well} and other cast calculi
\citep{siek2009exploring}. Unfortunately, straightforward
implementations of casts on higher-order values (functions, objects,
etc.) impose significant runtime overheads that can change the
asymptotic space complexity of a program
\citep{herman2010space}. There are several known space-efficient cast
representations, with various strengths and weaknesses
\citep{Siek:2015:BCT:2737924.2737968,Siek:2010:TWB:1706299.1706342,Garcia:2013:CTB:2500365.2500603,kuhlenschmidt2018efficient,siek2012interpretations,garcia2014deriving}.
The current state of the art includes

\begin{itemize}
\item threesomes 
\citep{Siek:2010:TWB:1706299.1706342,Garcia:2013:CTB:2500365.2500603},
\item supercoercions \citep{Garcia:2013:CTB:2500365.2500603}, and
\item coercions in normal form
  \citep{siek2012interpretations,Siek:2015:BCT:2737924.2737968}.
\end{itemize}
%Recall that in these systems, casts are compressed using a composition
%operator.
These systems compress casts using a compose operator.
Threesomes and supercoercions are good for mechanized
metatheory because their compose operators are structurally recursive,
making them easy to define in a proof assistant such as Agda. In
contrast, the coercions in normal form have compose operators that are
not structurally recursive, which makes it more difficult to define in
Agda, requiring what amounts to an explicit proof of termination.
%
On the other hand, coercions in normal form are easier to understand
than threesomes (with a strange labeled bottom type), and
supercoercions (10 different kinds).

This paper presents a new cast representation, named
\emph{hypercoercions}, that is good for both mechanized metatheory and
good for implementation. The composition operator for hypercoercions
is defined by structural recursion and hypercoercions are suggestive
of a bit-level representation that minimizes the need for pointers and
fits all first-order casts into 64 bits.
%
We present two flavors of hypercoercions to support the two blame
tracking strategies from the literature: D and
UD~\citep{siek2009exploring}. With the D strategy, only \textbf{d}own casts 
(casts from $\TOOdyn$ to some other types) are subject to blame. With the UD 
strategy, however, some \textbf{u}p casts are also blamable.
We are interested in the D blame
tracking strategy because it comes with a more straightforward notion of
safe cast compared to UD~\citep{siek2009exploring}, which is why D was
chosen in the Grift compiler~\citep{kuhlenschmidt2018efficient}. We are also 
interested in UD because it plays a
prominent role in the gradual typing literature
\citep{wadler2009well}.  The UD hypercoercions were inspired by the
supercoercions of \citet{Garcia:2013:CTB:2500365.2500603} (hence the name) and
the D hypercoercions were inspired by the normal forms of
\citet{siek2012interpretations}.
%
The semantics of casts can be lazy or
eager~\citep{siek2009exploring}. In this paper, we focus on lazy cast
strategies because we suspect that they are more efficient than eager
strategies and because \citet{new2019gradual} show that the eager
strategies are incompatible with $\eta$-equivalence of functions.

Of course, an alternative cast representation must be proved
correct. This paper presents steps toward a general framework for
proving equivalence of cast calculi and, in particular, proves that an
abstract machine using \lazyD{} hypercoercions is equivalent to an
abstract machine using standard \lazyD{}
casts~\citep{siek2009exploring}. We conjecture that the framework can
be generalized to \lazyUD{} and that it can be applied to coercions in
normal form, threesomes, and supercoercions.

To summarize, the primary contributions of this paper are:
\begin{itemize}
\item hypercoercions, a new cast representation, which
  has a structurally recursive composition and a memory
  representation more compact than space-efficient coercions.
\item a framework in Agda for proving the correctness of \lazyD{} cast
  representations.
\item a formal proof that \lazyD\ hypercoercions respect the semantics
  of the \lazyD{} cast calculus.
\end{itemize}

In Section~\ref{sec:background} we review cast calculi and coercions. 
We present hypercoercions in
Section~\ref{sec:hypercoercion-definition}.  We present a framework
for proving the correctness of \lazyD\ cast representations in
Section~\ref{sec:framework} and use it to prove the correctness of
\lazyD{} hypercoercions in
Section~\ref{sec:hypercoercion-correctness}.

\section{Background} \label{sec:background}

In this section, we first review lazy cast calculi
(Section~\ref{sec:cast-calculi}), where we present an abstract machine that is 
employed in our framework (Section~\ref{sec:framework}). Then we review 
coercions and their normal forms (Section~\ref{sec:coercion-calculus}), which 
motivates and inspires the design of hypercoercions 
(Section~\ref{sec:hypercoercion-definition}).

\subsection{Cast Calculi}
\label{sec:cast-calculi}

\begin{figure}
  Syntax
  \[
  \begin{array}{lrcl}
  \stxrule{T, S}{Types}{
    \star \mid{}
    P
  }
  \stxrule{P}{Pre-types}{
    \POOunit \mid
    \POOfun{T}{T} \mid
    \POOprod{T}{T} \mid
    \POOsum{T}{T}
  }
  \stxrule{e}{Terms}{
    \eOOvar{x} \mid{}
    \eOOsole{} \mid{}
    \eOOlam{T}{T}{x}{e} \mid
    \eOOapp{e}{e} \mid
    \eOOcons{T}{T}{e}{e} \mid
    \eOOcar{e} \mid
    \eOOcdr{e}
  }
  \stxrulecont{
    \eOOinl{T}{T}{e} \mid
    \eOOinr{T}{T}{e} \mid
    \eOOcase{e}{e}{e} \mid
    \eOOcast{e}{T}{l}{T} \mid
    \eOOblame{l}
  }
  \end{array}
  \]
  
  Consistency
  \fbox{$T_1 \sim T_2$}
  \begin{gather*}
  \inference{}{
    \star \sim \star
  } \quad
  \inference{}{
    \star \sim P
  } \quad
  \inference{}{
    P \sim \star
  } \\[1ex]
  \inference{}{
    \POOunit \sim \POOunit
  } \quad
  \inference{
    S_1 \sim S_2 &
    T_1 \sim T_2
  }{
    S_1 \rightarrow T_1 \sim S_2 \rightarrow T_2
  } \quad
  \inference{
    S_1 \sim S_2 &
    T_1 \sim T_2
  }{
    S_1 \times T_1 \sim S_2 \times T_2
  } \quad
  \inference{
    S_1 \sim S_2 &
    T_1 \sim T_2
  }{
    S_1 \plus T_1 \sim S_2 \plus T_2
  }
  \end{gather*}
  
  Term typing
  \fbox{$\judgetype{\Gamma}{e}{T}$}
  \begin{gather*}
          \dots \qquad
    \inference{
      \Gamma \vdash e : T_1 & T_1 \sim T_2
    }{
      \judgetype{\Gamma}{\eOOcast{e}{T_1}{l}{T_2}}{T_2}
    } \quad
    \inference{
    }{
      \judgetype{\Gamma}{\eOOblame{l}}{T}
    }
  \end{gather*}
  
  \caption{Syntax and static semantics of the cast calculi.}
  \label{fig:blame-static}
\end{figure}


\paragraph{Syntax and Static Semantics}

The syntax and static semantics are the same for the \lazyD{} and
\lazyUD{} cast calculi. They are reviewed in \figref{fig:blame-static}.
As usual, the important features are the cast expressions,
$\eOOcast{e}{T_1}{l}{T_2}$, which are responsible for runtime type
checking, and blame expressions, $\eOOblame{l}$, that raise errors. Polarities 
of blame labels is not treated but are straightforward to incorporate. 
The syntax and static semantics is the same as that of
\citet{siek2009exploring} except for a few minor exceptions:
\begin{itemize}
\item We add sum, product, and unit types.
\item We separate types into those with a type constructor at the top,
  the \emph{pretypes} ($\POOunit$, functions, products, and sums),
  versus the dynamic type $\star$ (a.k.a. $\mathtt{Dyn}$ or
  $\mathbb{?}$).
\item We annotate the type of many expressions explicitly because we 
refer to them in the dynamic semantics. These expressions include cons 
expressions, left injections, right injections, and lambda abstractions.
\end{itemize}
As usual, the source $T_1$ and target types $T_2$ of a cast
$\eOOcast{e}{T_1}{l}{T_2}$ are required to be consistent, written $T_1
\sim T_2$. The consistency relation is standard and defined in
\figref{fig:blame-static}.

\paragraph{Dynamic Semantics}

The dynamic semantics of a cast calculus is typically defined with a
reduction semantics. Here we use a CEK machine
\citep{felleisen1986control} instead because the first author is more
familiar with CEK machines and believes that a CEK machine is more
convenient to use for the space-efficient semantics in
Section~\ref{sec:framework:cek} (a major point of space-efficiency is about 
compressing continuations). So using an abstract machine for the cast calculi in
this section makes it easier to prove the correctness of the space-efficient
machines. Of course, one should prove that the abstract machine
presented here is equivalent to the standard reduction semantics for
cast calculi, but we have not yet done so.

Fig.~\ref{fig:machine-cekc} defines the transition relation of the CEK
machine and Fig.~\ref{fig:state} gives a grammar for machine states
$s$, including a definition of values $v$ and value typing. 
%Fig.~\ref{fig:state} gives a grammar for machine states
%$s$, including a definition of values and value typing and
%Fig.~\ref{fig:machine-cekc} defines the transition relation of the CEK
%machine.
The transitions involving casts are highlighted in red and described in
more detail below. The other transitions are standard for a CEK
machine for an extended simply typed lambda calculus.
%
Recall that CEK machines involve two kinds of transitions, (1) those
that dive further into an expression (looking for a redex) and push an
entry onto the continuation, and (2) those that return a value to the
current continuation and possibly perform a computation.
Corresponding to (1) and (2), the machine state is either in an evaluating
$\sOOinspect{e}{\mathcal{E}}{\kappa}$ or continuing $\sOOreturn{v}{\kappa}$ configuration, 
respectively. Additionally, there is the $\sOOhalt{o}$ configuration, where the 
machine halts with an observable ($o$). Observables include all value 
constructors, blame, and $\oOOdyn$, as in \citet{siek2012interpretations}. 
The function converting values to observables ($observe(v) = o$) is defined in 
the obvious way. 

Let $v$ range over values. A value is either the unit, a function, a pair, a 
left injection, a right injection, or a casted value. Value typing rules 
restrict the casts in casted values. If the cast is between pre-types, source 
and target types must have the same type constructor at the top ($P_1 \smile 
P_2$). If the cast is from a pre-type to the dynamic type, the pre-type must be 
injectable. The definition of injectable types depends on blame
strategies: for the \lazyD\ strategy, every pre-type is injectable;
for the \lazyUD\ strategy, a pre-types is injectable if all its sub-parts are 
the dynamic type.

The transition relation $\judgeCreduce{s}{s}$ is parameterized over
$applyCast$ to allow for the differences between D and UD.
%
When evaluating a cast expression, the machine moves the cast to the
continuation and evaluates the inner expression.
%% Other
%% transition rules starting from$Eval$states are standard.
To apply a casted function, the machine first casts $v_1$ (the operand), then
applies $v_2$ (the underlying function) to the casted operand, and then finally
casts the return value.
%
To take out the first (resp. second) part of a casted pair, the
machine firstly takes out the first (resp. second) part of $v$, the
underlying pair, and cast the result.
%
%In case splitting, if the target value is a left injection, the
%machine moves to a state that will apply the first continuation
%function to the value inside the left injection. The case for right
%injection is similar.
%
To case split a casted injection, the machine moves the cast from
the injection to continuations functions.
%
To cast a value, the machine invokes $applyCast$ on the value. If the cast 
succeeds ($\rOOsucc{v'}$), the machine returns the result to the next
continuation.  If the cast fails ($\rOOfail{l}$), the machine halts with the 
blame label.
%Let $r$ range over cast results. A cast result is either a success, which 
%brings back a value, or a failure, which brings back a blame label. 

%
%% When the continuation is $stop$, the machine enters a halting
%% state. The When the machine is in a halting state, it stays in the
%% same state.

The reflexive transitive closure of reduction ($\judgeCreduceTrans{s}{s}$) and 
evaluation ($eval_\mathcal{x}(e)$) are standard~\citep{felleisen03:_pllc}.

\begin{figure}
  Machine state and other runtime data structures
  \[
  \begin{array}{lrcl}
  \stxrule{\mathcal{E}}{Environments}{
  	\text{a partial function}\;\{\langle x , v \rangle , \dots \}
%  	\text{partial functions that map  variables to values}
  }
  \stxrule{v}{Values}{
    \vOOtt{} \mid
    \vOOfun{\mathcal{E}}{x}{e} \mid
    \vOOcons{v}{v} \mid
    \vOOinl{v} \mid
    \vOOinr{v} \mid   
    \vOOcast{v}{c}
  }
  \stxrule{c}{Casts}{
    \cOOcast{T}{l}{T}
  }
  \stxrule{I}{Injectable types (\lazyD)}{
    P
  }
  \stxrule{I}{Injectable types (\lazyUD)}{
    \POOunit \mid
    \POOfun{\star}{\star} \mid
    \star \times \star \mid
    \star + \star
  }
  \stxrule{o}{Observables}{
    \oOOdyn \mid
    \oOOsole \mid
    \oOOfun \mid
    \oOOcons \mid
    \oOOinl \mid
    \oOOinr \mid
    \oOOblame{l}
  }
  \stxrule{r}{Cast results}{
    \rOOsucc{v} \mid
    \rOOfail{l}
  }
  \stxrule{s}{States}{
    \sOOinspect{e}{\mathcal{E}}{\kappa} \mid{}
    \sOOreturn{v}{\kappa} \mid{}
    \sOOhalt{o}
  }
  \stxrule{\kappa}{Continuations}{
    \kOOmt \mid
    \kOOconsI{T}{T}{e}{\mathcal{E}}{\kappa} \mid
    \kOOconsII{T}{T}{v}{\kappa} \mid
    \kOOinl{T}{T}{\kappa}
  }
  \stxrulecont{
    \kOOinr{T}{T}{\kappa} \mid
    \kOOappI{e}{\mathcal{E}}{\kappa} \mid
    \kOOappII{v}{\kappa} \mid
    \kOOcar{\kappa}
  }
  \stxrulecont{ 
    \kOOcdr{\kappa}\mid
    \kOOcaseI{e}{e}{\mathcal{E}}{\kappa}\mid
    \kOOcaseII{v}{e}{\mathcal{E}}{\kappa}
  }
  \stxrulecont{
    \kOOcaseIII{v}{v}{\kappa} \mid
    \kOOcast{c}{\kappa}
  }
  \end{array}
  \]

        Shallow-consistency
  \fbox{$T \smile T$}
  \begin{gather*}
  \inference{}{
    \star \smile \star
  } \quad
  \inference{}{
    \star \smile P
  } \quad
  \inference{}{
    P \smile \star
  } \\
  \inference{}{
    \POOunit \smile \POOunit
  } \quad
  \inference{}{
    T_{11} \rightarrow T_{12} \smile T_{21} \rightarrow T_{22}
  } \quad
  \inference{}{
    T_{11} \times T_{12} \smile T_{21} \times T_{22}
  } \quad
  \inference{}{
  T_{11} \plus T_1 \smile S_2 \plus T_2
  }
  \end{gather*}
  
  Value typing \fbox{$v : T$}
  \begin{gather*}
  \dots \qquad
  \inference{
    v : I
  }{
    \vOOcast{v}{\cOOcast{I}{l}{\TOOdyn}} : \TOOdyn
  }
  \quad
  \inference{
    v : P_1 &
    P_1 \smile P_2
  }{
    \vOOcast{v}{\cOOcast{P_1}{l}{P_2}} : P_2
  }
  \end{gather*}
        \caption{Definition of machine state and auxiliary data
          structures.}
        \label{fig:state}
\end{figure}

%As shown by the value typing rules, if the target type of a
%value in cast is the dynamic type, the underlying value must be of an
%injectable type. The definition of injectable types depends on blame
%strategies: for the \lazyD\ strategy, every pre-type is injectable;
%for the \lazyUD\ strategy, a pre-types is injectable if and only if
%all its sub-parts are the dynamic type. If the target type of a value in cast 
%is a pre-type, the type of the underlying value must have the
%same type constructor.

\begin{figure}
  % Continuation typing \fbox{$\kappa : T_1 \Longrightarrow T_2$}
  % \begin{gather*}
  % \dots \quad
  % \inference{
  %   c : T_1 \Longrightarrow T_2 &
  %   \kappa : T_2 \Longrightarrow T_3
  % }{
  %   \langle c \rangle \kappa : T_1 \Longrightarrow T_3
  % }
  % \end{gather*}
  
  \[
  \begin{array}{rclr}
  \end{array}
  \]
  
  Transition \fbox{$\judgeCreduce{s}{s}$}
  \[
  \begin{array}{rclr}
    \hiredrule{
    \sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e}{\mathcal{E}}{
      \kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa}
%     \langle\cOOcast{T_1}{l}{T_2}\rangle\kappa
    }
  }{}
  \redrule{
    \sOOinspect{\eOOvar{x}}{\mathcal{E}}{\kappa}
  }{  
    \sOOreturn{\mathcal{E}(x)}{\kappa}
  }{}
  \redrule{
    \sOOinspect{\eOOsole}{\mathcal{E}}{\kappa}
  }{
    \sOOreturn{\vOOtt}{\kappa}
  }{}
  \redrule{
    \sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\mathcal{E}}{\kappa}
  }{
    \sOOreturn{\vOOfun{\mathcal{E}}{x}{e}}{\kappa}
  }{}
  \redrule{
    \sOOinspect{\eOOcons{T_1}{T_2}{e_1}{e_2}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e_1}{\mathcal{E}}{\kOOconsI{T_1}{T_2}{e_2}{\mathcal{E}}{\kappa}}
  }{}
  \redrule{
    \sOOinspect{\eOOinl{T_1}{T_2}{e}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e}{\mathcal{E}}{\kOOinl{T_1}{T_2}{\kappa}}
  }{}
  \redrule{
  \sOOinspect{\eOOinl{T_1}{T_2}{e}}{\mathcal{E}}{\kappa}
  }{
  \sOOinspect{e}{\mathcal{E}}{\kOOinr{T_1}{T_2}{\kappa}}
  }{}
  \redrule{
    \sOOinspect{\eOOapp{e_1}{e_2}}{\mathcal{E}}{\kappa}
  }{
\sOOinspect{e_1}{\mathcal{E}}{\kOOappI{e_2}{\mathcal{E}}{\kappa}}}{}

\redrule{
\sOOinspect{\eOOcar{e}}{\mathcal{E}}{\kappa}}{
\sOOinspect{e}{\mathcal{E}}{\kOOcar{\kappa}}}{}

\redrule{
  \sOOinspect{\eOOcdr{e}}{\mathcal{E}}{\kappa}}{
  \sOOinspect{e}{\mathcal{E}}{\kOOcdr{\kappa}}}{}

\redrule{
\sOOinspect{\eOOcase{e_1}{e_2}{e_3}}{\mathcal{E}}{\kappa}}{
\sOOinspect{e_1}{\mathcal{E}}{\kOOcaseI{e_2}{e_3}{\mathcal{E}}{\kappa}}}{}

\redrule{
\sOOinspect{\eOOblame{l}}{\mathcal{E}}{\kappa}}{
\sOOhalt{(\oOOblame{l})}}{}

\redrule{
\sOOreturn{v_1}{\kOOconsI{T_1}{T_2}{e_2}{\mathcal{E}}{\kappa}}}{
\sOOinspect{e_2}{\mathcal{E}}{\kOOconsII{T_1}{T_2}{v_1}{\kappa}}}{}

\redrule{
\sOOreturn{v_2}{\kOOconsII{T_1}{T_2}{v_1}{\kappa}}}{
\sOOreturn{\vOOcons{v_1}{v_2}}{\kappa}}{}

\redrule{
\sOOreturn{v}{\kOOinl{T_1}{T_2}{\kappa}}}{
\sOOreturn{\vOOinl{v}}{\kappa}}{}

\redrule{
\sOOreturn{v}{\kOOinr{T_1}{T_2}{\kappa}}}{
\sOOreturn{\vOOinr{v}}{\kappa}}{}

\redrule{
\sOOreturn{v_1}{\kOOappI{e_2}{\mathcal{E}}{\kappa}}}{
\sOOinspect{e_2}{\mathcal{E}}{\kOOappII{v_1}{\kappa}}}{}

\redrule{
\sOOreturn{v_2}{\kOOappII{(\vOOfun{\mathcal{E}}{x}{e})}{\kappa}}}{
\sOOinspect{e}{\mathcal{E}[x:=v_2]}{\kappa}}{}
  \hiredrule{
    \sOOreturn{v_1}{
      \kOOappII{\vOOcast{v_2}{
          \cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
      }}{\kappa}
%     (\mathtt{app_2} \; \vOOcast{v_2}{
%       \cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}
%     } \; \kappa)
    }
  }{
    \sOOreturn{v_1}{
      \kOOcast{\cOOcast{T_3}{l}{T_1}}{
        \kOOappII{v_2}{
          \kOOcast{\cOOcast{T_2}{l}{T_4}}{\kappa}
        }
      }
%     \langle\rangle
%     (\mathtt{app_2} \; v_2 \; 
%     \langle\cOOcast{T_2}{l}{T_4}\rangle \kappa}
    }
  }{}
  \redrule{
  \sOOreturn{
    \vOOcons{v_1}{v_2}
  }{\kOOcar{\kappa}}
  }{
  \sOOreturn{v_1}{\kappa}
  }{}
  \hiredrule{
    \sOOreturn{
      \vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
          \POOprod{T_3}{T_4}}}
    }{\kOOcar{\kappa}}
  }{
    \sOOreturn{v}{
      \kOOcar{
        \kOOcast{\cOOcast{T_1}{l}{T_3}}{\kappa}
      }}
  }{}
  \redrule{
  \sOOreturn{
  \vOOcons{v_1}{v_2}
  }{\kOOcdr{\kappa}}
  }{
  \sOOreturn{v_2}{\kappa}
  }{}
  
  \hiredrule{
    \sOOreturn{
      \vOOcast{v}{\cOOcast{\POOprod{T_1}{T_2}}{l}{
          \POOprod{T_3}{T_4}}}
    }{\kOOcdr{\kappa}}
  }{
    \sOOreturn{v}{
      \kOOcdr{\kOOcast{\cOOcast{T_2}{l}{T_4}}{\kappa}}}
  }{}

\redrule{
\sOOreturn{v_1}{\kOOcaseI{e_2}{e_3}{\mathcal{E}}{\kappa}}}{
\sOOinspect{e_2}{\mathcal{E}}{\kOOcaseII{v_1}{e_3}{\mathcal{E}}{\kappa}}}{}

\redrule{
\sOOreturn{v_2}{\kOOcaseII{v_1}{e_3}{\mathcal{E}}{\kappa}}}{
\sOOinspect{e_3}{\mathcal{E}}{
  \kOOcaseIII{v_1}{v_2}{\kappa}
}}{}  

\redrule{
\sOOreturn{v_3}{
  \kOOcaseIII{(\vOOinl{v})}{v_2}{\kappa}
}
}{
\sOOreturn{v}{\kOOappII{v_2}{\kappa}}
}{}

\redrule{
  \sOOreturn{v_3}{
    \kOOcaseIII{(\vOOinr{v})}{v_2}{\kappa}
  }
}{
\sOOreturn{v}{\kOOappII{v_3}{\kappa}}
}{}

\redrule{
  \highlight{\sOOreturn{v_3}{
    \kOOcaseIII{
        \vOOcast{v}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
      }{v_2}{\kappa}
  }}
}{
  \highlight{\sOOreturn{v_3'}{
      \kOOcaseIII{v}{v_2'}{\kappa}
  }}
}{\\&&
\highlight{\text{where}\;
	\kappa:T
%\kappa\;\text{is waiting for a value of type}\;T
}
\\&&
\highlight{\text{and}\;
v2' = \vOOcast{v_2}{\cOOcast{\POOfun{T_3}{T}}{l}{\POOfun{T_1}{T}}}}
\\&&
\highlight{\text{and}\;
v3' = \vOOcast{v_3}{\cOOcast{\POOfun{T_4}{T}}{l}{\POOfun{T_2}{T}}}}
}
  
  \redrule{
    \highlight{\sOOreturn{v}{
        \kOOcast{c}{\kappa}
      }}
  }{
\highlight{          
\begin{cases}
  \sOOreturn{v'}{\kappa} & \sidecond{applyCast(v,c) = \rOOsucc{v'}}
  \\
  \sOOhalt{\oOOblame{l}} & \sidecond{applyCast(v,c) = \rOOfail{l}}
\end{cases}}
  }{}
\redrule{
\sOOreturn{v}{\kOOmt}}{
\sOOhalt{observe(v)}}{}
  \end{array}
  \]  
  
  Evaluation \fbox{$\judgeCeval{e}{o}$}
  \[
  \inference{
    \judgeCreduceTrans{
      \sOOinspect{e}{\emptyset}{\hckOOmt}
    }{\sOOhalt{o}}    
  }{
    \judgeCeval{e}{o}
  }
  \]
  
  \caption{Dynamic semantics of the cast calculi as a CEK
          machine. The transitions that involve casts are highlighted
          in red.}
  \label{fig:machine-cekc}
\end{figure}

%Let $\kappa$ range over continuations. $\mathtt{stop}$ is the top 
%continuation. The remaining continuations correspond to expressions. For 
%example, $\kOOconsI{T_1}{T_2}{e}{\mathcal{E}}{\kappa}$ is the continuation 
%waiting 
%for 
%the first part of the pair. And the last continuation, $\kOOcast{c}{\kappa}$ 
%is 
%to cast the value before returning to $\kappa$.

\begin{figure}
  
  \fbox{$applyCast(v,c) = r$}
  \[
  \begin{array}{rclr}
  \funrule{
    applyCast(v,\cOOcast{\star}{l}{\star})
  }{
    \rOOsucc{v}
  }{}
  \funrule{
    applyCast(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
  }{
    applyCast(v,\cOOcast{P_1}{l_2}{P_2})
  }{}
  \funrule{
    applyCast(v,\cOOcast{P}{l}{\star})
  }{
    \rOOsucc{\vOOcast{v}{\cOOcast{P}{l}{\star}}}
  }{}
  \funrule{
    applyCast(v,\cOOcast{P_1}{l}{P_2})
  }{
    \rOOsucc{\vOOcast{v}{\cOOcast{P_1}{l}{P_2}}}
  }{\sidecond{P_1 \smile P_2}}
  \funrule{
    applyCast(v,\cOOcast{P_1}{l}{P_2})
  }{
    \rOOfail{l}
  }{\sidecond{P_1 \not\smile P_2}}
  
  \end{array}
  \]
  \caption{Definition of $applyCast$ for \lazyD}
  \label{fig:applyCast-D-C}
\end{figure}

\begin{definition}[\lazyD{} CEK Machine]
  The \lazyD{} CEK machine, written \ineffCEKD{}, is the CEK machine of
  \figref{fig:machine-cekc} using the $applyCast$ for \lazyD{} defined
  in \figref{fig:applyCast-D-C}.  We write the transition relations of
  this machine as $\judgeDreduce{s}{s}$ and $\judgeDreduceTrans{s}{s}$
  and write the evaluation function as $\judgeDeval{e}{o}$.
\end{definition}

We conjecture that \ineffCEKD{} agrees with the \lazyD{} cast calculus
of \citet{siek2009exploring}.

Next, we define the CEK Machine for \lazyUD{}. The only difference with
respect to \lazyD{} is in the definition of the $\mathit{applyCast}$
function, in which a cast whose source or target is the dynamic type
$\star$ is always split into two casts that go through an injectable
type, that is, a type in which all sub-components are the dynamic
type, such as $\star \to \star$.


\begin{definition}[\lazyUD{} CEK Machine]
  The \lazyUD{} CEK machine, written \ineffCEKUD{}, is the CEK machine of
  \figref{fig:machine-cekc} using the $applyCast$ for \lazyUD{} defined
  in \figref{fig:apply-Cast-UD}.  We write the transition relations of
  this machine as $\judgeUDreduce{s}{s}$ and $\judgeUDreduceTrans{s}{s}$
  and write the evaluation function as $\judgeUDeval{e}{o}$.
\end{definition}


\begin{figure}
  \fbox{$\mathit{applyCast}(v,c) = r$}
  \[
  \begin{array}{rclr}
    \mathit{applyCast}(v, \cOOcast{\star}{l}{\star} ) &=& \rOOsucc{v} \\
    \mathit{applyCast}(v, \cOOcast{P}{l}{\star}) &=&
        \rOOsucc{v \langle \cOOcast{P}{l}{I} \rangle
                   \langle \cOOcast{I}{l}{\star} \rangle}
        & \text{if } I \sim P, I \neq P \\  
    \mathit{applyCast}(v, \cOOcast{\star}{l}{P}) &=&          
        \rOOsucc{v \langle \cOOcast{\star}{l}{I} \rangle
                   \langle \cOOcast{I}{l}{P} \rangle}
        & \text{if } I \sim P, I \neq P \\  
  \mathit{applyCast}(v \langle \cOOcast{I}{l}{\star} \rangle , \cOOcast{\star}{l}{I}) &=& \rOOsucc{v} \\
  \mathit{applyCast}(v \langle \cOOcast{I_1}{l}{\star} \rangle , \cOOcast{\star}{l}{I_2}) &=& \rOOfail{l} & \text{if } I_1 \neq I_2 \\
  \mathit{applyCast}(v, \cOOcast{P_1}{l}{P_2}) &=&
           \rOOsucc{v \langle \cOOcast{P_1}{l}{P_2} \rangle}
          & \text{if } P_1 \smile P_2
  \end{array}
  \]

  \caption{Definition of \textit{applyCast} for \lazyUD{}.}
  \label{fig:apply-Cast-UD}
\end{figure}

We conjecture that \ineffCEKUD{} agrees with the \lazyUD{} cast
calculus of \citet{siek2009exploring}.

\subsection{Coercions and Normal Forms} 
\label{sec:coercion-calculus}

In this section, we review the
coercions~\citep{henglein1994dynamic,herman2010space} and the normal form of
\citet{siek2012interpretations} to motivate the design of hypercoercions.  We
omit sum types and product types in this section because
\citet{siek2012interpretations} did not discuss them. We assume a basic
familiarity with coercions, and suggest that readers unfamiliar with coercions
to familiarize themselves with \citet{siek2012interpretations} and
\citet{Siek:2015:BCT:2737924.2737968}.

\begin{figure}
  \[
  \begin{array}{lrcl}
  \stxrule{I}{Injectable types (\lazyD)}{
    \POOfun{T}{T} \mid \POOunit}
  \stxrule{I}{Injectable types (\lazyUD)}{
    \POOfun{\TOOdyn}{\TOOdyn} \mid \POOunit
  }
  \stxrule{c}{Coercions}{
    \ncInj{I} \mid
    \ncProj{I}{l} \mid
    \ncId \mid
    \ncFail{l} \mid
    \ncSeq{c}{c} \mid
    \ncFun{c}{c}
  }
\stxrule{\hat{c}}{normal coercions}{
  \ncFun{\hat{c}}{\hat{c}} \mid
  \ncSeq{\ncProj{I}{l}}{\ncFun{\hat{c}}{\hat{c}}} \mid
  \ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}} \mid
  \ncSeq{\ncProj{I}{l}}{\ncSeq{\ncFun{\hat{c}}{\hat{c}}}{\ncInj{I}}} \mid
  \ncSeq{\ncProj{I}{l}}{\ncFail{l}}
}
\stxrulecont{
  \ncId \mid
  \ncProj{I}{l} \mid
  \ncInj{I} \mid
  \ncSeq{\ncProj{I}{l}}{\ncInj{I}} \mid
  \ncFail{l} 
}
  \end{array}
  \]
  \caption{Syntax of coercions and normal forms {\`a} la \citet{siek2012interpretations}.}
  \label{fig:normal-coercion}
\end{figure}

\figref{fig:normal-coercion} reviews the grammar for coercions,
written $c$.
%
To review, an injection $I!$ takes a value from an injectable type
$I$ to type $\TOOdyn$. An injectable type is simply a type that can be
cast directly to and from $\TOOdyn$. The
definition of injectable types depends on the blame strategy. With \lazyD,
all pre-types are injectable. With \lazyUD, only
$\POOfun{\TOOdyn}{\TOOdyn}$ and $\POOunit$ are injectable.
%
A projection $I?^l$ takes a value from type $\TOOdyn$ to type $I$, or
halts the program and blames $l$ if the value is of a different type.
The coercion $\iota$ is the identity, $\bot^{l}$ is the coercion that
always fails and blames $l$, and $(\ncSeq{c_1}{c_2})$ applies $c_1$ and
then $c_2$ in sequence. The function coercion $\ncFun{c_1}{c_2}$
applies $c_1$ to the argument of a function and $c_2$ to the return
value.

Coercions come with a reduction relation so it is natural to ask about
their normal forms. \figref{fig:normal-coercion} defines the syntax of
coercion in normal form, written $\hat{c}$. Conceptually, a coercion
in normal form has three parts, all of which are optional.  It may
start with a projection $I?^l$, followed by a function coercion, and
then concluded with an injection $I!$ or a failure $\bot^l$. While
this is a simple idea, there are 10 clauses in the definition for
$\hat{c}$!

%% Let $\bar{c}$ range over wrapper coercions, which represent casts in $
%% \vOOcast{v}{c}$.  Let $\hat{c}$ range over normal coercions. If we
%% inline $\bar{c}$ and re-order the cases, the definition of $\hat{c}$
%% becomes:
%% \[
%% \begin{array}{rclr}
%% \end{array}
%% \]

%% Three observables on this definition leads to hypercoercion: 
%% \begin{enumerate}
%%  \item The length of normal coercion is at most three.
%%  \item Projections are always at the beginning when present.
%%  \item Injections and failures are always at the end when present.
%% \end{enumerate}


\section{Definition of Hypercoercions} \label{sec:hypercoercion-definition}

\begin{figure}
  Syntax of Hypercoercions
  \[
  \begin{array}{lrcl}
  \stxrule{I}{Injectable types (\lazyD)}{P}
  \stxrule{I}{Injectable types (\lazyUD)}{
    \POOunit \mid
    \POOfun{\TOOdyn}{\TOOdyn} \mid
    \POOprod{\TOOdyn}{\TOOdyn} \mid
    \POOsum{\TOOdyn}{\TOOdyn}
  }
  \stxrule{c}{Hypercoercions}{
    \hyperCoercionI \mid{}
    \hyperCoercionC{h}{m}{t}
  }
  \stxrule{h}{Heads}{
    \epsilon \mid{}
    ?^l
  }
  \stxrule{m}{Middles}{
    \POOunit \mid
    \POOfun{c}{c} \mid
    \POOprod{c}{c} \mid
    \POOsum{c}{c}
  }
  \stxrule{t}{Tails}{
    \epsilon \mid{}
    ! \mid{}
    \bot^l
  }
  \end{array}
  \]
    
  Hypercoercion typing \fbox{$c : T \Longrightarrow T$}
  \begin{gather*}
  \inference{}{\typingHC{\hyperCoercionI}{\TOOdyn}{\TOOdyn}}
  \quad
  \inference{
    \typingHC{h}{T_1}{P_1} &
    \typingHC{m}{P_1}{P_2} &
    \typingHC{t}{P_2}{T_2}
  }{
    \typingHC{\hyperCoercionC{h}{m}{t}}{T_1}{T_2}
  }
  \end{gather*}
  
  Head typing \fbox{$\typingHC{h}{T}{P}$}
  \begin{gather*}
  \inference{}{\typingHC{\epsilon}{P}{P}}
  \quad
  \inference{}{\typingHC{?^l}{\TOOdyn}{I}}
  \end{gather*}
  
  Middle typing \fbox{$\typingHC{m}{T}{T}$}
  \begin{gather*}
  \inference{}{\typingHC{\POOunit}{\POOunit}{\POOunit}}
  \quad
  \inference{
    \typingHC{c_1}{T_3}{T_1} &
    \typingHC{c_2}{T_2}{T_4}
  }{
    \typingHC{\POOfun{c_1}{c_2}}{\POOfun{T_1}{T_2}}{\POOfun{T_3}{T_4}}
  }
  \\
  \inference{
    \typingHC{c_1}{T_1}{T_3} &
    \typingHC{c_2}{T_2}{T_4}
  }{
    \typingHC{\POOprod{c_1}{c_2}}{\POOprod{T_1}{T_2}}{\POOprod{T_3}{T_4}}
  }
  \quad
  \inference{
    \typingHC{c_1}{T_1}{T_3} &
    \typingHC{c_2}{T_2}{T_4}
  }{
    \typingHC{\POOsum{c_1}{c_2}}{\POOsum{T_1}{T_2}}{\POOsum{T_3}{T_4}}
  }
    \end{gather*}
    
    Tail typing \fbox{$\typingHC{t}{P}{T}$}
    \begin{gather*}
    \inference{}{\typingHC{\epsilon}{P}{P}} \quad
    \inference{}{\typingHC{!}{I}{\TOOdyn}} \quad
    \inference{}{\typingHC{\bot^l}{P}{T}} \quad
    \end{gather*}
  
  \caption{Definition of hypercoercions (HC)}
  \label{fig:hypercoercion}
\end{figure}

This section presents our first contribution, the definition of
hypercoercions.  The design of hypercoercions is motivated by the
observation that a normal coercion has at most three
parts. Hypercoercions make this structure explicit: a hypercoercion $c$ is
either $\hyperCoercionI$, the identity cast for $\TOOdyn$, or it contains
three parts: a head, middle, and tail, as defined in
\figref{fig:hypercoercion}.
\begin{itemize}
\item The head $h$ is either a projection or the no-op,
\item the middle $m$ involves coercions that preserve a type
  constructor, i.e., coercions between function, pair, sum types, and
  unit types, and
\item the tail $t$ is either an injection, a failure, or the no-op.
\end{itemize}
There is a close correspondence between middle coercions and type
constructors.  We generalize shallow-consistency to middles $m \smile
m$ in the obvious way.

Subsection~\ref{sec:ld-hc} defines the $id$, $seq$, and $cast$
functions that construct
\lazyD\ hypercoercions. Subsection~\ref{sec:lud-hc} defines
\lazyUD\ counterparts.  The functions that apply hypercoercions to
values are defined later in
Section~\ref{sec:hypercoercion-correctness}, after we introduce the framework 
and its new space-efficient definition of values in Section~\ref{sec:framework}.

\subsection{\lazyD{} Hypercoercions}
\label{sec:ld-hc}

\begin{figure}
  \[
  \begin{array}{lrcl}
  \stxrule{\ell}{Optional labels}{\epsilon \mid l}
  \end{array}
  \]
  
  Composition of hypercoercions \fbox{$c \fatsemi^\ell c = c$}
  \[ 
  \begin{array}{rclclr}
  
  \comprule{
    \hyperCoercionI
  }{
    \hyperCoercionI
  }{
    \hyperCoercionI
  }{}
  
  \comprule{
    \hyperCoercionI
  }{
    \hyperCoercionC{?^{l'}}{m}{t}
  }{
    \hyperCoercionC{?^{l'}}{m}{t}
  }{}
  
  \comprulel{
    \hyperCoercionI
  }{
    \hyperCoercionC{\epsilon}{m}{t}
  }{
    \hyperCoercionC{?^{l}}{m}{t}
  }{}
  
  \comprule{
    \hyperCoercionC{h}{m}{\bot^{l'}}
  }{
    c
  }{
    \hyperCoercionC{h}{m}{\bot^{l'}}
  }{}
  
  \comprule{
    \hyperCoercionC{h}{m}{t}
  }{
    \hyperCoercionI
  }{
    \hyperCoercionC{h}{m}{!}
  }{
    \sidecond{\forall l. t \neq \bot^{l}}
  }
  
  \comprule{
    \hyperCoercionC{h_1}{m_1}{t_1}
  }{
    \hyperCoercionC{?^l}{m_2}{t_2}
  }{
    \hyperCoercionC{h_1}{m_1}{\bot^l}
  }{
    \sidecond{
       m_1 \not\smile m_2
      \; \text{and} \;
      \forall l. t_1 \neq \bot^{l}
    }
  }

\comprulel{
\hyperCoercionC{h_1}{m_1}{t_1}
}{
\hyperCoercionC{\epsilon}{m_2}{t_2}
}{
\hyperCoercionC{h_1}{m_1}{\bot^l}
}{
\sidecond{
  m_1 \not\smile m_2
  \; \text{and} \;
  \forall l. t_1 \neq \bot^{l}
}
}
\comprule{
\hyperCoercionC{h_1}{m_1}{t_1}
}{
\hyperCoercionC{?^l}{m_2}{t_2}
}{
\hyperCoercionC{h_1}{m_1 \fatsemi^{l} m_2}{t_2}
}{
\sidecond{
  m_1 \smile m_2
  \; \text{and} \;
  \forall l. t_1 \neq \bot^{l}
}
}
  \comprule{
    \hyperCoercionC{h_1}{m_1}{t_1}
  }{
    \hyperCoercionC{\epsilon}{m_2}{t_2}
  }{
    \hyperCoercionC{h_1}{m_1 \fatsemi^{\ell} m_2}{t_2}
  }{
    \sidecond{
      m_1 \smile m_2
      \; \text{and} \;
      \forall l. t_1 \neq \bot^{l}
    }
  }
  \end{array}
  \]
  
  Composition of middles \fbox{$m \fatsemi^\ell m = m$}
  \[ 
  \begin{array}{rclclr}
  \comprule{\POOunit}{\POOunit}{
    \POOunit
  }{}
  \comprule{\POOfun{c_1}{c_2}}{\POOfun{c_3}{c_4}}{
    \POOfun{c_3 \fatsemi^{\ell} c_1}{c_2 \fatsemi^\ell c_4}
  }{}
  \comprule{\POOprod{c_1}{c_2}}{\POOprod{c_3}{c_4}}{
    \POOprod{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4}
  }{}
  \comprule{\POOsum{c_1}{c_2}}{\POOsum{c_3}{c_4}}{
    \POOsum{c_1 \fatsemi^\ell c_3}{c_2 \fatsemi^\ell c_4}
  }{}
  \end{array}
  \]
  
  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
  \funrule{seq(c_1,c_2)}{
    c_1 \fatsemi^\epsilon c_2
  }{}
  \end{array}
  \]
  
  \fbox{$id( P ) = m$}
  \[
  \begin{array}{rclr}
  \funrule{id(\POOunit)}{\POOunit}{}
  \funrule{id(\POOfun{T_1}{T_2})}{
    \POOfun{id(T_1)}{id(T_2)}
  }{}
  \funrule{id(\POOprod{T_1}{T_2})}{
    \POOprod{id(T_1)}{id(T_2)}
  }{}
  \funrule{id(\POOsum{T_1}{T_2})}{
    \POOsum{id(T_1)}{id(T_2)}
  }{}
  \end{array}
  \]
  
  \fbox{$id( T ) = c$}
  \[
  \begin{array}{rclr}
  \funrule{id(\star)}{
    \hyperCoercionI
  }{}
  \funrule{id(P)}{
    \hyperCoercionC{\epsilon}{id(P)}{\epsilon}
  }{}
  \end{array}
  \]
  
  \fbox{$cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
  \funrule{cast(T_1,l,T_2)}{
    id(T_1) \fatsemi^l id(T_2)
  }{}
  \end{array}
  \]
  \caption{\lazyD{} Hypercoercions}
  \label{fig:HC-D}
\end{figure}

\figref{fig:HC-D} defines the functions $id$, $seq$, and $cast$ that construct
\lazyD{} hypercoercions. We use these functions to satisfy the Cast abstract
data type defined in Section~\ref{sec:framework}. \figref{fig:HC-D} also defines
some auxiliary functions.

The $seq$ operator is defined in terms of coercion composition, which
is the key to compressing coercions and maintaining space-efficiency.
A composition operator for coercions typically requires the target
type of the first coercion to match the source type of the second.
However, it is useful to relax this restriction for the D blame
tracking strategy.
%
We shall need optional blame labels, written $\ell$ , that range over
$\epsilon$ or $l$. The label is mandatory when the target
type of the first coercion does not match the source type of the second. 
Then we write the composition of hypercoercions as $c_1
\fatsemi^\ell c_2$.  When both $c_1$ and $c_2$ are $\hyperCoercionI$,
their composition is also $\hyperCoercionI$.  If the head of $c_2$ is
a projection, the result is $c_2$.  Otherwise, we need a label to
build the projection. Since the head of $c_2$ is the no-op, its
source type must be a pretype. Thus we know $\ell$ must be a label and
we put it in the projection. When $c_1$ ends with a failure, the
composition is $c_1$ itself. In all the remaining cases, $c_1$ does
not end with a failure.  When $m_1$ and $m_2$ have different top
constructors ($m_1 \not\smile m_2$), the result is a failure coercion,
which needs a label. When $c_2$ starts with a projection, we blame the 
projection for casting a value to a shallowly inconsistent type. When $c_2$
starts with the no-op, we know $\ell$ must be a label, which is blamed for
composing shallowly inconsistent hypercoercions. The last two cases
compose $m_1$ and $m_2$ with the auxiliary function $m \fatsemi^\ell
m$, which assumes its inputs have the same top constructor. The
definition of $m \fatsemi^\ell m$ is a straightforward structural
recursion. Going back to the last two cases of $c_1 \fatsemi^\ell
c_2$. When $c_2$ starts with a projection, we do not know whether the
target type of $m_1$ matches the source of $m_2$. So we use the $l$ in the 
projection to  compose the middles $m_1 \fatsemi^l m_2$. When $c_2$ starts with 
the no-op, we compose the middles using $\ell$.

The definitions of $id(T)$ and $cast(T_1,l,T_2)$ are straightforward,
although $cast(T_1,l,T_2)$ is unusual in its use of $id$ and
composition.

A proof of correctness for hypercoercions (in 
Section~\ref{secc:framework:monoid-correct}) relies on the following
two basic properties of hypercoercions.

\begin{proposition}[\lazyD{} Hypercoercions Form a Monoid]
  \label{thm:LazyD-HC-monoid}
  For all $c : T_1 \Longrightarrow T_2$,
  $c_1 : T_1 \Longrightarrow T_2$,
  $c_2 : T_2 \Longrightarrow T_3$, and
  $c_3 : T_3 \Longrightarrow T_4$,
  \begin{enumerate}
    \item $seq(id(T_1),c) = c$,
    \item $seq(c,id(T_2)) = c$, and
    \item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Part (1) and (2) are by induction on $c$. Part (3) is by induction
  on $c_2$ and case analysis on $c_1$ then $c_3$.
\end{proof}

\begin{proposition}[\lazyD{} Identity Casts]
	\label{thm:LazyD-HC-identity-casts}
  For all $T$ and $l$, $cast(T,l,T) = id(T) $
\end{proposition}
\begin{proof}
  By induction on $T$.
\end{proof}

\subsection{\lazyUD{} Hypercoercions}
\label{sec:lud-hc}

Hypercoercions for the UD blame tracking strategy have the same syntax
as for D (\figref{fig:hypercoercion}), but the definitions of $id$,
$cast$, and $seq$, differ from D.  Again, the $seq$ operator
(Figure~\ref{fig:HC-UD}) is defined in terms of composition, but here
composition $c_1 \fatsemi c_2$ makes the usual assumption that the
target type of $c_1$ matches the source type of $c_2$.  The definition
of composition for UD is particularly straightforward. The first two
lines say that $\hyperCoercionI$ acts as the identity on both the left
and right. The third line handles the case when both the tail of $c_1$
and the head of $c_2$ are no-ops, in which case the middles types
$m_1$ and $m_2$ are composed via an auxiliary composition
operator. This compose operator for middle coercions assumes that its
inputs are shallowly consistent.  The fourth line handles the
important case when the tail of $c_1$ is an injection and the head of
$c_2$ is a projection. If the two middle coercions are shallowly
consistent, then they can be composed. If not, the tail of the result
is a failure coercion with the projection's label.  The last line
handles the case when the tail of $c_1$ is a failure, in which case
the result of composition is $c_1$.


The definition of $id$ is straightforward (Figure~\ref{fig:HC-UD}) .

\begin{figure}
  Composition of hypercoercions \fbox{$c \fatsemi c = c$}
  \[
  \begin{array}{rclclr}
  c &\fatsemi& \hyperCoercionI{} &=& c\\
  \hyperCoercionI{} &\fatsemi& \hyperCoercionC{h_2}{m_2}{t_2} &=&
       \hyperCoercionC{h_2}{m_2}{t_2} \\
  \hyperCoercionC{h_1}{m_1}{\epsilon} &\fatsemi& 
  \hyperCoercionC{\epsilon}{m_2}{t_2} &=&
       \hyperCoercionC{h_1}{m_1 \fatsemi m_2}{t_2} \\
  \hyperCoercionC{h_1}{m_1}{!} &\fatsemi& \hyperCoercionC{?^l}{m_2}{t_2} &=&
  \begin{cases}
    \hyperCoercionC{h_1}{m_1 \fatsemi m_2}{t_2} & \text{if } m_1 \smile m_2 \\
    \hyperCoercionC{h_1}{m_1}{\bot^l} & \text{otherwise}
  \end{cases} \\
  \hyperCoercionC{h_1}{m_1}{\bot^l} &\fatsemi& \hyperCoercionC{h_2}{m_2}{t_2} 
  &=&
     \hyperCoercionC{h_1}{m_1}{\bot^l}
  \end{array}
  \]
  Composition of middles \fbox{$m \fatsemi m = m$}
  \[
  \begin{array}{rclclr}  
  \POOunit &\fatsemi& \POOunit &=& \POOunit \\
  c \to d &\fatsemi& c' \to d' &=& (c' \fatsemi c) \to (d \fatsemi d') \\
  c \times d &\fatsemi& c' \times d' &=& (c \fatsemi c') \times (d \fatsemi d') \\
  c + d &\fatsemi& c' + d' &=& (c \fatsemi c') + (d \fatsemi d')
  \end{array}
  \]
  Shallow consistency of middles \fbox{$m \smile m$}
  \[
  \POOunit \smile \POOunit \quad
  (c \to d) \smile (c' \to d') \quad
  (c \times d) \smile (c' \times d') \quad
  (c + d) \smile (c' + d')
  \]

  \fbox{$seq(c,c) = c$}
  \[
  \begin{array}{rclr}
    \funrule{seq(c_1,c_2)}{
      c_1 \fatsemi c_2
    }{}
  \end{array}
  \]
  
  \fbox{$id( P ) = m$}
  \[
  \begin{array}{rclr}
    \funrule{id(\POOunit)}{\POOunit}{}
    \funrule{id(\POOfun{T_1}{T_2})}{
    \POOfun{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOprod{T_1}{T_2})}{
    \POOprod{id(T_1)}{id(T_2)}
    }{}
    \funrule{id(\POOsum{T_1}{T_2})}{
    \POOsum{id(T_1)}{id(T_2)}
    }{}
  \end{array}
  \]
  
  \fbox{$id( T ) = c$}
  \[
  \begin{array}{rclr}
    \funrule{id(\star)}{
    \hyperCoercionI
    }{}
    \funrule{id(P)}{
    \hyperCoercionC{\epsilon}{id(P)}{\epsilon}
    }{}
  \end{array}
  \]
  \caption{Lazy UD Hypercoercions}
  \label{fig:HC-UD}
\end{figure}




\begin{figure}
  \fbox{$\mathit{castToDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castToDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castToDyn}(P,l) &=&
      \hyperCoercionC{\epsilon}{m}{!} \\
    && \text{where } m = \mathit{castToInj}(P,l,\mathit{ground}(P)) 
  \end{array}
  \]
  \fbox{$\mathit{castFromDyn}(P,l) = c$}
  \[
  \begin{array}{rclr}
    \mathit{castFromDyn}(\star,l) &=& \hyperCoercionI{} \\
    \mathit{castFromDyn}(P,l) &=& \hyperCoercionC{?^l}{m}{\epsilon} \\
    && \text{where } m = \mathit{castFromInj}(\mathit{ground}(P),l,P) 
  \end{array}
  \]
  \fbox{$\mathit{castToInj}(P,l,I) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castToInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castToInj}(T_1 \to T_2,l, \star \to \star) &=&
        \mathit{castFromDyn}(T_1,l) \to \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 \times T_2,l, \star \times \star) &=&
        \mathit{castToDyn}(T_1,l) \times \mathit{castToDyn}(T_2,l) \\
    \mathit{castToInj}(T_1 + T_2,l, \star + \star) &=&
        \mathit{castToDyn}(T_1,l) + \mathit{castToDyn}(T_2,l) \\
  \end{array}
  \]
  
  \fbox{$\mathit{castFromInj}(I,l,P) = m$}
  \[
  \begin{array}{rclr}
    \mathit{castFromInj}(\POOunit,l,\POOunit) &=& \POOunit \\
    \mathit{castFromInj}(\star \to \star,l, T_1 \to T_2) &=&
        \mathit{castToDyn}(T_1,l) \to \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star \times \star,l, T_1 \times T_2) &=&
        \mathit{castFromDyn}(T_1,l) \times \mathit{castFromDyn}(T_2,l) \\
    \mathit{castFromInj}(\star + \star,l, T_1 + T_2) &=&
        \mathit{castFromDyn}(T_1,l) + \mathit{castFromDyn}(T_2,l) \\
  \end{array}
  \]

  
  \fbox{$cast(T,l,T) = c$}
  \[
  \begin{array}{rclr}
    \funrule{cast(\star,l,T_2)}{ castFromDyn(T_2, l) }{} 
    \funrule{cast(T_1,l,\star)}{ castToDyn(T_1, l) }{} 
    \funrule{cast(\POOunit,l,\POOunit)}{
        \hyperCoercionC{\epsilon}{\POOunit}{\epsilon} }{} 
    cast(T_1 \to T_2,l, T_3 \to T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \to
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_3, l, T_1) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 \times T_2,l, T_3 \times T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        \times
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)\\
    cast(T_1 + T_2,l, T_3 + T_4) &=&
      \hyperCoercionC{\epsilon}{
         c_1
        +
         c_2
      }{\epsilon}
      \quad \text{where } c_1 = cast(T_1, l, T_3) \\
      &&  \qquad\qquad\qquad \text{and } c_2 = cast(T_2, l, T_4)
  \end{array}
  \]

  \caption{\textit{cast} and its auxiliary functions for Lazy UD.}
  \label{fig:HC-UD-cast}
\end{figure}


\begin{proposition}[\lazyUD{} Hypercoercions Form a Monoid]
  For all $c : T_1 \Longrightarrow T_2$,
  $c_1 : T_1 \Longrightarrow T_2$,
  $c_2 : T_2 \Longrightarrow T_3$, and
  $c_3 : T_3 \Longrightarrow T_4$,
  \begin{enumerate}
    \item $seq(id(T_1),c) = c$,
    \item $seq(c,id(T_2)) = c$, and
    \item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  See the Agda proof at the following URL:
  
  \url{https://github.com/jsiek/gradual-typing-in-agda/blob/master/HyperCoercions.agda}
  
\end{proof}

The $cast$ function is defined in Figure~\ref{fig:HC-UD-cast}.  Prior
presentations of this function do not use auxiliary functions, as we
do here. The reason that we introduce the auxiliary functions
$\mathit{castToDyn}$, $\mathit{castFromDyn}$, $\mathit{castToInj}$,
and $\mathit{castFromInj}$, is to ensure that each of them is
structurally recursive, which makes them straightforward to define in
Agda.

\begin{proposition}[\lazyUD{} Identity Casts]
  For all $T$ and $l$, $cast(T,l,T) = id(T) $
\end{proposition}
\begin{proof}
  By induction on $T$.
\end{proof}


\subsection{Compact Representation of Hypercoercions}

Hypercoercions enable a bit-level representation that is particularly
compact for the most common-case coercions. The most frequent
coercions are injections and projections to base types (here
$\POOunit$ is the only base type, but in a real language the base
types would include integers, Booleans, etc.) and identity coercions.
Values of base types are often stored in CPU registers, so it would be
nice for coercions on base types to also fit in registers, that is, in
64 bits, so that applying a coercion to a value would not require
access to main memory, which is an order of magnitude slower than
accessing registers on a modern CPU.
%
Coercions involving non-base types, such as function types,
may be arbitrarily large, so in those cases, the hypercoercion
representation can be a pointer to a heap-allocated structure.  Here
is a sketch for the bit-level representation for hypercoercions.

\begin{itemize}
\item 1 bit to differentiate between $\hyperCoercionI$
  and three-part coercions.

\item 1 bit to differentiate between middle coercions of base type
  versus non-base type.

\item If the middle is of non-base type, then 61 bits represent a
  pointer to a heap-allocated structure. Heap allocated structures are
  usually 8-byte aligned, so there are 3 unused bits in a pointer.

\item If the middle is of base types, then the remaining 62 bits are
  used to represent the head (25 bits), middle (11 bits), and tail (26
  bits).
  \begin{itemize}
  \item The head requires 1 bit to differentiate between $\epsilon$
    and $?^l$ and then 24 bits could be used for the label $l$.
  \item The middle would use 11 bits to differentiate all the base types.
  \item The tail requires 2 bits to differentiate between $\epsilon$,
    $!$, and $\bot^l$, and could use 24 bits for the label $l$.
  \end{itemize}
  The bits for blame labels represent an index into a table of blame information.
  In the event that a program requires too many blame labels, then the implementation
  can fallback to using the heap-allocated structure for more
  coercions.
\end{itemize}
  

\section{A framework for proving correctness of cast representations}
\label{sec:framework}

This section presents our second contribution, a framework for proving
the correctness of cast representations, especially space-efficient
ones. Section~\ref{sec:hypercoercion-correctness} applies this
framework to prove the correctness of the \lazyD{} hypercoercions.

The framework includes an abstract data type named Cast ADT 
(Section~\ref{sec:framework:adt}), and a CEK machine \effCEK{C} that is 
parameterized over Cast ADTs (Section~\ref{sec:framework:cek}). This machine is 
space-efficient provided that the Cast ADT implementation performs compression. 
We conjecture that all cast representations defined in the literature
are instances of this ADT. The framework is available at the following URL:
\[\text{\urlLazyDProof}\]

%We start by defining a CEK machine \effCEK{C} that is parameterized
%over the cast representation $C$
%(Section~\ref{sec:framework:cek}). This machine is space-efficient
%provided that the cast representation performs compression.  The
%interface between the machine and the cast representation is defined
%by an abstract data type, named Cast ADT, that we define shortly 
%(Section~\ref{sec:framework:adt}).  We
%conjecture that all cast representations defined in the literature
%are instances of this ADT.

In Section~\ref{secc:framework:monoid-correct} we prove that, for any
instance $C$ of the Cast ADT, if $C$ satisfies a more refined abstract
data type for Lazy D casts, then \effCEK{C} is equivalent to
\ineffCEKD{}, that is,
\[
  \evalEqv{\effCEK{C}}{\ineffCEKD}
\]
We conjecture that all of the cast representations in the literature
for \lazyD{} (supercoercions, coercions in normal form, threesomes)
are instances of the Lazy D Cast ADT.  We are working on a similar
theorem for \lazyUD{} cast representations.

We then apply this framework to \lazyD{} hypercoercions $H$
(Section~\ref{sec:hypercoercion-correctness}), where we show that $H$
is an instance of the Lazy D Cast ADT, and therefore
\[
  \evalEqv{\effCEK{H}}{\ineffCEKD}
\]

Before turning to the definition of the abstract data types, we first
give the definition of values and cast results used by the \effCEK{C}, as they 
are mentioned in the definition of the ADTs. The $\hcvOOinj{I}{v}$ stands for 
values that are cast to the dynamic type, as in \citet{wadler2009well}.

\begin{definition}[Values and cast results for the \effCEK{C} machine] 
\label{def:values-effCEK}
  \[
  \begin{array}{lrcl}
  \stxrule{v}{Values}{
    \hcvOOtt \mid
    \hcvOOfun{c}{\mathcal{E}}{x}{e}{c} \mid
    \hcvOOcons{v}{c}{v}{c} \mid
    \hcvOOinl{v}{c} \mid
    \hcvOOinr{v}{c} \mid
    \hcvOOinj{I}{v}
  }
\stxrule{r}{Cast results}{
  \rOOsucc{v} \mid
  \rOOfail{l}
}
\stxrule{\mathcal{E}}{Environments}{
	\text{a partial function}\;\{\langle x , v \rangle , \dots \}
}

  \end{array}
  \]
\end{definition}

Let $v$ range over values. In \ineffCEK{} we have one value
constructor for all casted values.  In \effCEK{C}, however, we do not
have this generic value constructor, instead, we push casts into the ordinary 
values. Thus non-casted values in \ineffCEK\ correspond to values in 
\effCEK{C} where casts are identities. For instance, $(\vOOcons{v_1}{v_2})$ 
corresponds to $(\hcvOOcons{v_1'}{id(T_1)}{v_2'}{id(T_2)})$.

%\hcvOOcons{v_1}{c_1}{v_3}{c_2} \approx v_2 : \POOprod{T_1}{T_2} \\
%c_1' = seq(c_1,cast(T_1,l,T_3)) \\
%c_2' = seq(c_2,cast(T_2,l,T_4))
%}{
%\hcvOOcons{v_1}{c_1'}{v_3}{c_2'} \approx
%\vOOcast{v_2}{\cOOcast{\POOprod{T_1}{T_2}}{l}{\POOprod{T_3}{T_4}}}
%: \POOprod{T_3}{T_4}
%}

Cast results ($r$) and environments ($\mathcal{E}$) are the same as for 
\ineffCEK. 
Value typing ($\judgeType{v}{T}$) is defined in the obvious way.

\subsection{The Cast Abstract Data Types}
\label{sec:framework:adt}

The \emph{Cast Abstract Data Type}, defined below, captures the set of
operators that a cast representation $C$ must provide for it to be
used with the \effCEK{C} machine.  The first three operators enable
\effCEK{C} to construct casts so we call them \textit{cast
  constructors}. The fourth and last operator enables \effCEK{C} to
apply casts to values.

\begin{definition}[Cast Abstract Data Type (Cast ADT)]
  \label{def:cast-rep}
  A cast abstract data type is a set $Cast$, which is indexed by two types, 
  with four operators:
  \begin{description}
  \item[$id(T)=c$] constructs an identity cast from a type
  \item[$seq(c,c)=c$] composes two casts
  \item[$cast(T,l,T)=c$] constructs a cast from a source type, a label, and a 
  target type
  \item[$applyCast(v,c)=r$] applies a cast to a value, producing a cast result
  \end{description}
  We use the syntax $c : T_1 \Longrightarrow T_2$ to mean $c$ is in the set $Cast \; T_1 \; T_2$
  and we say ``$c$ is from $T_1$ to $T_2$''.
\end{definition}

Next, we define the \emph{Lazy D Cast ADT}, which captures the further
requirements that are needed for the theorem that establishes
equivalence to \ineffCEKD{}. Property (1) below states that $id(T)$
acts as the identity function. Property (2) states that $seq(c,c)$
acts as a sequence of casts. Properties (3) through (11) state that
$cast(T_1,l,T_2)$ acts like the Lazy D $applyCast$ for \ineffCEK\
(Fig.~\ref{fig:applyCast-D-C}).

\begin{definition}[Lazy D Cast ADT]
  \label{def:surely-lazyd}
  A  Cast is a Lazy D Cast if:
  \begin{enumerate}
  \item If $v : T$ then $applyCast(v,id(T)) = \mathtt{succ} \; v $
  \item If $\judgeType{v}{T_1}$ and
    $ \judgeTypeFT{c_1}{T_1}{T_2}$ and
    $ \judgeTypeFT{c_2}{T_2}{T_3}$\\
    then $applyCast(v,seq(c_1,c_2)) = 
    applyCast(v,c_1) \mbind{} \lambda v'.applyCast(v',c_2)$\\
    where 
    \[
    \begin{array}{rcl}
      \rOOsucc{v} \mbind{} f & = & f(v) \\
      \rOOfail{l} \mbind{} f & = & \rOOfail{l}
    \end{array}
    \]
  \item If $v : T_1$ and $T_1 \not\smile T_2$,
    then $applyCast(v,cast(T_1, l, T_2)) = \rOOfail{l} $
  \item If $v : \star$,
    then $applyCast(v,cast(\TOOdyn,l,\TOOdyn)) = \rOOsucc{v} $
  \item If $v : P$,
    then $applyCast(\hcvOOinj{P}{v},cast(\star,l,P')) 
    = applyCast(v,cast(P,l,P')) $
  \item If $v : P$,
    then $applyCast(v,cast(P,l,\star)) = \rOOsucc{(\hcvOOinj{P}{v})} $
  \item If $v : \POOunit$,
    then $applyCast(v,cast(\POOunit,l,\POOunit)) = \rOOsucc{v} $
  \item If $(\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2}) : \POOfun{T_1}{T_2}$,
    then\\
    $ 
    applyCast(\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2}, 
    cast(\POOfun{T_1}{T_2},l,\POOfun{T_3}{T_4})) \\
    = 
    \rOOsucc{(\hcvOOfun{seq(cast(T_3,l,T_1),c_1)}{\mathcal{E}}{x}{e}{seq(c_2,cast(T_2,l,T_4))})}$
  \item If $(\hcvOOcons{v_1}{c_1}{v_2}{c_2}) : \POOprod{T_1}{T_2}$,
    then \\
    $ 
    applyCast(\hcvOOcons{v_1}{c_1}{v_2}{c_2},cast(\POOprod{T_1}{T_2},l,T_3 
    \times 
    T_4))$\\
    $ = 
    \rOOsucc{(\hcvOOcons{v_1}{seq(c_1,cast(T_1,l,T_3))}{v_2}{seq(c_2,cast(T_2,l,T_4))})}
    $ 
  \item If $(\hcvOOinl{v}{c}) : \POOsum{T_1}{T_2}$,
    then \\
    $ 
    applyCast(\hcvOOinl{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
    = \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))})} $
  \item If $(\hcvOOinr{v}{c}) : \POOsum{T_1}{T_2}$,
    then \\$
    applyCast(\hcvOOinr{v}{c},cast(\POOsum{T_1}{T_2},l,\POOsum{T_3}{T_4}))
    = \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_2,l,T_4))})} $
  \end{enumerate}
\end{definition}

\subsection{A Space-efficient CEK Machine}
\label{sec:framework:cek}

\effCEK{C} is a space-efficient CEK machine parameterized over the Cast ADT ($C$).  
The key differences between \effCEK{C} and \ineffCEK\ are the places where 
casts can accumulate at runtime, that is, values and continuations.
The differences regarding values was discussed 
above (Definition~\ref{def:values-effCEK}).
We define contiuations below, with $\kappa$ ranging over continuations
and $k$ ranging over pre-continuations.
%
Pre-continuations are like the continuations in \ineffCEK{}, but there is no 
constructor for casts.
%
A continuation is now a pre-continuation prefixed with a cast.


\begin{definition}[Continuations for the \effCEK{C} machine] 
\label{def:conts-effCEK}
  \[
  \begin{array}{lrcl}
  \stxrule{\kappa}{Continuation}{
    \kOOcast{c}{k}
  }
  \stxrule{k}{Pre-continuations}{
    \kOOmt \mid{}
    \kOOconsI{T}{T}{e}{\mathcal{E}}{\kappa} \mid
    \kOOconsII{T}{T}{v}{\kappa} \mid
    \kOOinl{T}{T}{\kappa}
  }
  \stxrulecont{
  	\kOOinr{T}{T}{\kappa} \mid
    \kOOappI{e}{\mathcal{E}}{\kappa} \mid
    \kOOappII{v}{\kappa} \mid
    \kOOcar{\kappa} \mid
    \kOOcdr{\kappa}
  }
  \stxrulecont{
    \kOOcaseI{e}{e}{\mathcal{E}}{\kappa} \mid
    \kOOcaseII{v}{e}{\mathcal{E}}{\kappa} \mid
    \kOOcaseIII{v}{v}{\kappa}
  }
  \end{array}
  \]
\end{definition}


Continuations in \ineffCEKD{} have zero or more casts at the top.  In 
\effCEK{C}, however, every continuation has exactly one cast at the top.
Continuations in \ineffCEK\ that have no casts at the top correspond
to continuations in \effCEK{C}\ whose casts are identities.
Continuations in \ineffCEK\ that have many casts at the top correspond
to continuations in \effCEK{C}\ where those casts are composed by
$seq(c,c)$.


\begin{figure} 
  Build continuation \fbox{$wrap(k) = \kappa$}
  \[
  \begin{array}{rclc}
  \funrule{wrap(k)}{\kOOcast{id(T_1)}{k}}{
    \sidecond{k : T_1 \Longrightarrow T_2}}
  \end{array}
  \]
  
  Extend continuation \fbox{$ext(c,\kappa) = \kappa$}
  \[
  \begin{array}{rclc}
  \funrule{ext(c_1,\kOOcast{c_2}{k})}{
    \kOOcast{seq(c_1,c_2)}{k}
  }{}
  \end{array}
  \]

  Transition \fbox{$\judgeSreduce{C}{s}{s}$}
  \[
  \begin{array}{rclr}
  \hiredruleS{
    \sOOinspect{\eOOcast{e}{T_1}{l}{T_2}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e}{\mathcal{E}}{ext(cast(T_1,l,T_2),\kappa)}
  }{}
  \redruleS{
    \sOOinspect{\eOOvar{x}}{\mathcal{E}}{\kappa}
  }{  
    \sOOreturn{\mathcal{E}(x)}{\kappa}
  }{}
  \redruleS{
    \sOOinspect{\eOOsole}{\mathcal{E}}{\kappa}
  }{
    \sOOreturn{\hcvOOtt}{\kappa}
  }{}
  \hiredruleS{
    \sOOinspect{\eOOlam{T_1}{T_2}{x}{e}}{\mathcal{E}}{\kappa}
  }{
    \sOOreturn{\hcvOOfun{id(T_1)}{\mathcal{E}}{x}{e}{id(T_2)}}{\kappa}
  }{}
  \redruleS{
    \sOOinspect{\eOOcons{T_1}{T_2}{e_1}{e_2}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e_1}{\mathcal{E}}{
      wrap(\kOOconsI{T_1}{T_2}{e_2}{\mathcal{E}}{\kappa})
    }
  }{}
  \redruleS{
    \sOOinspect{\eOOinl{T_1}{T_2}{e}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e}{\mathcal{E}}{wrap(\kOOinl{T_1}{T_2}{\kappa})}
  }{}
  \redruleS{
    \sOOinspect{\eOOinr{T_1}{T_2}{e}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e}{\mathcal{E}}{wrap(\kOOinr{T_1}{T_2}{\kappa})}
  }{}
  \redruleS{
    \sOOinspect{\eOOapp{e_1}{e_2}}{\mathcal{E}}{\kappa}
  }{
    \sOOinspect{e_1}{\mathcal{E}}{wrap(\kOOappI{e_2}{\mathcal{E}}{\kappa})}}{}
  
  \redruleS{
    \sOOinspect{\eOOcar{e})}{\mathcal{E}}{\kappa}}{
    \sOOinspect{e}{\mathcal{E}}{wrap(\kOOcar{\kappa})}}{}
  
  \redruleS{
    \sOOinspect{\eOOcdr{e}}{\mathcal{E}}{\kappa}}{
    \sOOinspect{e}{\mathcal{E}}{wrap(\kOOcdr{\kappa})}}{}
  
  \redruleS{
    \sOOinspect{\eOOcase{e_1}{e_2}{e_3}}{\mathcal{E}}{\kappa}}{
    \sOOinspect{e_1}{\mathcal{E}}{wrap(\kOOcaseI{e_2}{e_3}{\mathcal{E}}{\kappa})}}{}


\redruleS{
	\sOOinspect{\eOOblame{l}}{\mathcal{E}}{\kappa}}{
	\sOOhalt{(\oOOblame{l})}}{}

  \hiredruleS{
    \sOOreturn{v}{\kOOcast{c}{k}}
  }{
  \begin{cases}
  \continue{k}{v'} & \sidecond{applyCast(v,c) = \rOOsucc{v'}} 
  \\
  \sOOhalt{\oOOblame{l}} & \sidecond{applyCast(v,c) = \rOOfail{l}}
  \end{cases}
  }{}
  \end{array}
  \]
  
  Apply continuation
  \fbox{$\continue{v}{k} = s$}
  \[
  \begin{array}{rclr}
  

\funrule{
  \continue{v_1}{\kOOconsI{T_1}{T_2}{e_2}{\mathcal{E}}{\kappa}}}{
  \sOOinspect{e_2}{\mathcal{E}}{wrap(\kOOconsII{T_1}{T_2}{v_1}{\kappa})}}{}

\hifunrule{
  \continue{v_2}{\kOOconsII{T_1}{T_2}{v_1}{\kappa}}}{
  \sOOreturn{\hcvOOcons{v_1}{id(T_1)}{v_2}{id(T_2)}}{\kappa}}{}

\hifunrule{
  \continue{v}{\kOOinl{T_1}{T_2}{\kappa}}}{
  \sOOreturn{\hcvOOinl{v}{id(T_1)}}{\kappa}}{}

\hifunrule{
  \continue{v}{\kOOinr{T_1}{T_2}{\kappa}}}{
  \sOOreturn{\hcvOOinr{v}{id(T_2)}}{\kappa}}{}

\funrule{
  \continue{v_1}{\kOOappI{e_2}{\mathcal{E}}{\kappa}}}{
  \sOOinspect{e_2}{\mathcal{E}}{
    wrap(\kOOappII{v_1}{\kappa})
  }}{}

\hifunrule{
  \continue{v_2}{\kOOappII{(\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2})}{\kappa}}}{
\begin{cases}
\sOOinspect{e}{\mathcal{E}[x:=v']}{ext(c_2,\kappa)} \\
\sidecond{applyCast(v_2,c_1) = \rOOsucc{v'}}
\\
\sOOhalt{l} \\
\sidecond{applyCast(v_2,c_1) = \rOOfail{l}}
\end{cases}
}{}


\hifunrule{
  \continue{\hcvOOcons{v_1}{c_1}{v_2}{c_2}}{
    \kOOcar{\kappa}
  }
}{
  \sOOreturn{v_1}{ext(c_1,\kappa)}
}{}
\hifunrule{
  \continue{\hcvOOcons{v_1}{c_1}{v_2}{c_2}}{
    \kOOcdr{\kappa}
  }
}{
  \sOOreturn{v_2}{ext(c_2,\kappa)}
}{}

\funrule{
  \continue{v_1}{\kOOcaseI{e_2}{e_3}{\mathcal{E}}{\kappa}}
}{
  \sOOinspect{e_2}{\mathcal{E}}{
    wrap(\kOOcaseII{v_1}{e_3}{\mathcal{E}}{\kappa})
  }
}{}

\funrule{
  \continue{v_2}{
    \kOOcaseII{v_1}{e_3}{\mathcal{E}}{\kappa}
  }
}{
  \sOOinspect{e_3}{\mathcal{E}}{
  wrap(\kOOcaseIII{v_1}{v_2}{\kappa})
  }
}{}

\hifunrule{
  \continue{v_3}{
    \kOOcaseIII{(\hcvOOinl{v}{c})}{(\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2})}{\kappa}
%   (\mathtt{case_3}\;()\;
%   ()
%   \;)
  }
}{
  \sOOreturn{v}{wrap(\kOOappII{(\hcvOOfun{seq(c,c_1)}{\mathcal{E}}{x}{e}{c_2})}{\kappa})}
}{}

\hifunrule{
  \continue{(\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2})}
  {
    \kOOcaseIII{(\hcvOOinr{v}{c})}{v_2}{\kappa}
  }
}{
  \sOOreturn{v}{wrap(\kOOappII{(\hcvOOfun{seq(c,c_1)}{\mathcal{E}}{x}{e}{c_2})}{\kappa})}
}{}

\funrule{
  \continue{v}{\kOOmt}}{
  \sOOhalt{observe(v)}}{}
  
  \end{array}\]
  
% Transitive closure of reduction \fbox{$s \longrightarrow_{S(C)}^{*} s$}
% \[\dots\]
  
% Evaluation \fbox{$\judgeSeval{C}{e}{o}$}
% \[
% \inference{
%   \judgeSreduceTrans{C}{
%     \sOOinspect{e}{\emptyset}{wrap(\hckOOmt)}
%   }{
%     \sOOhalt{o}
%   }   
% }{
%   \judgeSeval{C}{e}{o}
% }
% \]
  
  \caption{Space-efficient CEK machine$\mathcal{S}(C)$}
  \label{fig:machine-cekcc}
\end{figure}

\figref{fig:machine-cekcc} defines the transition relation 
$\judgeSreduce{C}{s}{s}$. They rely on functions provided 
by $C$ to work with casts.
%
When evaluating a cast expression, the machine extends the continuation with 
cast $cast(T_1,l,T_2)$. The function $ext(c,\kappa)$ composes $c$ with the cast 
at the top of $k$ by calling $seq$.
%
To construct a function, the machine fills the casts with $id$s.
%
To return a value to a continuation, the machine first applies the top cast to 
the value. If the application fails, the machine halts with the blame label 
from the failure. Otherwise, the machine handles the pre-continuation with 
$cont$.
%
When the machine constructs a pair, a left injection, or a right injection, it 
fills the casts with $id$ as well, just like how it did for functions. 
%
To apply a function, the machine applies the domain cast $c_1$ to the 
operand $v_2$, extends the continuation with the codomain cast $c_2$, and 
evaluates the function body.
%
To take out the first part of a pair, the machine returns the first value to a 
continuation extended with the first cast. Taking out the second 
part of a pair is similar.
%
%%In case splitting, if the target value is a left injection, the
%%machine moves to a state that will apply the first continuation
%%function to the value inside the left injection. The case for right
%%injection is similar.
%%
To case split a variant, the machine first looks at the variant value. If the 
variant is a left injection, the machine composes the cast in the left 
injection with the domain cast of the first continuation function, then move 
to a state that will apply the new function to the value in the left injection.
The case for right injections is similar.

Reflexive transitive closure of reduction ($\judgeSreduceTrans{C}{s}{s}$) and
evaluation ($\judgeSeval{C}{e}{o}$) are the same as for \ineffCEK.

\subsection{\effCEK{C} Is Equivalent to \ineffCEKD{}, Provided $C$ Is an Instance of the Lazy D ADT}
\label{secc:framework:monoid-correct}

In this section, we prove that for all $C$, if $C$ is a Lazy D Cast
ADT, then
\[
  \evalEqv{\effCEK{C}}{\ineffCEKD}
\]
The main work of the proof is in a lemma that establishes a weak
bisimulation between \effCEK{C} and \ineffCEKD{}.  The bisimulation
goes more smoothly if we require two more properties of the cast
representation: that the casts form a monoid (the $id$ and $seq$
operators) and that the cast constructor is equivalent to the identity
operator when applied to an identical source and target type.
However, the final theorem does not require these two properties
because we can prove 1) that \effCEK{C_1} and \effCEK{C_2} are
equivalent for any two Lazy D Cast ADTs $C_1$ and $C_2$
(Proposition~\ref{thm:surely-lazyD-eqv}), and 2) there is an instance
of the Lazy D Cast ADT, named $L$, that is a monoid and satisfies the
two extra properties, and is therefore equivalent to \ineffCEKD{}
(Lemma~\ref{lem:L-correct}). So by transitivity, for any Lazy D Cast
ADT $C$ we have \evalEqv{\effCEK{C}}{\ineffCEKD}.

\subsubsection{Weak Bisimulation between \effCEK{C} and \ineffCEKD{}}

We shall prove that if an instance of Cast ADT $C$ is Lazy D, is a
monoid, and if $cast(T,l,T) = id(T)$, then there is
%% $eval_\mathcal{D} = eval_{\mathcal{S}(C)}$. We proof this lemma with
a weak bisimulation between \effCEK{C} and \ineffCEKD{}.
We define monoid as follows.

\begin{definition}[Monoid]
  A Cast ADT is a monoid if 
  for all
  $c_1 : T_1 \Longrightarrow T_2$,
  $c_2 : T_2 \Longrightarrow T_3$, and
  $c_3 : T_3 \Longrightarrow T_4$,
  \begin{enumerate}
    \item $seq(id(T_1),c_1) = c_1$,
    \item $seq(c_1,id(T_2)) = c_1$, and
    \item $seq(seq(c_1, c_2), c_3) = seq(c_1, seq(c_2, c_3))$.
  \end{enumerate}
\end{definition}

%Lazy D Cast ADT confines the behavior of operators so narrowly that it 
%effectively allows us to ``run'' programs without referring to an actual 
%representation of cast.

%\todo[inline]{How does the following bisimulation relation
%  compare to the one used in the Blame and Coercion paper?
%  Are there any guiding principles to how this bisimulation
%  relation was constructed? -JS
%\\---\\
%The guiding principle is to keep the change in D side atomic. \\
%In the blame and coercion paper,
%the bisimulation relation between $ \lambda{}C $ and $ \lambda{}S $ seems to 
%be 
%related, but its (iii) rules in Figure 6 looks wired to me. -KC}

Fig.~\ref{fig:bisim-SC-D} defines the bisimulation relation
$s_1 \approx s_2$, where $s_1 \in \effCEK{C}$ and $s_2 \in \ineffCEKD{}$.
It is the smallest congruence relation that also includes the
pairs induced by the rules in Fig.~\ref{fig:bisim-SC-D}.
%
One nice aspect of using abstract machines for this proof is that
the expressions in the machine are simply related by syntactic equality.
%
The bisimulation relation is mutually defined on continuations, written $\kappa
\approx \kappa : T$, where $T$ is their source type, and values, written $v 
\approx v : T$, where $T$ is their type.
%
If $k \approx \kappa : T$, adding an identity cast on top of $k$ gives a 
related continuation. This handles the way in which
\effCEK{C} uses $wrap$ to push identity coercions onto continuations
whereas \ineffCEKD{} does not.
%
We remark that this bisimulation relation is unusual in that it uses
some ADT operations in its definition, such as $id$, $cast$, and
$seq$, which is necessary because \effCEK{C} and the bisimulation
is parameterized over the Cast ADT.
%
%\todo[inline]{The use of ``wrap'' obscures this explanation.
%  Consider getting rid of wrap by inlining it. -JS
%\\---\\
%I agree that inlining wrap and ext can improve readability of $\kappa \approx 
%\kappa$, but this would make latex different from Agda, is it alright?
%-KC
%\\---\\
%Yes, that is alright. Inlining is really a trivial change.
%-JS
%}
%
If $\kOOcast{c}{k_1} \approx \kappa_2 : T$, extending the right-hand
side with a cast $T_1 \Rightarrow^l T_2$ and sequencing
$cast(T_1,l,T_2)$ with $c$ on the left-hand side, produces related
continuations. This takes care of the difference between
the transition rules for $e \langle T_1 \Rightarrow^l T_2 \rangle$
on the two machines.

\begin{figure}
%  $\text{\effCEK{C}} \approx \text{\ineffCEKD}$
% \[\dots\]
  \fbox{$s \approx s$}
  % Because the grammar for states of the two machines are not identical,
  % I think it is worthwhile to write out these rules explicitly. -Jeremy
  \begin{gather*}
    \inference{dom(\mathcal{E}_1) = dom(\mathcal{E}_2) \\
               \forall x {:} T \in dom(\mathcal{E}_1),\,
                   \mathcal{E}_1(x) \approx \mathcal{E}_2(x) : T\\
               \kappa_1 \approx \kappa_2 : T}
              {\langle e, \mathcal{E}_1, \kappa_1 \rangle \approx
              \langle e, \mathcal{E}_2, \kappa_2 \rangle}
    %% \quad
    %% \inference{v_1 \approx v_2 : T \quad \kappa_1 \approx \kappa_2 : T}
    %%           {\langle v_1, \kappa_1 \rangle  \approx
    %%           \langle v_2, \kappa_2 \rangle}
    \quad
    \inference{}
              {\sOOhalt{o} \approx \sOOhalt{o}} \\
  \end{gather*} 
  \fbox{$\kappa \approx \kappa : T$}
  \begin{gather*}
  \inference{
    k \approx \kappa : T
  }{
    \kOOcast{id(T)}{k} \approx \kappa
  }
  \quad
  \inference{
    \kOOcast{c}{k_1} \approx \kappa_2 : T_2
  }{
    \kOOcast{seq(cast(T_1,l,T_2),c)}{k_1} \approx 
    \kOOcast{\cOOcast{T_1}{l}{T_2}}{\kappa_2}
  }
\\
  \end{gather*}
\\  
  \fbox{$v \approx v : T$}
  \begin{gather*}
  \inference{
    v_1 \approx v_2 : I
  }{
    \hcvOOinj{I}{v_1} \approx \vOOcast{v_2}{\cOOcast{I}{l}{\TOOdyn}}
    : \TOOdyn
  }
  \\[1ex]
   %% This one is an obvious congruence rule. -Jeremy
   %% \inference{}{
   %%  \hcvOOtt \approx \vOOtt : \POOunit
   %% }
   %% \quad
  \inference{}{
    \hcvOOtt \approx \vOOcast{\vOOtt}{\cOOcast{\POOunit}{l}{\POOunit}}
    : \POOunit
  }
  \\[1ex]
  \inference{
  	\Gamma , x : T_1 \vdash e : T_2
  	\\
  	\forall{} x \in dom(\Gamma).\;
  		\mathcal{E}_1(x) \approx \mathcal{E}_2(x) : \Gamma(x)
  }{
    \hcvOOfun{id(T_1)}{\mathcal{E}_1}{x}{e}{id(T_2)}
    \approx
    \vOOfun{\mathcal{E}_2}{x}{e}
    : \POOfun{T_1}{T_2}
  }
\\[1ex]
\inference{
\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2} \approx v_2 : \POOfun{T_1}{T_2}}{
\hcvOOfun{c_1'}{\mathcal{E}}{x}{e}{c_2'}
\approx
\vOOcast{v_2}{\cOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}}}
: \POOfun{T_3}{T_4}
}
\begin{array}{l}
c_1' = seq(cast(T_3,l,T_1),c_1) \\
c_2' = seq(c_2,cast(T_2,l,T_4))
\end{array}
\\[1ex]
  \inference{
    v_1 \approx v_2 : T_1 &
    v_3 \approx v_4 : T_2 &
  }{
    \hcvOOcons{v_1}{id(T_1)}{v_3}{id(T_2)}
    \approx
    \vOOcons{v_2}{v_4}
    : \POOprod{T_1}{T_2}
  }
\\[1ex]
  \inference{
    \hcvOOcons{v_1}{c_1}{v_3}{c_2} \approx v_2 : \POOprod{T_1}{T_2}
  }{
    \hcvOOcons{v_1}{c_1'}{v_3}{c_2'} \approx
    \vOOcast{v_2}{\cOOcast{\POOprod{T_1}{T_2}}{l}{\POOprod{T_3}{T_4}}}
    : \POOprod{T_3}{T_4}
  }
  \begin{array}{l}
    c_1' = seq(c_1,cast(T_1,l,T_3)) \\
    c_2' = seq(c_2,cast(T_2,l,T_4))
  \end{array}
\\[1ex]
  \inference{
    v_1 \approx v_2 : T_1
  }{
    \hcvOOinl{v_1}{id(T_1)} \approx \vOOinl{v_2}
    : \POOsum{T_1}{T_2}
  }
  \quad
  \inference{
    \hcvOOinl{v_1}{c} \approx v_2
    : \POOsum{T_1}{T_2} &
    c' = seq(c,cast(T_1,l,T_3))
  }{
    \hcvOOinl{v_1}{c'} \approx
    \vOOcast{v_2}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
    : \POOsum{T_3}{T_4} 
  }
  \\[1ex]
  \inference{
  v_1 \approx v_2 : T_2
  }{
  \hcvOOinr{v_1}{id(T_2)} \approx \vOOinr{v_2}
  : \POOsum{T_1}{T_2}
  }
  \quad
  \inference{
  \hcvOOinr{v_1}{c} \approx v_2
  : \POOsum{T_1}{T_2} &
  c' = seq(c,cast(T_2,l,T_4))
  }{
  \hcvOOinr{v_1}{c'} \approx
  \vOOcast{v_2}{\cOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}}}
  : \POOsum{T_3}{T_4}
  }
  \end{gather*}
  \caption{Bisimulation between \effCEK{C} and \ineffCEKD}
  \label{fig:bisim-SC-D}
\end{figure}

The bisimulation relation for values is designed to make
Lemma~\ref{thm:lem-apply-cast-SD} true, that is, if $v_1 \approx v_2$,
then
  \[
  applyCast_{\text{\effCEK{C}}}(v_1,cast(T_1,l,T_2)) 
  \approx 
  applyCast_{\text{\ineffCEKD}}(v_2,\cOOcast{T_1}{l}{T_2})
  \]
So if two values of type $I$ are related, injecting them to $\TOOdyn$
gives related values.
%
% The following is part of being a congruence. -JS
%Unit values are of course related. 
%
To relate to a closure in \ineffCEKD, the closure in \effCEK{C} must
have identities as its casts.
%
If a closure on the left is related to a value, we can apply
equivalent casts on both sides to obtain related values.
%
The rules for products and sums are similar.
%
Lemma~\ref{thm:lem-apply-cast-SD} is used in our bisimulation proof to
handle the transitions that apply casts to values.

\begin{lemma}[$applyCast$ Preserves Bisimulation]
  \label{thm:lem-apply-cast-SD}
  Assume $C$ implements Lazy D Cast ADT,
  $v_1$ is a value in \effCEK{C},
  $v_2$ is a value in \ineffCEKD,
  and $v_1 \approx v_2 : T_1$,
  \[
  applyCast_{\text{\effCEK{C}}}(v_1,cast(T_1,l,T_2)) 
  \approx 
  applyCast_{\text{\ineffCEKD}}(v_2,\cOOcast{T_1}{l}{T_2})
  \]
\end{lemma}
\begin{proof}
  Case splitting whether $T_1$ is shallowly consistent with $T_2$.
  If yes, case splitting how they are shallowly consistent.
  Then apply properties (3) - (11) of Lazy D Cast when applicable.
\end{proof}

We now come to the main lemma, the weak bisimulation between
\effCEK{C} and \ineffCEKD{}.

\begin{lemma}[Weak Bisimulation between \effCEK{C} and \ineffCEKD{}]
  \label{thm:SD-bisim}
  Assume $C$ implements Lazy D Cast ADT
  and $C$ is a monoid
  and $cast(T,l,T)=id(T)$,
  $s_{1} \in \text{\effCEK{C}}$,
  $s_{2} \in \text{\ineffCEKD}$,
  $s_{1} \approx s_{2}$,
\begin{enumerate}
	\item If $\judgeSreduce{C}{s_1}{s_3}$ then
	$\judgeDreduceTrans{s_2}{s_4}$ and $s_3 \approx s_4$ for some $s_4$.
	\item If $\judgeDreduce{s_2}{s_4}$ then
	$\judgeSreduceTrans{C}{s_1}{s_3}$,
	$\judgeDreduceTrans{s_4}{s_5}$, and
	$s_3 \approx s_5$ for some $s_3$ and $s_5$.
	\item $s_1 = \sOOhalt{o}$ if and only if  $s_2 = \sOOhalt{o}$
\end{enumerate}
%\begin{enumerate}
%  \item $s_1 = \sOOhalt{o}$ if and only if  $s_2 = \sOOhalt{o}$
%%  \item If $s_2 = \sOOhalt{o}$ then $s_1 = \sOOhalt{o}$
%  \item If $\judgeSreduce{C}{s_1}{s_3}$ 
%    then $\judgeDreduce{s_2}{s_4}$ 
%    and  $s_3 \approx^{*} s_4$
%    for some $s_4$
%  \item If $\judgeDreduce{s_2}{s_4}$
%    then $\judgeSreduce{C}{s_1}{s_3}$ 
%    and  $s_3 \approx^{*} s_4$
%    for some $s_3$
%\end{enumerate}
%{\color{red}
%  Jeremy's attempt to reformulate in a more standard way that
%  remains equivalent:
%\begin{enumerate}
%\item If $\judgeSreduce{C}{s_1}{s_3}$ then
%  $\judgeDreducePlus{s_2}{s_4}$ and $s_3 \approx s_4$ for some $s_4$.
%\item If $\judgeDreduce{s_2}{s_4}$ then
%  $\judgeSreduce{C}{s_1}{s_3}$,
%  $\judgeDreduceTrans{s_4}{s_5}$, and
%   $s_3 \approx s_5$ for some $s_3$ and $s_5$.
%\item $s_1 = \sOOhalt{o}$ if and only if  $s_2 = \sOOhalt{o}$
%\end{enumerate}
%}
%Or diagrammatically, 
%  \[\begin{array}{clclc}
%  s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_1'\\
%  \rotatebox[origin=c]{90}{$\approx$} 
%  & & & \;\;\;\rotatebox[origin=c]{-20}{$\approx$} \\
%  s_{2} & 
%  \longrightarrow_{\text{\ineffCEKD}} & s_2' &
%  \longrightarrow^{*}_{\text{\ineffCEKD}} & s_2'' \\
%  \end{array}\]
\end{lemma}
\begin{proof}
  Part (3) follows from the definition of $s \approx s$.
  Part (1) and (2) are more interesting. 
  By the definition of $s \approx s$, it is straightforward to prove 
  $\judgeSreduce{C}{s_1}{s_3}$ if and only if $\judgeDreduce{s_2}{s_4}$.
  So we can prove two parts together by showing that if $s_{1} \approx s_{2}$
  and $\judgeDreduce{s_2}{s_4}$ then
  \[
%  \text{if}\; 
%  \;\text{and}\;\judgeSreduce{C}{s_1}{s_3}
%  \;\text{and}\;\judgeDreduce{s_2}{s_4}
  \;\text{there exists}\; s'
  \;\text{such that}\; \judgeDreduceTrans{s_4}{s'}
  \;\text{and}\; s_3 \approx s'.
  \]
  To put it another way, our goal is to prove that 
  one reduction step in \effCEK{C} corresponds to
  one or more steps in \ineffCEKD.  
  Although there are many cases, the general idea is the same.
  Consider
  \[
  \sOOreturn{\hcvOOcons{v_{11}}{c_{11}}{v_{12}}{c_{12}}}{
    wrap(\kOOcar{\kappa})
  }
  \approx
  \sOOreturn{v_2}{\kOOcar{\kappa}}
  \]

  By looking at the definition of $v \approx v$, we know
  \begin{align*}
   c_{11} &= seq(seq(id(T_1),cast(T_1,l,T_3)) \dots) \\
   c_{12} &= seq(seq(id(T_2),cast(T_2,l,T_4)) \dots) \\
   v_2 &= \vOOcast{(\vOOcons{v_{21}}{v_{22}})}{
    \cOOcast{\POOprod{T_1}{T_2}}{l_1}{\POOprod{T_3}{T_4}}} \dots
  \end{align*}
  Thus we have the following reduction in \effCEK{C}. Then we employ
  equational reasoning that relies on the premise that $C$ is a
  monoid.
  \[
  \begin{array}{ll}
&
\sOOreturn{\hcvOOcons{v_{11}}{c_{11}}{v_{12}}{c_{12}}}{wrap(\kOOcar{\kappa})}
\\
\longmapsto_\text{\effCEK{C}} &
\sOOreturn{v_{11}}{ext(c_{11},\kappa)}
\\
= &
\sOOreturn{v_{11}}{ext(seq(seq(id(T_1),cast(T_1,l,T_3))\dots),\kappa)}
\\
= &
\sOOreturn{v_{11}}{
	ext(id(T_1),ext(cast(T_1,l,T_3),ext(\dots,\kappa)))
}
\\
= &
\sOOreturn{v_{11}}{ext(cast(T_1,l,T_3),ext(\dots,\kappa)}
  \end{array}
  \]

We have the following corresponding reduction in \ineffCEKD, where the
last state is related to the above \effCEK{C} state.
\[
\begin{array}{ll}
& \sOOreturn{
  \vOOcast{(\vOOcons{v_{21}}{v_{22}})}{   
  \cOOcast{\POOprod{T_1}{T_2}}{l_1}{\POOprod{T_3}{T_4}}} \dots
}{\kOOcar{\kappa}}
\\
\longmapsto_{\mathcal{D}}^{*} &
\sOOreturn{(\vOOcons{v_{21}}{v_{22}})}{
  \kOOcar{
  \kOOcast{\cOOcast{T_1}{l}{T_3}}{\dots\kappa}
}}
\\
\longmapsto_{\mathcal{D}} &
\sOOreturn{v_{21}}{
  \kOOcast{\cOOcast{T_1}{l}{T_3}}{\dots\kappa}
}
\end{array}
\]

Other cases are similar. Of course, we need the lemma about
$applyCast$ (Lemma~\ref{thm:lem-apply-cast-SD}) when cast applications
happen in both machines.  And in case splitting, we employ
$cast(T,l,T)=id(T)$ to relate the continuation functions.
\end{proof}

\begin{corollary}[Correctness of \effCEK{C}]
  \label{thm:SD-equiv}
  Suppose $C$ is an instance of the Cast ADT
  and the \lazyD{} ADT, $C$ is a monoid,
  and $cast(T,l,T)=id(T)$.
  If $\judgetype{\emptyset}{e}{T}$ and $o : T$, then
  \[
    \text{\evalEqv{\effCEK{C}}{\ineffCEKD}}
  \]
\end{corollary}
\begin{proof}
	By the definitions of $eval$, we need to show 
	\[
	\judgeSreduceTrans{C}{\sOOinspect{e}{\emptyset}{wrap(\kOOmt)}}{
		\sOOhalt{o}
	}
	\;\text{if and only if}\;
	\judgeSreduceTrans{C}{\sOOinspect{e}{\emptyset}{\kOOmt}}{
		\sOOhalt{o}
	}
	\]
	Obviously, the initial states are related in the bisimulation relation.
	\[
	\sOOinspect{e}{\emptyset}{wrap(\kOOmt)}
	\approx
	\sOOinspect{e}{\emptyset}{\kOOmt}
	\]
	So we can generalize our goal, and prove that if $s_1 \approx s_2$
	\[
	\judgeSreduceTrans{C}{s_1}{\sOOhalt{o}}
	\;\text{if and only if}\;
	\judgeSreduceTrans{C}{s_2}{\sOOhalt{o}}
	\]
	
	Let us prove left to right first by induction on 
	$\judgeSreduceTrans{C}{s_1}{\sOOhalt{o}}$.
	
	\begin{itemize}
		\item 
		If $s_1$ takes zero step to the halting state, it must be halting.
		By Lemma~\ref{thm:SD-bisim}, $s_2$ is halting as well, so we are done.
		\item 
		If $\judgeSreduce{C}{s_1}{s_3}$ and 
		$\judgeSreduceTrans{C}{s_3}{\sOOhalt{o}}$,
		by Lemma~\ref{thm:SD-bisim}, there exists a $s_4$ such that 
		$\judgeDreduceTrans{s_2}{s_4}$ and $s_3 \approx s_4$. So we can apply 
		our induction hypothesis.
	\end{itemize}
	
	Now let us prove right to left by induction on 
	$\judgeDreduceTrans{s_2}{\sOOhalt{o}}$.
	\begin{itemize}
		\item If $s_2$ takes zero step to the halting state, it must be halting.
		By Lemma~\ref{thm:SD-bisim}, $s_2$ is halting as well, so we are done.
		\item If $\judgeDreduce{s_2}{s_4}$ and 
		$\judgeDreduceTrans{s_4}{\sOOhalt{o}}$,
		by Lemma~\ref{thm:SD-bisim}, there exist $s_3,s_5$ such that
		\[
			\judgeSreduceTrans{C}{s_1}{s_3}
			\;\text{and}\;
			\judgeDreduceTrans{s_4}{s_5}
			\;\text{and}\;
			s_3 \approx s_5
		\]
		From $\judgeDreduceTrans{s_4}{\sOOhalt{o}}$ and 
		$\judgeDreduceTrans{s_4}{s_5}$ we know 
		$\judgeDreduceTrans{s_5}{\sOOhalt{o}}$ because our machine is 
		deterministic. Now we can apply our induction hypothesis.
	\end{itemize}
%  Proving that the left-hand side implies the right-hand side is
%  trivial.  To prove $\judgeDeval{e}{o}$ implies
%  $\judgeSeval{C}{e}{o}$, we first take one step in \effCEK{C}, and
%  catch it up in \ineffCEKD\ by taking one or more steps in
%  \ineffCEKD. As we just took a positive number of steps, we are
%  closer to the halting state.
\end{proof}

%% \subsection{\lazyD\ Cast ADT Respect \ineffCEKD}
%% \label{secc:framework:all-correct}

%% In this subsection, we prove that for all $C$, if $C$ is a Lazy D Cast ADT, 
%% then \evalEqv{\ineffCEKD}{\effCEK{C}}. We first 
%% prove that all $S(C)$ where $C$ is a Lazy D Cast ADT are equivalent, then 
%% connect this theorem to Lemma~\ref{thm:SD-equiv}.

\subsubsection{\effCEK{C_1} and \effCEK{C_2} are equivalent if $C_1$ and $C_2$ 
are Lazy D}

We prove the equivalence among two \effCEK{C} machines with a strong
bisimulation. The bisimulation relation is the smallest congruence relation 
that also includes the rules below.
\begin{gather*}
\inference{
}{
  cast_1(T_1,l,T_2) \approx cast_2(T_1,l,T_2)
}
\quad
\inference{
}{
  id_1(T) \approx id_2(T)
}
\quad
\inference{
  c_1 \approx c_2 &
  c_3 \approx c_4
}{
  seq_1(c_1,c_3) \approx seq_2(c_2,c_4)
}
\end{gather*}

\begin{lemma}[Strong Bisimulation among $\mathcal{S}(\cdot)$]
  \label{thm:CEKS-bisim}
  Assume $C_1$ and $C_2$ implements Lazy D Cast ADT
  $s_{1} \in \text{\effCEK{C_1}}$,
  $s_{2} \in \text{\effCEK{C_2}}$,
  $s_{1} \approx s_{2}$,
  \begin{enumerate}
    \item If $s_1 = \sOOhalt{o}$ then $s_2 = \sOOhalt{o}$
    \item If $s_2 = \sOOhalt{o}$ then $s_1 = \sOOhalt{o}$
    \item If $\judgeSreduce{C_1}{s_1}{s_3}$ 
    then $\judgeSreduce{C_2}{s_2}{s_4}$ and $s_3 \approx s_4$ for some $s_4$
    \item If $\judgeSreduce{C_2}{s_2}{s_4}$ 
    then $\judgeSreduce{C_1}{s_1}{s_3}$ and $s_3 \approx s_4$ for some $s_3$
  \end{enumerate}
% 
%  Or diagrammatically, 
%  \[\begin{array}{clc}
%  s_{1} & \longrightarrow_{\text{\effCEK{C}}} & s_3\\
%  \rotatebox[origin=c]{90}{$\approx$} 
%  & & \rotatebox[origin=c]{90}{$\approx$} \\
%  s_{2} & 
%  \longrightarrow_{\text{\ineffCEKD}} & s_4 \\
%  \end{array}\]
\end{lemma}
\begin{proof} This proof is straightforward. The key ideas are undoing 
  uses of $seq$ with the property (2) of Lazy D Cast ADT, and handling all
  uses of $cast$ with properties (3)-(11).
\end{proof}

\begin{proposition}[Equivalence of Two \lazyD{} Cast ADTs]
  \label{thm:surely-lazyD-eqv}
  Assume $C_1$ and $C_2$ implements Lazy D Cast ADT. If 
  $\judgetype{\emptyset}{e}{T}$ and $o : T$ then
  \[
  \evalEqv{\effCEK{C_1}}{\effCEK{C_2}}
  \]
%  \[
%  eval_{\mathcal{S}(C_1)} = eval_{\mathcal{S}(C_2)}.
%  \]
\end{proposition}
\begin{proof}
  Without loss of generality, assume $\judgeSeval{C_1}{e}{o}$ and prove 
  $\judgeSeval{C_2}{e}{o}$.\\
  By the definition of $eval_{\mathcal{S}(C)}$, we know 
\[
\judgeSreduceTrans{C_1}{\sOOinspect{e}{\emptyset}{wrap(\kOOmt)}}{\sOOhalt{o}}
\]
  By induction on this reduction sequence and Lemma~\ref{thm:CEKS-bisim}, we 
  have 
\[
\judgeSreduceTrans{C_2}{\sOOinspect{e}{\emptyset}{wrap(\kOOmt)}}{\sOOhalt{o}}
\]
  that is, $\judgeSeval{C_2}{e}{o}$
\end{proof}

\subsubsection{The $L$ instance of the Lazy D Cast ADT}

\begin{figure}
Syntax
\[
\begin{array}{lrcl}
\stxrule{c}{Casts}{\lcOOnull{} \mid \lcOOcons{s}{c}}
\stxrule{s}{Steps}{\lsOOcast{T}{l}{T}}
\end{array}
\]

Steps Typing
\fbox{$\judgeTypeFT{s}{T}{T}$}
\begin{gather*}
\inference{
  T_1 \neq T_2
}{
  \judgeTypeFT{\lsOOcast{T_1}{l}{T_2}}{T_1}{T_2}
}
\end{gather*}

Casts typing
\fbox{$\judgeTypeFT{c}{T}{T}$}
\begin{gather*}
\inference{
}{
  \judgeTypeFT{\lcOOnull}{T}{T}
}
\quad
\inference{
  \judgeTypeFT{s}{T_1}{T_2} &
  \judgeTypeFT{c}{T_2}{T_3}
}{
  \judgeTypeFT{\lcOOcons{s}{c}}{T_1}{T_3}
}
\end{gather*}

\fbox{$seq(c,c)=c$}
\[
\begin{array}{rclr}
\funrule{seq(\lcOOnull,c)}{c}{}
\funrule{seq(\lcOOcons{s}{c'},c)}{\lcOOcons{s}{seq(c',c)}}{}
\end{array}
\]

\fbox{$id(T)=c$}
\[
\begin{array}{rclr}
\funrule{id(T)}{\lcOOnull}{}
\end{array}
\]

\fbox{$cast(T,l,T)$}
\[
\begin{array}{rclc}
\funrule{cast(T_1,l,T_2)}{
  \lcOOnull
}{
  \sidecond{T_1 = T_2}
}
\funrule{cast(T_1,l,T_2)}{
  \lcOOcons{\lsOOcast{T_1}{l}{T_2}}{\lcOOnull}
}{
  \sidecond{T_1 \neq T_2}
}
\end{array}
\]

  
\fbox{$appS(v,s) = r$}
\[
\begin{array}{rclr}
\funrule{
  appS(v,\cOOcast{\star}{l}{\star})
}{
  \rOOsucc{v}
}{}
\funrule{
  appS(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
}{
  \rOOsucc{v}
}{\sidecond{P_1 = P_2}}
\funrule{
appS(\vOOcast{v}{\cOOcast{P_1}{l_1}{\star}},\cOOcast{\star}{l_2}{P_2})
}{
appS(v,\cOOcast{P_1}{l_2}{P_2})
}{\sidecond{P_1 \neq P_2}}
\funrule{
  appS(v,\cOOcast{P}{l}{\star})
}{
  \rOOsucc{\hcvOOinj{P}{v}}
}{}
\funrule{
  appS(v,\lsOOcast{\POOunit}{l}{\POOunit})
}{
  \rOOsucc{v}
}{}
\funrule{
  appS(
    \hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2},
    \lsOOcast{\POOfun{T_1}{T_2}}{l}{\POOfun{T_3}{T_4}})
}{
  \rOOsucc{(\hcvOOfun{c_1'}{\mathcal{E}}{x}{b}{c_2'})}
}{
  \\ &&
  \text{where} \;
  c_1' = seq(cast(T_3,l,T_1),c_1)
  \\ &&
  \text{and} \;
  c_2' = seq(c_2,cast(T_2,l,T_4))
}

\funrule{
  appS(
    \hcvOOcons{v_1}{c_1}{v_2}{c_2},
    \lsOOcast{\POOprod{T_1}{T_2}}{l}{\POOprod{T_3}{T_4}}
}{
  \rOOsucc{(\hcvOOcons{v_1}{c_1'}{v_2}{c_2'})}
}{
\\ &&
\text{where} \;
c_1' = seq(c_1,cast(T_1,l,T_3))
\\ &&
\text{and} \;
c_2' = seq(c_2,cast(T_2,l,T_4))
}
\funrule{
  appS(\hcvOOinl{v}{c},\lsOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}})
}{
  \rOOsucc{(\hcvOOinl{v}{seq(c,cast(T_1,l,T_3))})}
}{}
\funrule{
  appS(\hcvOOinr{v}{c},\lsOOcast{\POOsum{T_1}{T_2}}{l}{\POOsum{T_3}{T_4}})
}{
  \rOOsucc{(\hcvOOinr{v}{seq(c,cast(T_2,l,T_4))})}
}{}
\funrule{
  appS(v,\cOOcast{P_1}{l}{P_2})
}{
  \rOOfail{l}
}{\sidecond{P_1 \not\smile P_2}}

\end{array}
\]


\fbox{$applyCast(v,c) = r$}
\[
\begin{array}{rclr}
\funrule{
  applyCast(v,\lcOOnull)
}{
  \rOOsucc{v}
}{}
\funrule{
  applyCast(v,\lcOOcons{s}{c})
}{
  applyStep(v,s) \mbind{} \lambda v. applyCast(v,c)
}{}
\end{array}
\]

\caption{The $L$ Lazy D Cast ADT}
\label{fig:L-instance-LazyD}
\end{figure}

The $L$ cast representation is defined in \figref{fig:L-instance-LazyD}.
Casts in $L$ are lists of steps ($s$), where every step is like a cast in 
\ineffCEKD. The function $applyCast$ applies steps from left to right. Steps are 
restricted by its typing rule such that its source and target are different. This 
restriction is necessary to show $cast(T,l,T) = id(T)$. With this representation
of casts, the operator $id$ produces an empty list of steps
and $seq$ appends two lists of steps. 

\begin{proposition}[$L$ Properties]\label{thm:L-LazyD-monoid}\ 
  \begin{enumerate}
  \item $L$ is an instance of the Lazy D ADT
  \item $L$ is a monoid
  \item $cast(T,l,T) = id(T)$
  \end{enumerate}
\end{proposition}
\begin{proof}
  Part (1) is straightforward because property (1) and (2) are 
  trivially true and because $appS$ effectively repeats property (3) - 
  (11).
  Part (2) is true because lists are known to be a monoid with respect to append.
  Part (3) follows immediately from the definition of $cast(T,l,T)$
\end{proof}

\begin{lemma}[$L$ is Correct wrt. \ineffCEKD]
  \label{lem:L-correct}
  If $\judgetype{\emptyset}{e}{T}$ and $o : T$, then
  \[
  \text{\evalEqv{\effCEK{L}}{\ineffCEKD}}
  \]
\end{lemma}
\begin{proof}
  Immediately from
  Correctness of \effCEK{C} (Corollary~\ref{thm:SD-equiv}) and 
  Properties of $L$ (Proposition~\ref{thm:L-LazyD-monoid}).
\end{proof}

\subsubsection{Correctness of \effCEK{C}}

\begin{theorem}[\effCEK{C} is Correct wrt. \ineffCEKD{}]
  \label{thm:surely-lazyD-correct}
  Suppose $C$ is a \lazyD{} Cast ADT.  If
  $\judgetype{\emptyset}{e}{T}$ and $o : T$ then
  \[
  \evalEqv{\effCEK{C}}{\ineffCEKD}
  \]
\end{theorem}
\begin{proof}
	Immediately from 
	Equivalence of \lazyD{} Cast ADTs (Lemma~\ref{thm:surely-lazyD-eqv})
%	\evalEqv{\effCEK{C}}{\effCEK{L}} (Lemma~\ref{thm:surely-lazyD-eqv})
	and
	$L$ is Correct wrt. \ineffCEKD{} (Lemma~\ref{lem:L-correct})
%	\evalEqv{\effCEK{L}}{\ineffCEKD} (Lemma~\ref{lem:L-correct})
\end{proof}


\section{Correctness Proof of \lazyD{} hypercoercions}
\label{sec:hypercoercion-correctness}

In this section, we prove \lazyD\ hypercoercions are 
correct. First, we define $applyCast(v,c)$ to make it an instance of Cast ADT, 
then prove that it is also Lazy D, and finally apply 
Theorem~\ref{thm:surely-lazyD-correct} to finish the proof.

\figref{hc-applyCast} defines $applyCast(v,c)$ for \lazyD\ hypercoercions.
Applying the identity cast for the dynamic type succeeds immediately. If the
value is injected and the cast is not the identity cast, then $applyCast$
projects the value and relies on $applyMiddle$ to ensure that value is shallow
consistent with target type of the head. Regardless of whether or not the value
is projected, $applyCast$ applies the middle, then apply the tail if the middle
succeeds. We denote by $r \; \mbind{} \; f$ to mean that if $r$ is 
$\rOOsucc{v}$, the
result is $f(v)$, otherwise, the result is the failure. In the definition of
$applyMiddle(v,\ell,m)$, we generalize shallow-consistency to compare middles
and values ($v \smile m$) in the obvious way. When a value is shallowly
inconsistent from the middle, it is the result of projecting a value that was
shallowly inconsistent with the expected type of the projection in the head. Thus, a
blame label $l$ must have been pass in as $\ell$ and is to blame. Finally if a
failure in $applyMiddle$ has not occurred then $applyTail(v, t)$ interprets the
tail, $t$, to the appropriate cast of the value $v$.

\begin{figure}
  \fbox{$applyCast(v,c) = r$}
  \[
  \begin{array}{rclr}
  \funrule{applyCast(v,\hyperCoercionI,)}{\rOOsucc{v}}{}
  \funrule{applyCast(\hcvOOinj{P}{v},\hyperCoercionC{?^l}{m}{t})}{
    applyMiddle(v,l,m) \; \mbind{} \; \lambda v. applyTail(t,v)
  }{}
  \funrule{applyCast(v,\hyperCoercionC{\epsilon}{m}{t})}{
    applyMiddle(v,\epsilon,m) \; \mbind{} \; \lambda v. applyTail(t,v)
  }{}
  \end{array}
  \]
  
  \fbox{$applyMiddle(v,\ell,m) = r$}
  \[
  \begin{array}{rclr}
  \funrule{applyMiddle(\hcvOOtt,\ell,\POOunit)}{\rOOsucc{\hcvOOtt}}{}
  \funrule{applyMiddle(\hcvOOfun{c_1}{\mathcal{E}}{x}{e}{c_2},\ell,\POOfun{c_3}{c_4})}{
    \rOOsucc{(\hcvOOfun{(c_3 \fatsemi^\ell c_1)}{\mathcal{E}}{x}{e}{(c_2 
    \fatsemi^\ell c_4)})}
  }{}
  \funrule{applyMiddle(\hcvOOcons{v_1}{c_1}{v_2}{c_2},\ell,\POOprod{c_3}{c_4})}{
    \rOOsucc{(\hcvOOcons{v_1}{(c_1 \fatsemi^\ell c_3)}{v_2}{(c_2 
    \fatsemi^\ell c_4)})}
  }{}
  \funrule{applyMiddle(\hcvOOinl{v}{c_1},\ell,\POOsum{c_3}{c_4})}{
    \rOOsucc{(\hcvOOinl{v}{(c_1 \fatsemi^\ell c_3)})}
  }{}
  \funrule{applyMiddle(\hcvOOinr{v}{c_2},\ell,\POOsum{c_3}{c_4})}{
    \rOOsucc{(\hcvOOinr{v}{(c_2 \fatsemi^\ell c_4)})}
  }{}
  \funrule{applyMiddle(v,l,m)}{
    \rOOfail{l}
  }{
    \sidecond{v \not\smile m}
  }
  \end{array}
  \]
  
  \fbox{$applyTail(v,t) = r$}
  \[
  \begin{array}{rclr}
  \funrule{applyTail(v,\bot^l)}{\rOOfail{l}}{}
  \funrule{applyTail(v,\epsilon)}{\rOOsucc{v}}{}
  \funrule{applyTail(v,!)}{\rOOsucc{(\hcvOOinj{P}{v})}}{}
  \end{array}
  \]
  \caption{\lazyD\ hypercoercion's $applyCast$}
  \label{hc-applyCast}
\end{figure}


\begin{lemma}[\lazyD{} Hypercoercion is a \lazyD{} Cast ADT]
  \label{thm:hc-surely-lazyD}
\end{lemma}
\begin{proof}
	See the Agda proof at the following URL:\\
	\urlLazyDProof
\end{proof}

\begin{theorem}[\lazyD{} Hypercoercion Respect \ineffCEKD]
  If $\judgetype{\emptyset}{e}{T}$ and $o : T$
  \[
  \text{\evalEqv{\effCEK{H}}{\ineffCEKD}}
  \]
\end{theorem}
\begin{proof}
  Immediately from that every Lazy D Cast ADT is correct ( 
  Theorem~\ref{thm:surely-lazyD-correct}) and that Lazy D hypercoercion is a 
  Lazy D Cast ADT (Lemma~\ref{thm:hc-surely-lazyD}). 
  %
  Alternatively, from Lemma~\ref{thm:SD-equiv},
  Lemma~\ref{thm:hc-surely-lazyD}, Proposition~\ref{thm:LazyD-HC-monoid}, and 
  Proposition~\ref{thm:LazyD-HC-identity-casts}
\end{proof}

\section{Conclusion} \label{sec:conclude}

In this paper, we presented a new cast representation, hypercoercions,
in two flavors, Lazy D and Lazy UD. Hypercoercions have a structurally
recursive composition operator and have a more compact memory
representation in comparison to coercions in normal form.

We also present steps toward the first framework for proving the
correctness of cast representations.
%
The framework includes abstract data types for cast representations
(Cast ADT and its refinement Lazy D Cast ADT), a parameterized abstract machine
\effCEK{C}, and a theorem which states that \effCEK{C} is equivalent
to $\ineffCEKD{}$ when $C$ is a Lazy D Cast ADT.
%
%The Lazy D Cast ADT refines the Cast ADT. 
%
We conjecture that Lazy D
threesomes and Lazy D coercions in normal form are instances of the
Lazy D Cast ADT.

Finally, we proved that Lazy D hypercoercions ($H$) is a Lazy D Cast
ADT. By using our framework, we showed that it is a correct cast
representation because $S(H)$ is equivalent to $D$.

%% Acknowledgments
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
\bibliography{bibfile,all}


%% Appendix
% \appendix
% \section{Appendix}

% Text of appendix \ldots


\end{document}
